{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Agent Prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains examples for using the Document Agent Prototype.\n",
    "\n",
    "It uses the new doc_agent_chat and doc_agent_upload services to upload documents to a project and then asks an agent questions about the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload a document\n",
    "\n",
    "We can upload a document to the database by calling the doc_agent_upload service.\n",
    "\n",
    "This service takes a URL to fetch text content, then it processes the text and uploads it to a vector database (Pinecone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The new services are designed to be called in a similar way to the existing AI chat services. This is just a function to illustrate the usage in this notebook.\n",
    "def upload_document(doc_url, user_description, project_id):\n",
    "    notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "    services_dir = os.path.abspath(os.path.join(notebook_dir, \"..\"))\n",
    "    \n",
    "    input_data = {\n",
    "        \"doc_url\": doc_url,\n",
    "        \"user_description\": user_description,\n",
    "        \"project_id\": project_id\n",
    "    }\n",
    "    \n",
    "    input_path = os.path.join(services_dir, \"tmp\", \"doc_agent_upload.json\")\n",
    "    output_path = os.path.join(services_dir, \"tmp\", \"upload_output.json\")\n",
    "    \n",
    "    with open(input_path, \"w\") as f:\n",
    "        json.dump(input_data, f, indent=2)\n",
    "    \n",
    "    result = subprocess.run(\n",
    "        [\"python\", \"entry.py\", \"doc_agent_upload\", \"--input\", \"tmp/doc_agent_upload.json\", \"--output\", \"tmp/upload_output.json\"],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        cwd=services_dir\n",
    "    )\n",
    "    \n",
    "    with open(output_path, \"r\") as f:\n",
    "        output_data = json.load(f)\n",
    "    \n",
    "    print(f\"✓ Uploaded: {user_description}\")\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The service takes a URL, user description and project ID. It returns a document ID for the uploaded document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Uploaded: Design workflow\n"
     ]
    }
   ],
   "source": [
    "# Example: upload a document\n",
    "doc_url = \"https://raw.githubusercontent.com/OpenFn/docs/refs/heads/main/docs/design/design-workflow.md\"\n",
    "user_description = \"Design workflow\"\n",
    "project_id = \"proj_1\"\n",
    "\n",
    "# Uncomment to upload:\n",
    "# upload_result = upload_document(doc_url, user_description, project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat with the document agent\n",
    "\n",
    "We can chat to an LLM that has the ability to query the uploaded documents by calling the doc_agent_chat service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_agent_chat(content, project_id, project_name, documents, history):\n",
    "    # Build the input payload\n",
    "    input_data = {\n",
    "        \"content\": content,\n",
    "        \"context\": {\n",
    "            \"project_id\": project_id,\n",
    "            \"project_name\": project_name,\n",
    "            \"documents\": documents\n",
    "        },\n",
    "        \"history\": history\n",
    "    }\n",
    "    \n",
    "    # Get the services directory (one level up from doc_agent_chat)\n",
    "    notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "    services_dir = os.path.abspath(os.path.join(notebook_dir, \"..\"))\n",
    "    \n",
    "    input_path = os.path.join(services_dir, \"tmp\", \"doc_agent_chat.json\")\n",
    "    output_path = os.path.join(services_dir, \"tmp\", \"output.json\")\n",
    "    \n",
    "    # Write input file\n",
    "    with open(input_path, \"w\") as f:\n",
    "        json.dump(input_data, f, indent=2)\n",
    "    \n",
    "    # Call the service from the services directory\n",
    "    result = subprocess.run(\n",
    "        [\"python\", \"entry.py\", \"doc_agent_chat\", \"--input\", \"tmp/doc_agent_chat.json\", \"--output\", \"tmp/output.json\"],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        cwd=services_dir\n",
    "    )\n",
    "    \n",
    "    # Read the output\n",
    "    with open(output_path, \"r\") as f:\n",
    "        output_data = json.load(f)\n",
    "    \n",
    "    # Print only the response text\n",
    "    if \"response\" in output_data:\n",
    "        print(\"Response:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(output_data[\"response\"])\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The document agent service takes a user message (content), project ID, project name, documents and conversation history as inputs.\n",
    "\n",
    "Like the other Apollo chat services, this service is stateless and should be called every conversation turn. The front-end would need to have a system for storing project and document IDs at least, and the database a more sophisticated way to limit access between orgs/projects/docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "--------------------------------------------------------------------------------\n",
      "Based on the documentation, here are the key practices for handling user data when working with the CLI:\n",
      "\n",
      "## Security Best Practices\n",
      "\n",
      "### 1. **Store Sensitive Files in a `tmp` Directory**\n",
      "\n",
      "\n",
      "\n",
      "It's a good practice to store `state.json` and `output.json` in a `tmp` folder\n",
      "\n",
      ", as these files often contain sensitive information.\n",
      "\n",
      "### 2. **Never Upload Sensitive Files to GitHub**\n",
      "\n",
      "\n",
      "\n",
      "Since `state.json` and `output.json` may contain sensitive configuration information and project data, it's important to never upload them to GitHub. To ensure that GitHub ignores these files, add the `tmp` directory to your `.gitignore` file\n",
      "\n",
      " using: `echo \"tmp\" >> .gitignore`\n",
      "\n",
      "### 3. **Be Careful with Logging**\n",
      "\n",
      "\n",
      "\n",
      "Note that `console.log(state)` will display the whole state, including `state.configuration` elements such as **username and password**. Remove this log whenever you're done debugging to avoid accidentally exposing sensitive information when the job is successfully deployed on production.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The OpenFn platform has built in protections to \"scrub\" state from the logs, but when you're using the CLI directly you're on your own!\n",
      "\n",
      "\n",
      "\n",
      "### 4. **Use Separate Credential Files**\n",
      "\n",
      "When working with workflows, \n",
      "\n",
      "specify a path to a git ignored configuration file that will contain necessary credentials that will be used to access the destination system\n",
      "\n",
      ".\n",
      "\n",
      "### 5. **Keep Initial Data Secure**\n",
      "\n",
      "\n",
      "\n",
      "In case you need to pass initial data to your job, specify a path to a gitignored data file\n",
      "\n",
      ".\n",
      "\n",
      "## Summary\n",
      "\n",
      "The key principle is to **keep sensitive data separate from your code** and ensure these files are git-ignored. Always be mindful when using `console.log()` to avoid exposing credentials or sensitive user information in your logs.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Query parameters\n",
    "content = \"How should I handle user data when working with the CLI?\"\n",
    "project_id = \"proj_1\"\n",
    "project_name = \"OpenFN CLI Project\"\n",
    "\n",
    "# All uploaded documents that the user wants to include in the conversation\n",
    "documents = [\n",
    "    {\n",
    "        \"uuid\": \"fd8370c4-24ad-4323-8ab2-4053569aedef\",\n",
    "        \"title\": \"CLI Walkthrough\",\n",
    "        \"description\": \"OpenFn CLI documentation\"\n",
    "    }\n",
    "]\n",
    "# Or use empty list if no documents:\n",
    "# documents = []\n",
    "\n",
    "history = []\n",
    "\n",
    "# Call the service and save output\n",
    "output = call_agent_chat(content, project_id, project_name, documents, history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Output Details\n",
    "\n",
    "Explore tool calls, retrieved texts, and other details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'code': 500,\n",
       " 'type': 'INTERNAL_ERROR',\n",
       " 'message': \"string indices must be integers, not 'str'\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool calls\n",
    "if \"tool_calls\" in output:\n",
    "    print(\"Tool Calls:\")\n",
    "    print(\"-\" * 80)\n",
    "    for i, tool_call in enumerate(output[\"tool_calls\"], 1):\n",
    "        print(f\"\\n{i}. {tool_call.get('name', 'Unknown')}\")\n",
    "        if \"arguments\" in tool_call:\n",
    "            print(f\"   Arguments: {json.dumps(tool_call['arguments'], indent=2)}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Retrieved texts/documents\n",
    "if \"retrieved_texts\" in output:\n",
    "    print(\"\\n\\nRetrieved Texts:\")\n",
    "    print(\"-\" * 80)\n",
    "    for i, text in enumerate(output[\"retrieved_texts\"], 1):\n",
    "        print(f\"\\n{i}. {text[:200]}...\" if len(text) > 200 else f\"\\n{i}. {text}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Show all available keys\n",
    "print(\"\\n\\nAvailable output keys:\", list(output.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openfn",
   "language": "python",
   "name": "openfn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
