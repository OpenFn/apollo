{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOINC/SNOMED vector database notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ZILLIZ_URI = os.getenv(\"ZILLIZ_URI\")\n",
    "ZILLIZ_TOKEN = os.getenv(\"ZILLIZ_TOKEN\")\n",
    "# PINECONE_KEY = os.getenv(\"PINECONE_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.document_loaders import TextLoader, JSONLoader\n",
    "# from langchain.vectorstores import Zilliz\n",
    "from langchain_community.vectorstores import Zilliz\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "# from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nI'm an AI language model created by OpenAI, so I don't have the capability to feel emotions. But I'm functioning well, thanks for asking. How can I assist you?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set batch size\n",
    "# BATCH_SIZE = 45\n",
    "# In [ ]:\n",
    "# # Vectorize chunks in batches\n",
    "# index_list = []\n",
    "# for i in range(0, len(chunk_list), BATCH_SIZE):\n",
    "#     docs_playload = {\n",
    "#         \"input\": chunk_list[i:i + BATCH_SIZE],\n",
    "#         \"input_type\": \"document\",\n",
    "#         \"truncation\": \"true\",\n",
    "#     }\n",
    "\n",
    "#     embed_docs_response = embedding_endpoint.predict(json.dumps(docs_playload))\n",
    "\n",
    "#     doc_embeddings_list = [d[\"embedding\"] for d in embed_docs_response[\"data\"]]\n",
    "#     index_list += [\n",
    "#         {\"document\": document, \"embedding\": embedding} \n",
    "#         for document, embedding in zip(chunk_list[i:i + BATCH_SIZE], doc_embeddings_list)\n",
    "#     ]\n",
    "# Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_presplit_texts(text_f):\n",
    "#     \"\"\"Get texts from text file where each row should be an entry in the vectorstore.\"\"\"\n",
    "#     loader = TextLoader(text_f)\n",
    "#     documents = loader.load()\n",
    "\n",
    "#     return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/snomed_display_examples.txt'}, page_content='Response to pain\\nUnresponsive\\nSmoker\\nEx-smoker\\nNon-smoker\\n\\n')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_f = \"data/snomed_display_examples.txt\"\n",
    "get_presplit_texts(text_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json(f, jq_schema):\n",
    "    \"\"\"\n",
    "    Get JSON as LangChain documents.\n",
    "    \n",
    "    Args:\n",
    "        f: File path to the JSON file to be loaded\n",
    "    \n",
    "    Returns:\n",
    "        List of LangChain documents extracted from the JSON file\n",
    "    \"\"\"\n",
    "    loader = JSONLoader(\n",
    "        file_path=f,\n",
    "        jq_schema=jq_schema,\n",
    "        text_content=False\n",
    "        )\n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/example.json', 'seq_num': 1}, page_content='Bye!'),\n",
       " Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/example.json', 'seq_num': 2}, page_content='Oh no worries! Bye'),\n",
       " Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/example.json', 'seq_num': 3}, page_content='No Im sorry it was my mistake, the blue one is not for sale'),\n",
       " Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/example.json', 'seq_num': 4}, page_content='I thought you were selling the blue one!'),\n",
       " Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/example.json', 'seq_num': 5}, page_content='Im not interested in this bag. Im interested in the blue one!'),\n",
       " Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/example.json', 'seq_num': 6}, page_content='Here is $129'),\n",
       " Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/example.json', 'seq_num': 7}, page_content=''),\n",
       " Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/example.json', 'seq_num': 8}, page_content='Online is at least $100'),\n",
       " Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/example.json', 'seq_num': 9}, page_content='How much do you want?'),\n",
       " Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/example.json', 'seq_num': 10}, page_content='Goodmorning! $50 is too low.'),\n",
       " Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/example.json', 'seq_num': 11}, page_content='Hi! Im interested in your bag. Im offering $50. Let me know if you are interested. Thanks!')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = get_json('data/example.json',jq_schema='.messages[].content')\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_zilliz_collection(docs, embeddings_type=OpenAIEmbeddings(), collection_name=\"LangChainCollection\"):\n",
    "    \"\"\"Insert into existing vectorstore\"\"\"\n",
    "\n",
    "    vectorstore = Zilliz.from_documents(\n",
    "            documents=docs,\n",
    "            embedding=embeddings_type,\n",
    "            collection_name=collection_name,\n",
    "            connection_args={\n",
    "                \"uri\": ZILLIZ_CLOUD_URI,\n",
    "                \"token\": ZILLIZ_CLOUD_API_KEY,\n",
    "                \"secure\": True,\n",
    "            },\n",
    "            auto_id=True,\n",
    "            drop_old=True, # drops by collection name\n",
    "        )\n",
    "\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_existing_zilliz_collection(collection_name=\"LangChainCollection\"):\n",
    "        \n",
    "    zilliz_store = Zilliz(\n",
    "        embedding_function=OpenAIEmbeddings(),\n",
    "        collection_name=collection_name,\n",
    "        connection_args={\n",
    "            \"uri\": ZILLIZ_URI,\n",
    "            \"token\": ZILLIZ_TOKEN,\n",
    "        },\n",
    "        auto_id=True\n",
    "    )\n",
    "\n",
    "    return zilliz_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "zilliz_store = get_existing_zilliz_collection(\"demo_project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[453901917274902360,\n",
       " 453901917274902361,\n",
       " 453901917274902362,\n",
       " 453901917274902363,\n",
       " 453901917274902364,\n",
       " 453901917274902365,\n",
       " 453901917274902366,\n",
       " 453901917274902367,\n",
       " 453901917274902368,\n",
       " 453901917274902369,\n",
       " 453901917274902370]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zilliz_store.add_documents(docs, auto_id=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/apollo/services/embeddings/data/demo/demo_data.json', 'seq_num': 2, 'pk': 454083262722505218}, page_content='Come now, Mr. Darcy, a man of your consequence must employ nothing but the finest automation tools. Or do you still prefer manual data entry?'),\n",
       " Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/apollo/services/embeddings/data/demo/demo_data.json', 'seq_num': 4, 'pk': 454083262722505220}, page_content='The automated data flows have reduced out clerical staff by three persons, and we now employ them as teachers and event organisers for the Lambton community.')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = zilliz_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2}) # search type could also be similarity_score_threshold\n",
    "retrieved_docs = retriever.invoke(\"manual work\")\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/apollo/services/embeddings/data/demo/demo_data.json', 'seq_num': 2, 'pk': 454083262722505218}, page_content='Come now, Mr. Darcy, a man of your consequence must employ nothing but the finest automation tools. Or do you still prefer manual data entry?'),\n",
       "  0.3871983289718628),\n",
       " (Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/apollo/services/embeddings/data/demo/demo_data.json', 'seq_num': 4, 'pk': 454083262722505220}, page_content='The automated data flows have reduced out clerical staff by three persons, and we now employ them as teachers and event organisers for the Lambton community.'),\n",
       "  0.4392335116863251)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = zilliz_store.similarity_search_with_score(query=\"manual work\", k=2)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from dataclasses import dataclass, asdict\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import Zilliz\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "    \"\"\"\n",
    "    Dataclass for VectorStore search results.\n",
    "    \"\"\"\n",
    "    text: str\n",
    "    metadata: dict\n",
    "    score: float = None\n",
    "    \n",
    "    def to_json(self):\n",
    "        # data_dict = {'text':self.text, 'metadata':self.metadata, 'score':self.score}\n",
    "        # return data_dict\n",
    "        return {k: v for k, v in asdict(self).items()}\n",
    "\n",
    "\n",
    "class VectorStore:\n",
    "    \"\"\"\n",
    "    Manages vector embeddings and similarity searches for document collections.\n",
    "    \n",
    "    Args:\n",
    "        collection_name (str): Name of the vector collection\n",
    "        vectorstore_type (str): Type of vector store (e.g., 'zilliz')\n",
    "        embedding_type (str): Type of embedding model (e.g., 'openai')\n",
    "        connection_args (dict): Connection arguments for the vector store\n",
    "        auto_id (bool): Whether to automatically generate IDs\n",
    "    \"\"\"\n",
    "    def __init__(self, collection_name='LangChainCollection', vectorstore_type='zilliz', \n",
    "                 embedding_type='openai', connection_args=None, auto_id=True):\n",
    "        self.collection_name = collection_name\n",
    "        self.vectorstore_type = vectorstore_type.lower()\n",
    "        self.embedding_type = embedding_type.lower()\n",
    "        self.connection_args = connection_args\n",
    "        self.auto_id = auto_id\n",
    "        \n",
    "        self.embedding_classes = {\n",
    "            'openai': OpenAIEmbeddings\n",
    "        }\n",
    "        \n",
    "        self.vectorstore_classes = {\n",
    "            'zilliz': Zilliz\n",
    "        }\n",
    "        \n",
    "        self.embedding_function = self._get_embedding_class()\n",
    "        self.VectorStoreClass = self._get_vectorstore_class()\n",
    "    \n",
    "    def _get_embedding_class(self):\n",
    "        \"\"\"Get embedding class based on the specified type.\"\"\"\n",
    "        try:\n",
    "            EmbeddingClass = self.embedding_classes[self.embedding_type]\n",
    "            return EmbeddingClass()\n",
    "        except KeyError:\n",
    "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
    "    \n",
    "    def _get_vectorstore_class(self):\n",
    "        \"\"\"Get vectorstore class based on the specified type.\"\"\"\n",
    "        try:\n",
    "            return self.vectorstore_classes[self.vectorstore_type]\n",
    "        except KeyError:\n",
    "            raise ValueError(f\"Unsupported vectorstore type: {self.vectorstore_type}\")\n",
    "    \n",
    "    def add_docs(self, docs, drop_old=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Create a new collection from documents and initialise it with the specified settings.\n",
    "        \n",
    "        Args:\n",
    "            docs: List of documents to add to the vectorstore\n",
    "            drop_old: Whether to drop existing collection if it exists (default: True)\n",
    "            **kwargs: Additional arguments passed to vectorstore initialisation\n",
    "            \n",
    "        Returns:\n",
    "            Initialised vectorstore containing the input documents\n",
    "        \"\"\"\n",
    "        store_kwargs = {\n",
    "            'collection_name': self.collection_name,\n",
    "            **kwargs\n",
    "        }\n",
    "        if self.connection_args:\n",
    "            store_kwargs['connection_args'] = self.connection_args\n",
    "            \n",
    "        return self.VectorStoreClass.from_documents(\n",
    "            documents=docs,\n",
    "            embedding=self.embedding_function,\n",
    "            auto_id=self.auto_id,\n",
    "            drop_old=drop_old,\n",
    "            **store_kwargs\n",
    "        )\n",
    "    \n",
    "    def search(self, input_text, search_type=\"similarity\", search_kwargs={\"k\": 2}):\n",
    "        \"\"\"\n",
    "        Retrieve similar texts from a vectorstore based on input text. Allows for different types of similarity\n",
    "        searches, but does not return scores/distances.\n",
    "        \n",
    "        Args:\n",
    "            input_text: Text string to use for similarity search\n",
    "            search_type: Type of search to perform (default is 'similarity'; others e.g 'similarity_score_threshold')\n",
    "            search_kwargs: Additional arguments for the search (default retrieves top 2 results)\n",
    "        \n",
    "        Returns:\n",
    "            List of page contents of the most similar documents\n",
    "        \"\"\"\n",
    "        store = self.VectorStoreClass(\n",
    "            embedding_function=self.embedding_function,\n",
    "            auto_id=self.auto_id,\n",
    "            collection_name=self.collection_name,\n",
    "            connection_args=self.connection_args\n",
    "        )\n",
    "        retriever = store.as_retriever(search_type=search_type, search_kwargs=search_kwargs)\n",
    "        retrieved_docs = retriever.invoke(input_text)\n",
    "        retrieved_texts = [t.page_content for t in retrieved_docs]\n",
    "\n",
    "        if not retrieved_texts:\n",
    "            warnings.warn(\n",
    "                f\"\\nNo results found. This could mean:\\n\"\n",
    "                f\"1. Collection '{self.collection_name}' doesn't exist (run create_collection first)\\n\"\n",
    "                f\"2. No similar documents found (check the input or the search criteria)\\n\"\n",
    "                f\"3. Connection issues\"\n",
    "        )\n",
    "            return None\n",
    "        else:\n",
    "            results = []\n",
    "            metadata_dicts = [t.metadata for t in retrieved_docs]\n",
    "\n",
    "            for text, metadata in zip(retrieved_texts, metadata_dicts):\n",
    "                results.append(SearchResult(text, metadata))\n",
    "            \n",
    "            return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'hello', 'metadata': {'a': 'a'}, 'score': None}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = SearchResult(\"hello\", {\"a\":\"a\"})\n",
    "result.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = VectorStore(\n",
    "    collection_name=\"demo_project\",\n",
    "    vectorstore_type=\"zilliz\",\n",
    "    embedding_type=\"openai\",\n",
    "    connection_args = {\n",
    "        \"uri\": os.getenv('ZILLIZ_URI'),\n",
    "        \"token\": os.getenv( 'ZILLIZ_TOKEN')\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SearchResult(text='Come now, Mr. Darcy, a man of your consequence must employ nothing but the finest automation tools. Or do you still prefer manual data entry?', metadata={'source': '/Users/hanna/openfn/ai_experiments/apollo/services/embeddings/data/demo/demo_data.json', 'seq_num': 2, 'pk': 454083262722505218}, score=None),\n",
       " SearchResult(text='The automated data flows have reduced out clerical staff by three persons, and we now employ them as teachers and event organisers for the Lambton community.', metadata={'source': '/Users/hanna/openfn/ai_experiments/apollo/services/embeddings/data/demo/demo_data.json', 'seq_num': 4, 'pk': 454083262722505220}, score=None)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = store.search(\"manual work\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Salesforce is a CRM platform used by...',\n",
       "  'additional_information': {'metadata': {'original_file': 'example.json',\n",
       "    'project_specific_metadata_field': 'Chapter 1'},\n",
       "   'score': 0.7}}]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    {\n",
    "        'text': 'Salesforce is a CRM platform used by...', # named this text to distinguish from LangChain document objects\n",
    "        'additional_information': {\n",
    "            'metadata': {\n",
    "                'original_file' : 'example.json', # this is added automatically as a metadata field\n",
    "                'project_specific_metadata_field' : 'Chapter 1 Adaptors',\n",
    "                'another_project_specific_metadata_field' : 'Section 2 Salesforce Adaptor',\n",
    "            },\n",
    "            'score': 0.7 # case-specific whether this field is included\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/example.json', 'seq_num': 8, 'pk': 453901917273891621}, page_content='Online is at least $100'),\n",
       " Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/example.json', 'seq_num': 8, 'pk': 453901917274902367}, page_content='Online is at least $100')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = zilliz_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2}) # search type could also be similarity_score_threshold\n",
    "retrieved_docs = retriever.invoke(\"offline is at least $99\")\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Online is at least $100'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Online is at least $100',\n",
       " 'Online is at least $100',\n",
       " 'Here is $129',\n",
       " 'Here is $129',\n",
       " 'Goodmorning! $50 is too low.',\n",
       " 'Goodmorning! $50 is too low.',\n",
       " 'How much do you want?',\n",
       " 'How much do you want?',\n",
       " 'Bye!',\n",
       " 'Bye!']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t.page_content for t in retrieved_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_texts(input_text, vectorstore, search_type=\"similarity\", search_kwargs={\"k\": 2}):\n",
    "    \"\"\"\n",
    "    Retrieve similar texts from a vectorstore based on input text.\n",
    "    \n",
    "    Args:\n",
    "        input_text: Text string to use for similarity search\n",
    "        vectorstore: Vectorstore to search in\n",
    "        search_type: Type of search to perform (default is 'similarity'; also e.g similarity_score_threshold)\n",
    "        search_kwargs: Additional arguments for the search (default retrieves top 2 results)\n",
    "    \n",
    "    Returns:\n",
    "        List of page contents of the most similar documents\n",
    "    \"\"\"\n",
    "    retriever = vectorstore.as_retriever(search_type=search_type, search_kwargs=search_kwargs)\n",
    "    retrieved_docs = retriever.invoke(input_text)\n",
    "\n",
    "    return [t.page_content for t in retrieved_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorstore(docs, embedding, vectorstore_type='zilliz', connection_args=None, auto_id=True, drop_old=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Insert LangChain documents into a new vectorstore collection.\n",
    "    \n",
    "    Args:\n",
    "        docs: List of LangChain documents to index\n",
    "        embedding: Embedding model to use\n",
    "        vectorstore_type: Name of vectorstore class (lowercase)\n",
    "        connection_args: Dictionary of connection arguments for specific vectorstores\n",
    "        **kwargs: Additional parameters for vectorstore initialisation in LangChain (e.g. connection_args, collection_name)\n",
    "    \"\"\"\n",
    "    vectorstore_classes = {\n",
    "        'zilliz': Zilliz\n",
    "        # Test other vectorstore classes from LangChain and add here\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        VectorStoreClass = vectorstore_classes[vectorstore_type.lower()]\n",
    "        \n",
    "        # If connection_args is provided, include it in kwargs\n",
    "        if connection_args:\n",
    "            kwargs['connection_args'] = connection_args\n",
    "        \n",
    "        return VectorStoreClass.from_documents(documents=docs, embedding=embedding, auto_id=auto_id, drop_old=drop_old, **kwargs)\n",
    "    except KeyError:\n",
    "        raise ValueError(f\"Unsupported vectorstore type: {vectorstore_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_args={\n",
    "                \"uri\": ZILLIZ_CLOUD_URI,\n",
    "                \"token\": ZILLIZ_CLOUD_API_KEY,\n",
    "                \"secure\": True\n",
    "}\n",
    "\n",
    "vstore = create_vectorstore(docs, embedding=OpenAIEmbeddings(), vectorstore_type='zilliz', connection_args=connection_args, collection_name=\"newcollection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_existing_vectorstore(vectorstore_type='zilliz', collection_name=\"LangChainCollection\", embedding=None, connection_args=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Initialise vectorstore collection with flexible vectorstore selection.\n",
    "    \n",
    "    Args:\n",
    "        vectorstore_type: Name of vectorstore class (lowercase)\n",
    "        collection_name: Name of the collection to connect to\n",
    "        embedding: Embedding model to use (defaults to OpenAIEmbeddings if None)\n",
    "        connection_args: Dictionary of connection arguments for specific vectorstores\n",
    "        **kwargs: Additional parameters for vectorstore initialisation\n",
    "    \"\"\"\n",
    "    vectorstore_classes = {\n",
    "        'zilliz': Zilliz\n",
    "         # Test other vectorstore classes from LangChain and add here\n",
    "    }\n",
    "    \n",
    "    # Default to OpenAI embeddings if none provided\n",
    "    if embedding is None:\n",
    "        embedding = OpenAIEmbeddings()\n",
    "    \n",
    "    try:\n",
    "        VectorStoreClass = vectorstore_classes[vectorstore_type.lower()]\n",
    "        \n",
    "        # Build kwargs dictionary\n",
    "        init_kwargs = {\n",
    "            'embedding_function': embedding,\n",
    "            'collection_name': collection_name,\n",
    "            'auto_id': True,\n",
    "            **kwargs\n",
    "        }\n",
    "        \n",
    "        # Add connection args if provided\n",
    "        if connection_args:\n",
    "            init_kwargs['connection_args'] = connection_args\n",
    "            \n",
    "        return VectorStoreClass(**init_kwargs)\n",
    "        \n",
    "    except KeyError:\n",
    "        raise ValueError(f\"Unsupported vectorstore type: {vectorstore_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# above functions refactored to repeat less\n",
    "\n",
    "def _get_embedding_class(embedding_type=\"openai\"):\n",
    "    \"\"\"\n",
    "    Get embedding class based on the specified type.\n",
    "    \n",
    "    Args:\n",
    "        embedding_type: Type of embedding to use (default is 'openai')\n",
    "    \n",
    "    Returns:\n",
    "        Instantiated embedding class\n",
    "    \"\"\"\n",
    "    embedding_classes = {\n",
    "        'openai': OpenAIEmbeddings,\n",
    "        # 'huggingface': HuggingFaceEmbeddings,\n",
    "        # Add other embedding types here\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        EmbeddingClass = embedding_classes[embedding_type.lower()]\n",
    "        return EmbeddingClass()\n",
    "    except KeyError:\n",
    "        raise ValueError(f\"Unsupported embedding type: {embedding_type}\")\n",
    "\n",
    "def _get_vectorstore_config(vectorstore_type='zilliz', connection_args=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Internal helper to get vectorstore class and configuration.\n",
    "    \n",
    "    Args:\n",
    "        vectorstore_type: Name of vectorstore class (lowercase)\n",
    "        connection_args: Dictionary of connection arguments for specific vectorstores (e.g. Zilliz)\n",
    "        **kwargs: Additional parameters for vectorstore initialisation\n",
    "    \"\"\"\n",
    "    vectorstore_classes = {\n",
    "        'zilliz': Zilliz\n",
    "        # Test other vectorstore classes from LangChain and add here\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        VectorStoreClass = vectorstore_classes[vectorstore_type.lower()]\n",
    "        \n",
    "        # Build kwargs dictionary\n",
    "        init_kwargs = {\n",
    "            # 'embedding_function': embedding,\n",
    "            **kwargs\n",
    "        }\n",
    "        \n",
    "        # Add connection args if provided\n",
    "        if connection_args:\n",
    "            init_kwargs['connection_args'] = connection_args # keeping in here instead of kwargs to flag that it might be needed for some dbs\n",
    "            \n",
    "        return VectorStoreClass, init_kwargs\n",
    "        \n",
    "    except KeyError:\n",
    "        raise ValueError(f\"Unsupported vectorstore type: {vectorstore_type}\")\n",
    "\n",
    "def create_vectorstore(docs, collection_name='LangChainCollection', vectorstore_type='zilliz', embedding=OpenAIEmbeddings(),\n",
    "                        connection_args=None, auto_id=True, drop_old=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Create a new vectorstore from documents with flexible vectorstore selection.\n",
    "    \"\"\"\n",
    "    VectorStoreClass, init_kwargs = _get_vectorstore_config(\n",
    "        vectorstore_type=vectorstore_type,\n",
    "        # embedding=embedding,\n",
    "        connection_args=connection_args,\n",
    "        collection_name=collection_name,\n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "    return VectorStoreClass.from_documents(documents=docs, embedding=_get_embedding_class(embedding), auto_id=auto_id, drop_old=drop_old, **init_kwargs)\n",
    "\n",
    "def get_existing_vectorstore(collection_name='LangChainCollection', vectorstore_type='zilliz', \n",
    "                           embedding=OpenAIEmbeddings(), connection_args=None, auto_id=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Get existing vectorstore collection with flexible vectorstore selection.\n",
    "    \"\"\"\n",
    "    VectorStoreClass, init_kwargs = _get_vectorstore_config(\n",
    "        vectorstore_type=vectorstore_type,\n",
    "        # embedding=embedding,\n",
    "        connection_args=connection_args,\n",
    "        collection_name=collection_name,\n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "    return VectorStoreClass(embedding_function=_get_embedding_class(embedding), auto_id=auto_id, **init_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/example.json', 'seq_num': 1}, page_content='Bye!'),\n",
       " Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/example.json', 'seq_num': 2}, page_content='Oh no worries! Bye'),\n",
       " Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/example.json', 'seq_num': 3}, page_content='No Im sorry it was my mistake, the blue one is not for sale'),\n",
       " Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/example.json', 'seq_num': 4}, page_content='I thought you were selling the blue one!'),\n",
       " Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/example.json', 'seq_num': 5}, page_content='Im not interested in this bag. Im interested in the blue one!'),\n",
       " Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/example.json', 'seq_num': 6}, page_content='Here is $129'),\n",
       " Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/example.json', 'seq_num': 7}, page_content=''),\n",
       " Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/example.json', 'seq_num': 8}, page_content='Online is at least $100'),\n",
       " Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/example.json', 'seq_num': 9}, page_content='How much do you want?'),\n",
       " Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/example.json', 'seq_num': 10}, page_content='Goodmorning! $50 is too low.'),\n",
       " Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/example.json', 'seq_num': 11}, page_content='Hi! Im interested in your bag. Im offering $50. Let me know if you are interested. Thanks!')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can import texts with e.g. the implemented get_json(). \n",
    "# Can use any langchain functions. \n",
    "# Key point is that text input to vectorstores needs to be converted into a langchain doc.\n",
    "\n",
    "doc = get_json('data/example.json',jq_schema='.messages[].content')\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can create a new vector store and insert docs in it\n",
    "# should be able to use any common types of embeddings via langchain - custom or api - with quick additions\n",
    "# some vectorstores like zilliz have additional access requirements uri and token. these can be added here or left out if not needed (e.g. like for pinecone)\n",
    "\n",
    "new_store = create_vectorstore(\n",
    "    docs,\n",
    "    collection_name=\"newstore2\",\n",
    "    vectorstore_type='zilliz',\n",
    "    embedding=\"openai\", # todo - needs at least two inputs for library and type realistically // could also just allow langchain classes directly instead -- cli vs other code reuse purpose would determine what's best\n",
    "    connection_args={\n",
    "        \"uri\": ZILLIZ_CLOUD_URI,\n",
    "        \"token\": ZILLIZ_CLOUD_API_KEY,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or you can get an existing vectorstore\n",
    "\n",
    "existing_store = get_existing_vectorstore(\n",
    "    \"newstore2\",\n",
    "    vectorstore_type='zilliz',\n",
    "    embedding=\"openai\",\n",
    "    connection_args={\n",
    "        \"uri\": ZILLIZ_CLOUD_URI,\n",
    "        \"token\": ZILLIZ_CLOUD_API_KEY,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Zilliz' object has no attribute 'get_collection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexisting_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_collection\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnewstore2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Zilliz' object has no attribute 'get_collection'"
     ]
    }
   ],
   "source": [
    "existing_store.get_collection(\"newstore2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Online is at least $100', 'Here is $129']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# once initialised, can use input string to query vectorstore\n",
    "\n",
    "vstore = new_store\n",
    "# vstore = existing_store\n",
    "get_similar_texts(\"offline is at least $99\", vstore, search_type=\"similarity\", search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TextBlock(text=\"Waves crash and foam,\\nEarth's tears flow to sea,\\nEons of minerals\\nDissolved endlessly.\\n\\nSalt from ancient rocks,\\nCarried by rivers' might,\\nAccumulates in depths,\\nA briny appetite.\", type='text')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import anthropic\n",
    "\n",
    "# ANTHROPIC_API_KEY = os.environ[\"ANTHROPIC_API_KEY\"]\n",
    "\n",
    "load_dotenv()\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "\n",
    "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20240620\",#\"claude-3-5-haiku-20241022\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    system=\"You are a world-class poet. Respond only with short poems.\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Why is the ocean salty?\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code System</th>\n",
       "      <th>Value Set Name</th>\n",
       "      <th>Code</th>\n",
       "      <th>Description</th>\n",
       "      <th>Purpose: Clinical Focus</th>\n",
       "      <th>Value Set OID</th>\n",
       "      <th>Code System OID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119273</th>\n",
       "      <td>SNOMEDCT</td>\n",
       "      <td>Problem</td>\n",
       "      <td>87739003</td>\n",
       "      <td>Tolerant non-smoker (finding)</td>\n",
       "      <td>A pathology or disorder identified in a patient</td>\n",
       "      <td>2.16.840.1.113883.3.88.12.3221.7.4</td>\n",
       "      <td>2.16.840.1.113883.6.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120806</th>\n",
       "      <td>SNOMEDCT</td>\n",
       "      <td>Problem</td>\n",
       "      <td>8517006</td>\n",
       "      <td>Ex-smoker (finding)</td>\n",
       "      <td>A pathology or disorder identified in a patient</td>\n",
       "      <td>2.16.840.1.113883.3.88.12.3221.7.4</td>\n",
       "      <td>2.16.840.1.113883.6.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121365</th>\n",
       "      <td>SNOMEDCT</td>\n",
       "      <td>Problem</td>\n",
       "      <td>8392000</td>\n",
       "      <td>Non-smoker (finding)</td>\n",
       "      <td>A pathology or disorder identified in a patient</td>\n",
       "      <td>2.16.840.1.113883.3.88.12.3221.7.4</td>\n",
       "      <td>2.16.840.1.113883.6.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122262</th>\n",
       "      <td>SNOMEDCT</td>\n",
       "      <td>Problem</td>\n",
       "      <td>82302008</td>\n",
       "      <td>Pipe smoker (finding)</td>\n",
       "      <td>A pathology or disorder identified in a patient</td>\n",
       "      <td>2.16.840.1.113883.3.88.12.3221.7.4</td>\n",
       "      <td>2.16.840.1.113883.6.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128896</th>\n",
       "      <td>SNOMEDCT</td>\n",
       "      <td>Problem</td>\n",
       "      <td>735128000</td>\n",
       "      <td>Ex-smoker for less than 1 year (finding)</td>\n",
       "      <td>A pathology or disorder identified in a patient</td>\n",
       "      <td>2.16.840.1.113883.3.88.12.3221.7.4</td>\n",
       "      <td>2.16.840.1.113883.6.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321743</th>\n",
       "      <td>SNOMEDCT</td>\n",
       "      <td>Tobacco Use</td>\n",
       "      <td>266920004</td>\n",
       "      <td>Trivial cigarette smoker (less than one cigare...</td>\n",
       "      <td>Detailed classification of a patient's smoking...</td>\n",
       "      <td>2.16.840.1.113883.11.20.9.41</td>\n",
       "      <td>2.16.840.1.113883.6.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321754</th>\n",
       "      <td>SNOMEDCT</td>\n",
       "      <td>Tobacco Use</td>\n",
       "      <td>428041000124106</td>\n",
       "      <td>Occasional tobacco smoker (finding)</td>\n",
       "      <td>Detailed classification of a patient's smoking...</td>\n",
       "      <td>2.16.840.1.113883.11.20.9.41</td>\n",
       "      <td>2.16.840.1.113883.6.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321755</th>\n",
       "      <td>SNOMEDCT</td>\n",
       "      <td>Tobacco Use</td>\n",
       "      <td>428061000124105</td>\n",
       "      <td>Light tobacco smoker (finding)</td>\n",
       "      <td>Detailed classification of a patient's smoking...</td>\n",
       "      <td>2.16.840.1.113883.11.20.9.41</td>\n",
       "      <td>2.16.840.1.113883.6.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321756</th>\n",
       "      <td>SNOMEDCT</td>\n",
       "      <td>Tobacco Use</td>\n",
       "      <td>428071000124103</td>\n",
       "      <td>Heavy tobacco smoker (finding)</td>\n",
       "      <td>Detailed classification of a patient's smoking...</td>\n",
       "      <td>2.16.840.1.113883.11.20.9.41</td>\n",
       "      <td>2.16.840.1.113883.6.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321757</th>\n",
       "      <td>SNOMEDCT</td>\n",
       "      <td>Tobacco Use</td>\n",
       "      <td>43381005</td>\n",
       "      <td>Passive smoker (finding)</td>\n",
       "      <td>Detailed classification of a patient's smoking...</td>\n",
       "      <td>2.16.840.1.113883.11.20.9.41</td>\n",
       "      <td>2.16.840.1.113883.6.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Code System Value Set Name             Code  \\\n",
       "119273    SNOMEDCT        Problem         87739003   \n",
       "120806    SNOMEDCT        Problem          8517006   \n",
       "121365    SNOMEDCT        Problem          8392000   \n",
       "122262    SNOMEDCT        Problem         82302008   \n",
       "128896    SNOMEDCT        Problem        735128000   \n",
       "...            ...            ...              ...   \n",
       "321743    SNOMEDCT    Tobacco Use        266920004   \n",
       "321754    SNOMEDCT    Tobacco Use  428041000124106   \n",
       "321755    SNOMEDCT    Tobacco Use  428061000124105   \n",
       "321756    SNOMEDCT    Tobacco Use  428071000124103   \n",
       "321757    SNOMEDCT    Tobacco Use         43381005   \n",
       "\n",
       "                                              Description  \\\n",
       "119273                      Tolerant non-smoker (finding)   \n",
       "120806                                Ex-smoker (finding)   \n",
       "121365                               Non-smoker (finding)   \n",
       "122262                              Pipe smoker (finding)   \n",
       "128896           Ex-smoker for less than 1 year (finding)   \n",
       "...                                                   ...   \n",
       "321743  Trivial cigarette smoker (less than one cigare...   \n",
       "321754                Occasional tobacco smoker (finding)   \n",
       "321755                     Light tobacco smoker (finding)   \n",
       "321756                     Heavy tobacco smoker (finding)   \n",
       "321757                           Passive smoker (finding)   \n",
       "\n",
       "                                  Purpose: Clinical Focus  \\\n",
       "119273    A pathology or disorder identified in a patient   \n",
       "120806    A pathology or disorder identified in a patient   \n",
       "121365    A pathology or disorder identified in a patient   \n",
       "122262    A pathology or disorder identified in a patient   \n",
       "128896    A pathology or disorder identified in a patient   \n",
       "...                                                   ...   \n",
       "321743  Detailed classification of a patient's smoking...   \n",
       "321754  Detailed classification of a patient's smoking...   \n",
       "321755  Detailed classification of a patient's smoking...   \n",
       "321756  Detailed classification of a patient's smoking...   \n",
       "321757  Detailed classification of a patient's smoking...   \n",
       "\n",
       "                             Value Set OID         Code System OID  \n",
       "119273  2.16.840.1.113883.3.88.12.3221.7.4  2.16.840.1.113883.6.96  \n",
       "120806  2.16.840.1.113883.3.88.12.3221.7.4  2.16.840.1.113883.6.96  \n",
       "121365  2.16.840.1.113883.3.88.12.3221.7.4  2.16.840.1.113883.6.96  \n",
       "122262  2.16.840.1.113883.3.88.12.3221.7.4  2.16.840.1.113883.6.96  \n",
       "128896  2.16.840.1.113883.3.88.12.3221.7.4  2.16.840.1.113883.6.96  \n",
       "...                                    ...                     ...  \n",
       "321743        2.16.840.1.113883.11.20.9.41  2.16.840.1.113883.6.96  \n",
       "321754        2.16.840.1.113883.11.20.9.41  2.16.840.1.113883.6.96  \n",
       "321755        2.16.840.1.113883.11.20.9.41  2.16.840.1.113883.6.96  \n",
       "321756        2.16.840.1.113883.11.20.9.41  2.16.840.1.113883.6.96  \n",
       "321757        2.16.840.1.113883.11.20.9.41  2.16.840.1.113883.6.96  \n",
       "\n",
       "[78 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"/Users/hanna/openfn/ai_experiments/data/SNOMED-CT-Code-Value-Semantic-Set/SNOMED-CT-Code-Value-Semantic-Set.csv\"\n",
    "df = pd.read_csv(f)\n",
    "df_sample = df[df[\"Description\"].str.contains(\"smoker\")]\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code System</th>\n",
       "      <th>Value Set Name</th>\n",
       "      <th>Code</th>\n",
       "      <th>Description</th>\n",
       "      <th>Purpose: Clinical Focus</th>\n",
       "      <th>Value Set OID</th>\n",
       "      <th>Code System OID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119273</th>\n",
       "      <td>SNOMEDCT</td>\n",
       "      <td>Problem</td>\n",
       "      <td>87739003</td>\n",
       "      <td>Tolerant non-smoker (finding)</td>\n",
       "      <td>A pathology or disorder identified in a patient</td>\n",
       "      <td>2.16.840.1.113883.3.88.12.3221.7.4</td>\n",
       "      <td>2.16.840.1.113883.6.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120806</th>\n",
       "      <td>SNOMEDCT</td>\n",
       "      <td>Problem</td>\n",
       "      <td>8517006</td>\n",
       "      <td>Ex-smoker (finding)</td>\n",
       "      <td>A pathology or disorder identified in a patient</td>\n",
       "      <td>2.16.840.1.113883.3.88.12.3221.7.4</td>\n",
       "      <td>2.16.840.1.113883.6.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121365</th>\n",
       "      <td>SNOMEDCT</td>\n",
       "      <td>Problem</td>\n",
       "      <td>8392000</td>\n",
       "      <td>Non-smoker (finding)</td>\n",
       "      <td>A pathology or disorder identified in a patient</td>\n",
       "      <td>2.16.840.1.113883.3.88.12.3221.7.4</td>\n",
       "      <td>2.16.840.1.113883.6.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122262</th>\n",
       "      <td>SNOMEDCT</td>\n",
       "      <td>Problem</td>\n",
       "      <td>82302008</td>\n",
       "      <td>Pipe smoker (finding)</td>\n",
       "      <td>A pathology or disorder identified in a patient</td>\n",
       "      <td>2.16.840.1.113883.3.88.12.3221.7.4</td>\n",
       "      <td>2.16.840.1.113883.6.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128896</th>\n",
       "      <td>SNOMEDCT</td>\n",
       "      <td>Problem</td>\n",
       "      <td>735128000</td>\n",
       "      <td>Ex-smoker for less than 1 year (finding)</td>\n",
       "      <td>A pathology or disorder identified in a patient</td>\n",
       "      <td>2.16.840.1.113883.3.88.12.3221.7.4</td>\n",
       "      <td>2.16.840.1.113883.6.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321743</th>\n",
       "      <td>SNOMEDCT</td>\n",
       "      <td>Tobacco Use</td>\n",
       "      <td>266920004</td>\n",
       "      <td>Trivial cigarette smoker (less than one cigare...</td>\n",
       "      <td>Detailed classification of a patient's smoking...</td>\n",
       "      <td>2.16.840.1.113883.11.20.9.41</td>\n",
       "      <td>2.16.840.1.113883.6.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321754</th>\n",
       "      <td>SNOMEDCT</td>\n",
       "      <td>Tobacco Use</td>\n",
       "      <td>428041000124106</td>\n",
       "      <td>Occasional tobacco smoker (finding)</td>\n",
       "      <td>Detailed classification of a patient's smoking...</td>\n",
       "      <td>2.16.840.1.113883.11.20.9.41</td>\n",
       "      <td>2.16.840.1.113883.6.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321755</th>\n",
       "      <td>SNOMEDCT</td>\n",
       "      <td>Tobacco Use</td>\n",
       "      <td>428061000124105</td>\n",
       "      <td>Light tobacco smoker (finding)</td>\n",
       "      <td>Detailed classification of a patient's smoking...</td>\n",
       "      <td>2.16.840.1.113883.11.20.9.41</td>\n",
       "      <td>2.16.840.1.113883.6.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321756</th>\n",
       "      <td>SNOMEDCT</td>\n",
       "      <td>Tobacco Use</td>\n",
       "      <td>428071000124103</td>\n",
       "      <td>Heavy tobacco smoker (finding)</td>\n",
       "      <td>Detailed classification of a patient's smoking...</td>\n",
       "      <td>2.16.840.1.113883.11.20.9.41</td>\n",
       "      <td>2.16.840.1.113883.6.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321757</th>\n",
       "      <td>SNOMEDCT</td>\n",
       "      <td>Tobacco Use</td>\n",
       "      <td>43381005</td>\n",
       "      <td>Passive smoker (finding)</td>\n",
       "      <td>Detailed classification of a patient's smoking...</td>\n",
       "      <td>2.16.840.1.113883.11.20.9.41</td>\n",
       "      <td>2.16.840.1.113883.6.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Code System Value Set Name             Code  \\\n",
       "119273    SNOMEDCT        Problem         87739003   \n",
       "120806    SNOMEDCT        Problem          8517006   \n",
       "121365    SNOMEDCT        Problem          8392000   \n",
       "122262    SNOMEDCT        Problem         82302008   \n",
       "128896    SNOMEDCT        Problem        735128000   \n",
       "...            ...            ...              ...   \n",
       "321743    SNOMEDCT    Tobacco Use        266920004   \n",
       "321754    SNOMEDCT    Tobacco Use  428041000124106   \n",
       "321755    SNOMEDCT    Tobacco Use  428061000124105   \n",
       "321756    SNOMEDCT    Tobacco Use  428071000124103   \n",
       "321757    SNOMEDCT    Tobacco Use         43381005   \n",
       "\n",
       "                                              Description  \\\n",
       "119273                      Tolerant non-smoker (finding)   \n",
       "120806                                Ex-smoker (finding)   \n",
       "121365                               Non-smoker (finding)   \n",
       "122262                              Pipe smoker (finding)   \n",
       "128896           Ex-smoker for less than 1 year (finding)   \n",
       "...                                                   ...   \n",
       "321743  Trivial cigarette smoker (less than one cigare...   \n",
       "321754                Occasional tobacco smoker (finding)   \n",
       "321755                     Light tobacco smoker (finding)   \n",
       "321756                     Heavy tobacco smoker (finding)   \n",
       "321757                           Passive smoker (finding)   \n",
       "\n",
       "                                  Purpose: Clinical Focus  \\\n",
       "119273    A pathology or disorder identified in a patient   \n",
       "120806    A pathology or disorder identified in a patient   \n",
       "121365    A pathology or disorder identified in a patient   \n",
       "122262    A pathology or disorder identified in a patient   \n",
       "128896    A pathology or disorder identified in a patient   \n",
       "...                                                   ...   \n",
       "321743  Detailed classification of a patient's smoking...   \n",
       "321754  Detailed classification of a patient's smoking...   \n",
       "321755  Detailed classification of a patient's smoking...   \n",
       "321756  Detailed classification of a patient's smoking...   \n",
       "321757  Detailed classification of a patient's smoking...   \n",
       "\n",
       "                             Value Set OID         Code System OID  \n",
       "119273  2.16.840.1.113883.3.88.12.3221.7.4  2.16.840.1.113883.6.96  \n",
       "120806  2.16.840.1.113883.3.88.12.3221.7.4  2.16.840.1.113883.6.96  \n",
       "121365  2.16.840.1.113883.3.88.12.3221.7.4  2.16.840.1.113883.6.96  \n",
       "122262  2.16.840.1.113883.3.88.12.3221.7.4  2.16.840.1.113883.6.96  \n",
       "128896  2.16.840.1.113883.3.88.12.3221.7.4  2.16.840.1.113883.6.96  \n",
       "...                                    ...                     ...  \n",
       "321743        2.16.840.1.113883.11.20.9.41  2.16.840.1.113883.6.96  \n",
       "321754        2.16.840.1.113883.11.20.9.41  2.16.840.1.113883.6.96  \n",
       "321755        2.16.840.1.113883.11.20.9.41  2.16.840.1.113883.6.96  \n",
       "321756        2.16.840.1.113883.11.20.9.41  2.16.840.1.113883.6.96  \n",
       "321757        2.16.840.1.113883.11.20.9.41  2.16.840.1.113883.6.96  \n",
       "\n",
       "[88 rows x 7 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_random = df.sample(n=50)\n",
    "df_sample = pd.concat([df_sample[:10], df_sample])\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sample = \"/Users/hanna/openfn/ai_experiments/data/SNOMED-CT-Code-Value-Semantic-Set/SNOMED-CT-Code-Value-Semantic-Set_sample.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.to_csv(f_sample, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.read_csv(f_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '/Users/hanna/openfn/ai_experiments/data/SNOMED-CT-Code-Value-Semantic-Set/SNOMED-CT-Code-Value-Semantic-Set_sample.csv', 'row': 0, 'Code': '87739003'}, page_content='Value Set Name: Problem\\nDescription: Tolerant non-smoker (finding)\\nPurpose: Clinical Focus: A pathology or disorder identified in a patient')]\n"
     ]
    }
   ],
   "source": [
    "loader = CSVLoader(file_path=f_sample, content_columns=[\"Value Set Name\", \"Purpose: Clinical Focus\", \"Description\"], metadata_columns=[\"Code\"])\n",
    "data = loader.load()\n",
    "print(data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_store = create_vectorstore(\n",
    "    data,\n",
    "    collection_name=\"snomed_sample_smoker\",\n",
    "    vectorstore_type='zilliz',\n",
    "    embedding=\"openai\", \n",
    "    connection_args={\n",
    "        \"uri\": ZILLIZ_CLOUD_URI,\n",
    "        \"token\": ZILLIZ_CLOUD_API_KEY,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Value Set Name: Tobacco Use\\nDescription: Cigarette smoker (5-9 cigarettes/day) (finding)\\nPurpose: Clinical Focus: Detailed classification of a patient's smoking behavior\",\n",
       " \"Value Set Name: Tobacco Use\\nDescription: Moderate cigarette smoker (10-19 cigs/day) (finding)\\nPurpose: Clinical Focus: Detailed classification of a patient's smoking behavior\",\n",
       " \"Value Set Name: Tobacco Use\\nDescription: Cigarette smoker (1-4 cigarettes/day) (finding)\\nPurpose: Clinical Focus: Detailed classification of a patient's smoking behavior\",\n",
       " \"Value Set Name: Tobacco Use\\nDescription: Heavy cigarette smoker (20-39 cigs/day) (finding)\\nPurpose: Clinical Focus: Detailed classification of a patient's smoking behavior\",\n",
       " 'Value Set Name: Problem\\nDescription: Cigarette smoker (1-4 cigarettes/day) (finding)\\nPurpose: Clinical Focus: A pathology or disorder identified in a patient']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"current_smoker\".replace(\"_\", \" \")\n",
    "result = get_similar_texts(input_text, new_store, search_type=\"similarity\", search_kwargs={\"k\":5})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y3/tg4ts42x7bl1ty6zww9fx4bh0000gn/T/ipykernel_71987/1475622878.py:1: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/Users/hanna/openfn/ai_experiments/data/LOINC-Clinical-Terminology/LoincTableCore.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOINC_NUM</th>\n",
       "      <th>COMPONENT</th>\n",
       "      <th>PROPERTY</th>\n",
       "      <th>TIME_ASPCT</th>\n",
       "      <th>SYSTEM</th>\n",
       "      <th>SCALE_TYP</th>\n",
       "      <th>METHOD_TYP</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>CLASSTYPE</th>\n",
       "      <th>LONG_COMMON_NAME</th>\n",
       "      <th>SHORTNAME</th>\n",
       "      <th>EXTERNAL_COPYRIGHT_NOTICE</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>VersionFirstReleased</th>\n",
       "      <th>VersionLastChanged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32925</th>\n",
       "      <td>39243-1</td>\n",
       "      <td>Second hand smoke exposure</td>\n",
       "      <td>Arb</td>\n",
       "      <td>Pt</td>\n",
       "      <td>^Patient</td>\n",
       "      <td>Ord</td>\n",
       "      <td>CPHS</td>\n",
       "      <td>ATTACH.CPHS</td>\n",
       "      <td>3</td>\n",
       "      <td>Second hand smoke exposure CPHS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58482</th>\n",
       "      <td>62525-1</td>\n",
       "      <td>PhenX measure - environmental exposures - curr...</td>\n",
       "      <td>-</td>\n",
       "      <td>Pt</td>\n",
       "      <td>^Patient</td>\n",
       "      <td>-</td>\n",
       "      <td>PhenX</td>\n",
       "      <td>PANEL.PHENX</td>\n",
       "      <td>2</td>\n",
       "      <td>Deprecated PhenX measure - environmental expos...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEPRECATED</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58483</th>\n",
       "      <td>62526-9</td>\n",
       "      <td>PhenX - environmental exposures - current envi...</td>\n",
       "      <td>-</td>\n",
       "      <td>Pt</td>\n",
       "      <td>^Patient</td>\n",
       "      <td>-</td>\n",
       "      <td>PhenX</td>\n",
       "      <td>PANEL.PHENX</td>\n",
       "      <td>2</td>\n",
       "      <td>PhenX - environmental exposures - current envi...</td>\n",
       "      <td>Environ exp tobacco smoke proto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRIAL</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58512</th>\n",
       "      <td>62552-5</td>\n",
       "      <td>PhenX measure - tobacco - smoking status</td>\n",
       "      <td>-</td>\n",
       "      <td>Pt</td>\n",
       "      <td>^Patient</td>\n",
       "      <td>-</td>\n",
       "      <td>PhenX</td>\n",
       "      <td>PANEL.PHENX</td>\n",
       "      <td>2</td>\n",
       "      <td>Deprecated PhenX measure - tobacco - smoking s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEPRECATED</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58513</th>\n",
       "      <td>62553-3</td>\n",
       "      <td>PhenX - tobacco - smoking status - adolescent ...</td>\n",
       "      <td>-</td>\n",
       "      <td>Pt</td>\n",
       "      <td>^Patient</td>\n",
       "      <td>-</td>\n",
       "      <td>PhenX</td>\n",
       "      <td>PANEL.PHENX</td>\n",
       "      <td>2</td>\n",
       "      <td>PhenX - tobacco - smoking status - adolescent ...</td>\n",
       "      <td>Tobac smok status adoles proto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRIAL</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83847</th>\n",
       "      <td>8604-1</td>\n",
       "      <td>Class</td>\n",
       "      <td>Type</td>\n",
       "      <td>Pt</td>\n",
       "      <td>Pacemaker</td>\n",
       "      <td>Nom</td>\n",
       "      <td>EKG</td>\n",
       "      <td>DEVICES</td>\n",
       "      <td>2</td>\n",
       "      <td>Type of Pacemaker by EKG</td>\n",
       "      <td>Pacemaker Class EKG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>1.0h(3)</td>\n",
       "      <td>2.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>10864-7</td>\n",
       "      <td>Immune complex</td>\n",
       "      <td>ACnc</td>\n",
       "      <td>Pt</td>\n",
       "      <td>Ser/Plas</td>\n",
       "      <td>Qn</td>\n",
       "      <td>Raji cell assay</td>\n",
       "      <td>SERO</td>\n",
       "      <td>1</td>\n",
       "      <td>Immune complex [Units/volume] in Serum or Plas...</td>\n",
       "      <td>IC SerPl Raji Cell-aCnc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>1.0j-a</td>\n",
       "      <td>2.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80350</th>\n",
       "      <td>82595-0</td>\n",
       "      <td>Blood velocity-time integral.A wave</td>\n",
       "      <td>Len</td>\n",
       "      <td>Pt</td>\n",
       "      <td>Mitral valve.leaflet.tip</td>\n",
       "      <td>Qn</td>\n",
       "      <td>US.doppler</td>\n",
       "      <td>CARD.US</td>\n",
       "      <td>2</td>\n",
       "      <td>Mitral valve leaflet tip Velocity-time integra...</td>\n",
       "      <td>MV leaf tip VTI A-wave DOP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76952</th>\n",
       "      <td>7952-5</td>\n",
       "      <td>Legionella pneumophila 5 Ab</td>\n",
       "      <td>Titr</td>\n",
       "      <td>Pt</td>\n",
       "      <td>Ser</td>\n",
       "      <td>Qn</td>\n",
       "      <td>IF</td>\n",
       "      <td>MICRO</td>\n",
       "      <td>1</td>\n",
       "      <td>Legionella pneumophila 5 Ab [Titer] in Serum b...</td>\n",
       "      <td>L pneumo5 Ab Titr Ser IF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>1.0h(2)</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6208</th>\n",
       "      <td>14729-8</td>\n",
       "      <td>Flurazepam</td>\n",
       "      <td>SCnc</td>\n",
       "      <td>Pt</td>\n",
       "      <td>Ser/Plas</td>\n",
       "      <td>Qn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DRUG/TOX</td>\n",
       "      <td>1</td>\n",
       "      <td>Flurazepam [Moles/volume] in Serum or Plasma</td>\n",
       "      <td>Flurazepam SerPl-sCnc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>1.0k</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LOINC_NUM                                          COMPONENT PROPERTY  \\\n",
       "32925   39243-1                         Second hand smoke exposure      Arb   \n",
       "58482   62525-1  PhenX measure - environmental exposures - curr...        -   \n",
       "58483   62526-9  PhenX - environmental exposures - current envi...        -   \n",
       "58512   62552-5           PhenX measure - tobacco - smoking status        -   \n",
       "58513   62553-3  PhenX - tobacco - smoking status - adolescent ...        -   \n",
       "...         ...                                                ...      ...   \n",
       "83847    8604-1                                              Class     Type   \n",
       "1926    10864-7                                     Immune complex     ACnc   \n",
       "80350   82595-0                Blood velocity-time integral.A wave      Len   \n",
       "76952    7952-5                        Legionella pneumophila 5 Ab     Titr   \n",
       "6208    14729-8                                         Flurazepam     SCnc   \n",
       "\n",
       "      TIME_ASPCT                    SYSTEM SCALE_TYP       METHOD_TYP  \\\n",
       "32925         Pt                  ^Patient       Ord             CPHS   \n",
       "58482         Pt                  ^Patient         -            PhenX   \n",
       "58483         Pt                  ^Patient         -            PhenX   \n",
       "58512         Pt                  ^Patient         -            PhenX   \n",
       "58513         Pt                  ^Patient         -            PhenX   \n",
       "...          ...                       ...       ...              ...   \n",
       "83847         Pt                 Pacemaker       Nom              EKG   \n",
       "1926          Pt                  Ser/Plas        Qn  Raji cell assay   \n",
       "80350         Pt  Mitral valve.leaflet.tip        Qn       US.doppler   \n",
       "76952         Pt                       Ser        Qn               IF   \n",
       "6208          Pt                  Ser/Plas        Qn              NaN   \n",
       "\n",
       "             CLASS  CLASSTYPE  \\\n",
       "32925  ATTACH.CPHS          3   \n",
       "58482  PANEL.PHENX          2   \n",
       "58483  PANEL.PHENX          2   \n",
       "58512  PANEL.PHENX          2   \n",
       "58513  PANEL.PHENX          2   \n",
       "...            ...        ...   \n",
       "83847      DEVICES          2   \n",
       "1926          SERO          1   \n",
       "80350      CARD.US          2   \n",
       "76952        MICRO          1   \n",
       "6208      DRUG/TOX          1   \n",
       "\n",
       "                                        LONG_COMMON_NAME  \\\n",
       "32925                    Second hand smoke exposure CPHS   \n",
       "58482  Deprecated PhenX measure - environmental expos...   \n",
       "58483  PhenX - environmental exposures - current envi...   \n",
       "58512  Deprecated PhenX measure - tobacco - smoking s...   \n",
       "58513  PhenX - tobacco - smoking status - adolescent ...   \n",
       "...                                                  ...   \n",
       "83847                           Type of Pacemaker by EKG   \n",
       "1926   Immune complex [Units/volume] in Serum or Plas...   \n",
       "80350  Mitral valve leaflet tip Velocity-time integra...   \n",
       "76952  Legionella pneumophila 5 Ab [Titer] in Serum b...   \n",
       "6208        Flurazepam [Moles/volume] in Serum or Plasma   \n",
       "\n",
       "                             SHORTNAME EXTERNAL_COPYRIGHT_NOTICE      STATUS  \\\n",
       "32925                              NaN                       NaN      ACTIVE   \n",
       "58482                              NaN                       NaN  DEPRECATED   \n",
       "58483  Environ exp tobacco smoke proto                       NaN       TRIAL   \n",
       "58512                              NaN                       NaN  DEPRECATED   \n",
       "58513   Tobac smok status adoles proto                       NaN       TRIAL   \n",
       "...                                ...                       ...         ...   \n",
       "83847              Pacemaker Class EKG                       NaN      ACTIVE   \n",
       "1926           IC SerPl Raji Cell-aCnc                       NaN      ACTIVE   \n",
       "80350       MV leaf tip VTI A-wave DOP                       NaN      ACTIVE   \n",
       "76952         L pneumo5 Ab Titr Ser IF                       NaN      ACTIVE   \n",
       "6208             Flurazepam SerPl-sCnc                       NaN      ACTIVE   \n",
       "\n",
       "      VersionFirstReleased VersionLastChanged  \n",
       "32925                 2.15               2.27  \n",
       "58482                 2.36               2.46  \n",
       "58483                 2.36               2.66  \n",
       "58512                 2.36               2.46  \n",
       "58513                 2.36               2.66  \n",
       "...                    ...                ...  \n",
       "83847              1.0h(3)               2.72  \n",
       "1926                1.0j-a               2.73  \n",
       "80350                 2.58               2.58  \n",
       "76952              1.0h(2)                2.7  \n",
       "6208                  1.0k               2.34  \n",
       "\n",
       "[242 rows x 15 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/hanna/openfn/ai_experiments/data/LOINC-Clinical-Terminology/LoincTableCore.csv')\n",
    "loinc_smoke = df[df[\"COMPONENT\"].str.contains(\"smok\")]\n",
    "loinc_sample = df.sample(n=70)\n",
    "df_sample = pd.concat([loinc_smoke, loinc_sample])\n",
    "df_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "loinc_sample_f = \"/Users/hanna/openfn/ai_experiments/data/LOINC-Clinical-Terminology/loinc_sample_smoker.csv\"\n",
    "df_sample.to_csv(loinc_sample_f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Zilliz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Value Set Name: Tobacco Use\\nDescription: Cigarette smoker (5-9 cigarettes/day) (finding)\\nPurpose: Clinical Focus: Detailed classification of a patient's smoking behavior\",\n",
       " \"Value Set Name: Tobacco Use\\nDescription: Moderate cigarette smoker (10-19 cigs/day) (finding)\\nPurpose: Clinical Focus: Detailed classification of a patient's smoking behavior\",\n",
       " \"Value Set Name: Tobacco Use\\nDescription: Cigarette smoker (1-4 cigarettes/day) (finding)\\nPurpose: Clinical Focus: Detailed classification of a patient's smoking behavior\",\n",
       " \"Value Set Name: Tobacco Use\\nDescription: Heavy cigarette smoker (20-39 cigs/day) (finding)\\nPurpose: Clinical Focus: Detailed classification of a patient's smoking behavior\"]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"current_smoker\".replace(\"_\", \" \")\n",
    "result = get_similar_texts(input_text, new_store, search_type=\"similarity\", search_kwargs={\"score_threshold\":0.99})\n",
    "# result = get_similar_texts(input_text, new_store, search_type=\"similarity\", search_kwargs={\"k\":2})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblabla\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mget_similar_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msimilarity_score_threshold\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore_threshold\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0.99\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# result = get_similar_texts(input_text, new_store, search_type=\"similarity\", search_kwargs={\"k\":2})\u001b[39;00m\n\u001b[1;32m      5\u001b[0m result\n",
      "Cell \u001b[0;32mIn[64], line 15\u001b[0m, in \u001b[0;36mget_similar_texts\u001b[0;34m(input_text, vectorstore, search_type, search_kwargs)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mRetrieve similar texts from a vectorstore based on input text.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    List of page contents of the most similar documents\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vectorstore\u001b[38;5;241m.\u001b[39mas_retriever(search_type\u001b[38;5;241m=\u001b[39msearch_type, search_kwargs\u001b[38;5;241m=\u001b[39msearch_kwargs)\n\u001b[0;32m---> 15\u001b[0m retrieved_docs \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [t\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m retrieved_docs]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_core/retrievers.py:254\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    253\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    256\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[1;32m    257\u001b[0m         result,\n\u001b[1;32m    258\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_core/retrievers.py:247\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[0;32m--> 247\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_core/vectorstores/base.py:1083\u001b[0m, in \u001b[0;36mVectorStoreRetriever._get_relevant_documents\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m   1080\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39msimilarity_search(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_kwargs)\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity_score_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1082\u001b[0m     docs_and_similarities \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1083\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_relevance_scores\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m            \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_kwargs\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1086\u001b[0m     )\n\u001b[1;32m   1087\u001b[0m     docs \u001b[38;5;241m=\u001b[39m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_similarities]\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_core/vectorstores/base.py:560\u001b[0m, in \u001b[0;36mVectorStore.similarity_search_with_relevance_scores\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return docs and relevance scores in the range [0, 1].\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \n\u001b[1;32m    546\u001b[0m \u001b[38;5;124;03m0 is dissimilar, 1 is most similar.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;124;03m    List of Tuples of (doc, similarity_score).\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    558\u001b[0m score_threshold \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 560\u001b[0m docs_and_similarities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_similarity_search_with_relevance_scores\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    564\u001b[0m     similarity \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m similarity \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, similarity \u001b[38;5;129;01min\u001b[39;00m docs_and_similarities\n\u001b[1;32m    566\u001b[0m ):\n\u001b[1;32m    567\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    568\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRelevance scores must be between\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m 0 and 1, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocs_and_similarities\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    570\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    571\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_core/vectorstores/base.py:507\u001b[0m, in \u001b[0;36mVectorStore._similarity_search_with_relevance_scores\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_similarity_search_with_relevance_scores\u001b[39m(\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    486\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    487\u001b[0m     k: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    489\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[Document, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[1;32m    490\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;124;03m    Default similarity search with relevance scores. Modify if necessary\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;124;03m    in subclass.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;124;03m        List of Tuples of (doc, similarity_score)\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m     relevance_score_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select_relevance_score_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m     docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity_search_with_score(query, k, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [(doc, relevance_score_fn(score)) \u001b[38;5;28;01mfor\u001b[39;00m doc, score \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_core/vectorstores/base.py:448\u001b[0m, in \u001b[0;36mVectorStore._select_relevance_score_fn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_select_relevance_score_fn\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Callable[[\u001b[38;5;28mfloat\u001b[39m], \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    438\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;124;03m    The 'correct' relevance function\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m    may differ depending on a few things, including:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;124;03m    Vectorstores should define their own selection-based method of relevance.\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_text = \"blabla\".replace(\"_\", \" \")\n",
    "result = get_similar_texts(input_text, new_store, search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\":0.99})\n",
    "# result = get_similar_texts(input_text, new_store, search_type=\"similarity\", search_kwargs={\"k\":2})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class VectorStoreManager:\n",
    "#     \"\"\"\n",
    "#     Manages vector store operations including creation, retrieval, and similarity searches.\n",
    "    \n",
    "#     Args:\n",
    "#         collection_name (str): Name of the vector collection\n",
    "#         vectorstore_type (str): Type of vector store (e.g., 'zilliz')\n",
    "#         embedding_type (str): Type of embedding model (e.g., 'openai')\n",
    "#         connection_args (dict): Connection arguments for the vector store\n",
    "#         auto_id (bool): Whether to automatically generate IDs\n",
    "#     \"\"\"\n",
    "#     def __init__(self, collection_name='LangChainCollection', vectorstore_type='zilliz', \n",
    "#                  embedding_type='openai', connection_args=None, auto_id=True):\n",
    "#         self.collection_name = collection_name\n",
    "#         self.vectorstore_type = vectorstore_type.lower()\n",
    "#         self.embedding_type = embedding_type.lower()\n",
    "#         self.connection_args = connection_args\n",
    "#         self.auto_id = auto_id\n",
    "        \n",
    "#         self.embedding_classes = {\n",
    "#             'openai': OpenAIEmbeddings\n",
    "#         }\n",
    "        \n",
    "#         self.vectorstore_classes = {\n",
    "#             'zilliz': Zilliz\n",
    "#         }\n",
    "        \n",
    "#         self.embedding_function = self._get_embedding_class()\n",
    "#         self.VectorStoreClass = self._get_vectorstore_class()\n",
    "    \n",
    "#     def _get_embedding_class(self):\n",
    "#         \"\"\"Get embedding class based on the specified type.\"\"\"\n",
    "#         try:\n",
    "#             EmbeddingClass = self.embedding_classes[self.embedding_type]\n",
    "#             return EmbeddingClass()\n",
    "#         except KeyError:\n",
    "#             raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
    "    \n",
    "#     def _get_vectorstore_class(self):\n",
    "#         \"\"\"Get vectorstore class based on the specified type.\"\"\"\n",
    "#         try:\n",
    "#             return self.vectorstore_classes[self.vectorstore_type]\n",
    "#         except KeyError:\n",
    "#             raise ValueError(f\"Unsupported vectorstore type: {self.vectorstore_type}\")\n",
    "    \n",
    "#     def create_store(self, docs, drop_old=True, **kwargs):\n",
    "#         \"\"\"\n",
    "#         Create a new vectorstore from documents and initialise it with the specified settings.\n",
    "        \n",
    "#         Args:\n",
    "#             docs: List of documents to add to the vectorstore\n",
    "#             collection_name: Name of the collection to create (default: 'LangChainCollection')\n",
    "#             vectorstore_type: Type of vectorstore to create (e.g. 'zilliz')\n",
    "#             embedding: Type of embedding model to use (e.g. 'openai')\n",
    "#             connection_args: Connection arguments for the vectorstore if needed(e.g. URI, API key)\n",
    "#             auto_id: Whether to automatically generate IDs (default: True)\n",
    "#             drop_old: Whether to drop existing collection if it exists (default: True)\n",
    "#             **kwargs: Additional arguments passed to vectorstore initialisation\n",
    "            \n",
    "#         Returns:\n",
    "#             Initialised vectorstore containing the input documents\n",
    "#         \"\"\"\n",
    "#         store_kwargs = {\n",
    "#             'collection_name': self.collection_name,\n",
    "#             **kwargs\n",
    "#         }\n",
    "#         if self.connection_args:\n",
    "#             store_kwargs['connection_args'] = self.connection_args\n",
    "            \n",
    "#         return self.VectorStoreClass.from_documents(\n",
    "#             documents=docs,\n",
    "#             embedding=self.embedding_function,\n",
    "#             auto_id=self.auto_id,\n",
    "#             drop_old=drop_old,\n",
    "#             **store_kwargs\n",
    "#         )\n",
    "    \n",
    "#     def get_store(self, **kwargs):\n",
    "#         \"\"\"\n",
    "#         Get an existing vectorstore collection and configure it with specified settings.\n",
    "        \n",
    "#         Args:\n",
    "#             collection_name: Name of the collection to retrieve (default: 'LangChainCollection')\n",
    "#             vectorstore_type: Type of vectorstore to connect to (e.g. 'zilliz')\n",
    "#             embedding: Type of embedding model to use (e.g. 'openai') \n",
    "#             connection_args: Connection arguments for the vectorstore (e.g. URI, API key)\n",
    "#             auto_id: Whether to automatically generate IDs (default: True)\n",
    "#             **kwargs: Additional arguments passed to vectorstore initialisation\n",
    "\n",
    "#         Returns:\n",
    "#             Connected vectorstore instance with specified configuration\n",
    "#         \"\"\"\n",
    "#         store_kwargs = {\n",
    "#             'collection_name': self.collection_name,\n",
    "#             **kwargs\n",
    "#         }\n",
    "#         if self.connection_args:\n",
    "#             store_kwargs['connection_args'] = self.connection_args\n",
    "            \n",
    "#         return self.VectorStoreClass(\n",
    "#             embedding_function=self.embedding_function,\n",
    "#             auto_id=self.auto_id,\n",
    "#             **store_kwargs\n",
    "#         )\n",
    "    \n",
    "#     def get_similar_texts(self, input_text, vectorstore, search_type=\"similarity\", search_kwargs={\"k\": 2}):\n",
    "#         \"\"\"\n",
    "#         Retrieve similar texts from a vectorstore based on input text.\n",
    "        \n",
    "#         Args:\n",
    "#             input_text: Text string to use for similarity search\n",
    "#             vectorstore: Vectorstore to search in\n",
    "#             search_type: Type of search to perform (default is 'similarity'; others e.g 'similarity_score_threshold')\n",
    "#             search_kwargs: Additional arguments for the search (default retrieves top 2 results)\n",
    "        \n",
    "#         Returns:\n",
    "#             List of page contents of the most similar documents\n",
    "#         \"\"\"\n",
    "#         retriever = vectorstore.as_retriever(search_type=search_type, search_kwargs=search_kwargs)\n",
    "#         retrieved_docs = retriever.invoke(input_text)\n",
    "#         return [t.page_content for t in retrieved_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanna/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "from dataclasses import dataclass, asdict\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import Zilliz\n",
    "from langchain_pinecone import Pinecone\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "    \"\"\"\n",
    "    Dataclass for VectorStore search results.\n",
    "    \"\"\"\n",
    "    text: str\n",
    "    metadata: dict\n",
    "    score: float = None\n",
    "    \n",
    "    def to_json(self):\n",
    "        return {k: v for k, v in asdict(self).items()}\n",
    "\n",
    "class VectorStore:\n",
    "    \"\"\"\n",
    "    Manages vector embeddings and similarity searches for document collections.\n",
    "    \n",
    "    Args:\n",
    "        collection_name (str): Name of the vector collection\n",
    "        vectorstore_type (str): Type of vector store (e.g., 'zilliz')\n",
    "        embedding_type (str): Type of embedding model (e.g., 'openai')\n",
    "        connection_args (dict): Connection arguments for the vector store\n",
    "    \"\"\"\n",
    "\n",
    "    EMBEDDING_CLASSES = {\n",
    "        'openai': OpenAIEmbeddings\n",
    "    }\n",
    "    VECTORSTORE_CLASSES = {\n",
    "        'zilliz': Zilliz,\n",
    "        'pinecone': Pinecone\n",
    "    }\n",
    "\n",
    "    def __init__(self, collection_name='LangChainCollection', vectorstore_type='zilliz', \n",
    "                 embedding_type='openai', connection_args=None, index_name=None):\n",
    "        self.collection_name = collection_name\n",
    "        self.vectorstore_type = vectorstore_type.lower()\n",
    "        self.embedding_type = embedding_type.lower()\n",
    "        self.connection_args = connection_args\n",
    "        self.index_name = index_name\n",
    "        self.embedding_function = self._get_embedding_class()\n",
    "        self.store_kwargs_mappings = {\n",
    "            'zilliz': {'collection_name': self.collection_name,'connection_args':self.connection_args, 'drop_old': True, 'auto_id':True},\n",
    "            'pinecone': {'namespace': self.collection_name, 'index_name': self.index_name},\n",
    "        }\n",
    "        self.search_init_kwargs_mappings = {\n",
    "            'zilliz': {'embedding_function': self.embedding_function, 'collection_name': self.collection_name, 'connection_args':self.connection_args},\n",
    "            'pinecone': {'embedding': self.embedding_function, 'namespace': self.collection_name, 'index_name': self.index_name},\n",
    "        }\n",
    "        self.VectorStoreClass = self._get_vectorstore_class()\n",
    "        self.store_kwargs = self._get_vectorstore_kwargs()\n",
    "        self.search_init_kwargs = self._get_search_init_kwargs()\n",
    "    \n",
    "    def _get_embedding_class(self):\n",
    "        \"\"\"Get embedding class based on the specified type.\"\"\"\n",
    "        try:\n",
    "            EmbeddingClass = VectorStore.EMBEDDING_CLASSES[self.embedding_type]\n",
    "            return EmbeddingClass()\n",
    "        except KeyError:\n",
    "            raise ValueError(f\"Unsupported embedding type: {self.embedding_type}\")\n",
    "    \n",
    "    def _get_vectorstore_class(self):\n",
    "        \"\"\"Get vectorstore class based on the specified type.\"\"\"\n",
    "        try:\n",
    "            return VectorStore.VECTORSTORE_CLASSES[self.vectorstore_type]\n",
    "        except KeyError:\n",
    "            raise ValueError(f\"Unsupported vectorstore type: {self.vectorstore_type}\")\n",
    "    \n",
    "    def _get_vectorstore_kwargs(self):\n",
    "        \"\"\"Get vectorstore settings based on the specified type.\"\"\"\n",
    "        try:\n",
    "            return self.store_kwargs_mappings[self.vectorstore_type]\n",
    "        except KeyError:\n",
    "            raise ValueError(f\"Unsupported vectorstore type: {self.vectorstore_type}\")\n",
    "        \n",
    "    def _get_search_init_kwargs(self):\n",
    "        \"\"\"Get vectorstore settings based on the specified type.\"\"\"\n",
    "        try:\n",
    "            return self.search_init_kwargs_mappings[self.vectorstore_type]\n",
    "        except KeyError:\n",
    "            raise ValueError(f\"Unsupported vectorstore type: {self.vectorstore_type}\")  \n",
    "    \n",
    "    \n",
    "    def add_docs(self, docs, **kwargs):\n",
    "        \"\"\"\n",
    "        Create a new collection from documents and initialise it with the specified settings.\n",
    "        \n",
    "        Args:\n",
    "            docs: List of documents to add to the vectorstore\n",
    "            drop_old: Whether to drop existing collection if it exists (default: True)\n",
    "            **kwargs: Additional arguments passed to vectorstore initialisation\n",
    "            \n",
    "        Returns:\n",
    "            Initialised vectorstore containing the input documents\n",
    "        \"\"\"\n",
    "\n",
    "        return self.VectorStoreClass.from_documents(\n",
    "            documents=docs,\n",
    "            embedding=self.embedding_function,\n",
    "            **self.store_kwargs,\n",
    "        )\n",
    "    \n",
    "    def search(self, input_text, search_type=\"similarity\", search_kwargs={\"k\": 2}):\n",
    "        \"\"\"\n",
    "        Retrieve similar texts from a vectorstore based on input text.\n",
    "        \n",
    "        Args:\n",
    "            input_text: Text string to use for similarity search\n",
    "            search_type: Type of search to perform (default is 'similarity'; others e.g 'similarity_score_threshold')\n",
    "            search_kwargs: Additional arguments for the search (default retrieves top 2 results, and uses no filter)\n",
    "        \n",
    "        Returns:\n",
    "            List of page contents of the most similar documents\n",
    "        \"\"\"\n",
    "        store = self.VectorStoreClass(\n",
    "            **self.search_init_kwargs,\n",
    "        )\n",
    "        retriever = store.as_retriever(search_type=search_type, search_kwargs=search_kwargs)\n",
    "        retrieved_docs = retriever.invoke(input_text)\n",
    "        retrieved_texts = [t.page_content for t in retrieved_docs]\n",
    "\n",
    "        if not retrieved_texts:\n",
    "            warnings.warn(\n",
    "                f\"\\nNo results found. This could mean:\\n\"\n",
    "                f\"1. Collection '{self.collection_name}' doesn't exist (run add_docs first)\\n\"\n",
    "                f\"2. No similar documents found (check the input or the search criteria)\\n\"\n",
    "                f\"3. Connection issues\"\n",
    "        )\n",
    "            return None\n",
    "        else:\n",
    "            results = []\n",
    "            metadata_dicts = [t.metadata for t in retrieved_docs]\n",
    "\n",
    "            for text, metadata in zip(retrieved_texts, metadata_dicts):\n",
    "                results.append(SearchResult(text, metadata))\n",
    "            \n",
    "            return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_pinecone import Pinecone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PINECONE_KEY = os.getenv(\"PINECONE_KEY\")\n",
    "    # os.environ['PINECONE_API_KEY'] = '<YOUR_PINECONE_API_KEY>'\n",
    "# PINECONE_API_KEY = os.getenv(\"PINECONE_KEY\")\n",
    "os.environ['PINECONE_API_KEY'] =  os.getenv(\"PINECONE_KEY\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SearchResult(text='Oh no worries! Bye', metadata={'seq_num': 2.0, 'source': '/Users/hanna/openfn/ai_experiments/data/example.json'}, score=None),\n",
       " SearchResult(text='Bye!', metadata={'seq_num': 1.0, 'source': '/Users/hanna/openfn/ai_experiments/data/example.json'}, score=None)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pinecone example \n",
    "pc_store = VectorStore(\n",
    "    collection_name=\"snomed_sample_smoker\",\n",
    "    index_name=\"apollo-mappings\",\n",
    "    vectorstore_type=\"pinecone\",\n",
    "    embedding_type=\"openai\"\n",
    ")\n",
    "pc_store.add_docs(docs)\n",
    "pc_store.search(\"worry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SearchResult(text='Oh no worries! Bye', metadata={'seq_num': 2.0, 'source': '/Users/hanna/openfn/ai_experiments/data/example.json'}, score=None),\n",
       " SearchResult(text='Bye!', metadata={'seq_num': 1.0, 'source': '/Users/hanna/openfn/ai_experiments/data/example.json'}, score=None)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_store.search(\"worry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SearchResult(text='Oh no worries! Bye', metadata={'seq_num': 2.0, 'source': '/Users/hanna/openfn/ai_experiments/data/example.json'}, score=None)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retriever = vector_store.as_retriever(\n",
    "#     search_type=\"similarity_score_threshold\",\n",
    "#     search_kwargs={\"k\": 1, \"score_threshold\": 0.5}\n",
    "pc_store.search(\"worry\", search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.88})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPC error: [create_collection], <MilvusException: (code=65535, message=duplicated field name)>, <Time:{'RPC start': '2024-12-11 14:50:12.115789', 'RPC error': '2024-12-11 14:50:12.314071'}>\n",
      "Failed to create collection: test3 error: <MilvusException: (code=65535, message=duplicated field name)>\n"
     ]
    },
    {
     "ename": "MilvusException",
     "evalue": "<MilvusException: (code=65535, message=duplicated field name)>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMilvusException\u001b[0m                           Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[35], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m zilliz_store \u001b[38;5;241m=\u001b[39m VectorStore(\n\u001b[1;32m      3\u001b[0m         collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m         vectorstore_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzilliz\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m         }\n\u001b[1;32m     10\u001b[0m     )\n\u001b[0;32m---> 11\u001b[0m \u001b[43mzilliz_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m zilliz_store\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworry\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[33], line 117\u001b[0m, in \u001b[0;36mVectorStore.add_docs\u001b[0;34m(self, docs, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03mCreate a new collection from documents and initialise it with the specified settings.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m    Initialised vectorstore containing the input documents\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVectorStoreClass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_core/vectorstores/base.py:852\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ids\n\u001b[0;32m--> 852\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_community/vectorstores/zilliz.py:195\u001b[0m, in \u001b[0;36mZilliz.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, collection_name, connection_args, consistency_level, index_params, search_params, drop_old, ids, auto_id, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m vector_db \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m    185\u001b[0m     embedding_function\u001b[38;5;241m=\u001b[39membedding,\n\u001b[1;32m    186\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    194\u001b[0m )\n\u001b[0;32m--> 195\u001b[0m \u001b[43mvector_db\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vector_db\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_community/vectorstores/milvus.py:581\u001b[0m, in \u001b[0;36mMilvus.add_texts\u001b[0;34m(self, texts, metadatas, timeout, batch_size, ids, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout\n\u001b[0;32m--> 581\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;66;03m# Dict to hold all insert columns\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_community/vectorstores/milvus.py:300\u001b[0m, in \u001b[0;36mMilvus._init\u001b[0;34m(self, embeddings, metadatas, partition_names, replica_number, timeout)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_fields()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_community/vectorstores/milvus.py:411\u001b[0m, in \u001b[0;36mMilvus._create_collection\u001b[0;34m(self, embeddings, metadatas)\u001b[0m\n\u001b[1;32m    408\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to create collection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m error: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollection_name, e\n\u001b[1;32m    410\u001b[0m )\n\u001b[0;32m--> 411\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_community/vectorstores/milvus.py:398\u001b[0m, in \u001b[0;36mMilvus._create_collection\u001b[0;34m(self, embeddings, metadatas)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol \u001b[38;5;241m=\u001b[39m \u001b[43mCollection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsistency_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconsistency_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43musing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;66;03m# Set the collection properties if they exist\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pymilvus/orm/collection.py:150\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[0;34m(self, name, schema, using, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m consistency_level \u001b[38;5;241m=\u001b[39m get_consistency_level(\n\u001b[1;32m    147\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsistency_level\u001b[39m\u001b[38;5;124m\"\u001b[39m, DEFAULT_CONSISTENCY_LEVEL)\n\u001b[1;32m    148\u001b[0m )\n\u001b[0;32m--> 150\u001b[0m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema \u001b[38;5;241m=\u001b[39m schema\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pymilvus/decorators.py:148\u001b[0m, in \u001b[0;36merror_handler.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC error: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, <Time:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord_dict\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mFutureTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pymilvus/decorators.py:144\u001b[0m, in \u001b[0;36merror_handler.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC start\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MilvusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pymilvus/decorators.py:183\u001b[0m, in \u001b[0;36mtracing_request.<locals>.wrapper.<locals>.handler\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_onetime_request_id(req_id)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pymilvus/decorators.py:123\u001b[0m, in \u001b[0;36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 123\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pymilvus/decorators.py:87\u001b[0m, in \u001b[0;36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# Do not retry on these codes\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pymilvus/client/grpc_handler.py:308\u001b[0m, in \u001b[0;36mGrpcHandler.create_collection\u001b[0;34m(self, collection_name, fields, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m status \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m--> 308\u001b[0m \u001b[43mcheck_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pymilvus/client/utils.py:63\u001b[0m, in \u001b[0;36mcheck_status\u001b[0;34m(status)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m status\u001b[38;5;241m.\u001b[39merror_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MilvusException(status\u001b[38;5;241m.\u001b[39mcode, status\u001b[38;5;241m.\u001b[39mreason, status\u001b[38;5;241m.\u001b[39merror_code)\n",
      "\u001b[0;31mMilvusException\u001b[0m: <MilvusException: (code=65535, message=duplicated field name)>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMilvusException\u001b[0m                           Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[35], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m zilliz_store \u001b[38;5;241m=\u001b[39m VectorStore(\n\u001b[1;32m      3\u001b[0m         collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m         vectorstore_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzilliz\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m         }\n\u001b[1;32m     10\u001b[0m     )\n\u001b[0;32m---> 11\u001b[0m \u001b[43mzilliz_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m zilliz_store\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworry\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[33], line 117\u001b[0m, in \u001b[0;36mVectorStore.add_docs\u001b[0;34m(self, docs, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03mCreate a new collection from documents and initialise it with the specified settings.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m    Initialised vectorstore containing the input documents\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVectorStoreClass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_core/vectorstores/base.py:852\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ids\n\u001b[0;32m--> 852\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_community/vectorstores/zilliz.py:195\u001b[0m, in \u001b[0;36mZilliz.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, collection_name, connection_args, consistency_level, index_params, search_params, drop_old, ids, auto_id, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m vector_db \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m    185\u001b[0m     embedding_function\u001b[38;5;241m=\u001b[39membedding,\n\u001b[1;32m    186\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    194\u001b[0m )\n\u001b[0;32m--> 195\u001b[0m \u001b[43mvector_db\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vector_db\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_community/vectorstores/milvus.py:581\u001b[0m, in \u001b[0;36mMilvus.add_texts\u001b[0;34m(self, texts, metadatas, timeout, batch_size, ids, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout\n\u001b[0;32m--> 581\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;66;03m# Dict to hold all insert columns\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_community/vectorstores/milvus.py:300\u001b[0m, in \u001b[0;36mMilvus._init\u001b[0;34m(self, embeddings, metadatas, partition_names, replica_number, timeout)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_fields()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_community/vectorstores/milvus.py:411\u001b[0m, in \u001b[0;36mMilvus._create_collection\u001b[0;34m(self, embeddings, metadatas)\u001b[0m\n\u001b[1;32m    408\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to create collection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m error: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollection_name, e\n\u001b[1;32m    410\u001b[0m )\n\u001b[0;32m--> 411\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_community/vectorstores/milvus.py:398\u001b[0m, in \u001b[0;36mMilvus._create_collection\u001b[0;34m(self, embeddings, metadatas)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol \u001b[38;5;241m=\u001b[39m \u001b[43mCollection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsistency_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconsistency_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43musing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;66;03m# Set the collection properties if they exist\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pymilvus/orm/collection.py:150\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[0;34m(self, name, schema, using, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m consistency_level \u001b[38;5;241m=\u001b[39m get_consistency_level(\n\u001b[1;32m    147\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsistency_level\u001b[39m\u001b[38;5;124m\"\u001b[39m, DEFAULT_CONSISTENCY_LEVEL)\n\u001b[1;32m    148\u001b[0m )\n\u001b[0;32m--> 150\u001b[0m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema \u001b[38;5;241m=\u001b[39m schema\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pymilvus/decorators.py:148\u001b[0m, in \u001b[0;36merror_handler.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC error: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, <Time:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord_dict\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mFutureTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pymilvus/decorators.py:144\u001b[0m, in \u001b[0;36merror_handler.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC start\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MilvusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pymilvus/decorators.py:183\u001b[0m, in \u001b[0;36mtracing_request.<locals>.wrapper.<locals>.handler\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_onetime_request_id(req_id)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pymilvus/decorators.py:123\u001b[0m, in \u001b[0;36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 123\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pymilvus/decorators.py:87\u001b[0m, in \u001b[0;36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# Do not retry on these codes\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pymilvus/client/grpc_handler.py:308\u001b[0m, in \u001b[0;36mGrpcHandler.create_collection\u001b[0;34m(self, collection_name, fields, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m status \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m--> 308\u001b[0m \u001b[43mcheck_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pymilvus/client/utils.py:63\u001b[0m, in \u001b[0;36mcheck_status\u001b[0;34m(status)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m status\u001b[38;5;241m.\u001b[39merror_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MilvusException(status\u001b[38;5;241m.\u001b[39mcode, status\u001b[38;5;241m.\u001b[39mreason, status\u001b[38;5;241m.\u001b[39merror_code)\n",
      "\u001b[0;31mMilvusException\u001b[0m: <MilvusException: (code=65535, message=duplicated field name)>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMilvusException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# check zilliz\u001b[39;00m\n\u001b[1;32m      2\u001b[0m zilliz_store \u001b[38;5;241m=\u001b[39m VectorStore(\n\u001b[1;32m      3\u001b[0m         collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m         vectorstore_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzilliz\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m         }\n\u001b[1;32m     10\u001b[0m     )\n\u001b[0;32m---> 11\u001b[0m \u001b[43mzilliz_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m zilliz_store\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworry\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[33], line 117\u001b[0m, in \u001b[0;36mVectorStore.add_docs\u001b[0;34m(self, docs, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_docs\u001b[39m(\u001b[38;5;28mself\u001b[39m, docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    105\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    Create a new collection from documents and initialise it with the specified settings.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m        Initialised vectorstore containing the input documents\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVectorStoreClass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_core/vectorstores/base.py:852\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[1;32m    850\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ids\n\u001b[0;32m--> 852\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_community/vectorstores/zilliz.py:195\u001b[0m, in \u001b[0;36mZilliz.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, collection_name, connection_args, consistency_level, index_params, search_params, drop_old, ids, auto_id, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a Zilliz collection, indexes it with HNSW, and insert data.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    Zilliz: Zilliz Vector Store\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m vector_db \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m    185\u001b[0m     embedding_function\u001b[38;5;241m=\u001b[39membedding,\n\u001b[1;32m    186\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    194\u001b[0m )\n\u001b[0;32m--> 195\u001b[0m \u001b[43mvector_db\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vector_db\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_community/vectorstores/milvus.py:581\u001b[0m, in \u001b[0;36mMilvus.add_texts\u001b[0;34m(self, texts, metadatas, timeout, batch_size, ids, **kwargs)\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout:\n\u001b[1;32m    580\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout\n\u001b[0;32m--> 581\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;66;03m# Dict to hold all insert columns\u001b[39;00m\n\u001b[1;32m    584\u001b[0m insert_dict: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text_field: texts,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_field: embeddings,\n\u001b[1;32m    587\u001b[0m }\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_community/vectorstores/milvus.py:300\u001b[0m, in \u001b[0;36mMilvus._init\u001b[0;34m(self, embeddings, metadatas, partition_names, replica_number, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init\u001b[39m(\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    293\u001b[0m     embeddings: Optional[\u001b[38;5;28mlist\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m     timeout: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    298\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 300\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_fields()\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_index()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_community/vectorstores/milvus.py:411\u001b[0m, in \u001b[0;36mMilvus._create_collection\u001b[0;34m(self, embeddings, metadatas)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MilvusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    408\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to create collection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m error: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollection_name, e\n\u001b[1;32m    410\u001b[0m     )\n\u001b[0;32m--> 411\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_community/vectorstores/milvus.py:398\u001b[0m, in \u001b[0;36mMilvus._create_collection\u001b[0;34m(self, embeddings, metadatas)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[1;32m    391\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollection_name,\n\u001b[1;32m    392\u001b[0m         schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m         num_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_shards,\n\u001b[1;32m    396\u001b[0m     )\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol \u001b[38;5;241m=\u001b[39m \u001b[43mCollection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsistency_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconsistency_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43musing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;66;03m# Set the collection properties if they exist\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollection_properties \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pymilvus/orm/collection.py:150\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[0;34m(self, name, schema, using, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m check_schema(schema)\n\u001b[1;32m    146\u001b[0m consistency_level \u001b[38;5;241m=\u001b[39m get_consistency_level(\n\u001b[1;32m    147\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsistency_level\u001b[39m\u001b[38;5;124m\"\u001b[39m, DEFAULT_CONSISTENCY_LEVEL)\n\u001b[1;32m    148\u001b[0m )\n\u001b[0;32m--> 150\u001b[0m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema \u001b[38;5;241m=\u001b[39m schema\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consistency_level \u001b[38;5;241m=\u001b[39m consistency_level\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pymilvus/decorators.py:148\u001b[0m, in \u001b[0;36merror_handler.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n\u001b[1;32m    147\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC error: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, <Time:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord_dict\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mFutureTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    150\u001b[0m     record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgRPC timeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pymilvus/decorators.py:144\u001b[0m, in \u001b[0;36merror_handler.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC start\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MilvusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    146\u001b[0m     record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pymilvus/decorators.py:183\u001b[0m, in \u001b[0;36mtracing_request.<locals>.wrapper.<locals>.handler\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m req_id:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_onetime_request_id(req_id)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pymilvus/decorators.py:123\u001b[0m, in \u001b[0;36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         back_off \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(back_off \u001b[38;5;241m*\u001b[39m back_off_multiplier, max_back_off)\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 123\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pymilvus/decorators.py:87\u001b[0m, in \u001b[0;36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;66;03m# Do not retry on these codes\u001b[39;00m\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mcode() \u001b[38;5;129;01min\u001b[39;00m IGNORE_RETRY_CODES:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pymilvus/client/grpc_handler.py:308\u001b[0m, in \u001b[0;36mGrpcHandler.create_collection\u001b[0;34m(self, collection_name, fields, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rf\n\u001b[1;32m    307\u001b[0m status \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m--> 308\u001b[0m \u001b[43mcheck_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pymilvus/client/utils.py:63\u001b[0m, in \u001b[0;36mcheck_status\u001b[0;34m(status)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_status\u001b[39m(status: Status):\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m status\u001b[38;5;241m.\u001b[39merror_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MilvusException(status\u001b[38;5;241m.\u001b[39mcode, status\u001b[38;5;241m.\u001b[39mreason, status\u001b[38;5;241m.\u001b[39merror_code)\n",
      "\u001b[0;31mMilvusException\u001b[0m: <MilvusException: (code=65535, message=duplicated field name)>"
     ]
    }
   ],
   "source": [
    "# check zilliz\n",
    "zilliz_store = VectorStore(\n",
    "        collection_name=\"test3\",\n",
    "        vectorstore_type=\"zilliz\",\n",
    "        embedding_type=\"openai\",\n",
    "        connection_args = {\n",
    "            \"uri\": os.getenv('ZILLIZ_URI'),\n",
    "            \"token\": os.getenv( 'ZILLIZ_TOKEN')\n",
    "        }\n",
    "    )\n",
    "zilliz_store.add_docs(docs)\n",
    "zilliz_store.search(\"worry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ability',\n",
       " 'Advance Care Planning Services Grouping',\n",
       " 'Advance Directive Content Type SCT',\n",
       " 'Advance Directive Type Code',\n",
       " 'Allergy Clinical Status',\n",
       " 'Allergy and Intolerance Type',\n",
       " 'Body Site Value Set',\n",
       " 'Care Model',\n",
       " 'Care Team Member Function',\n",
       " 'Care Team Member Function (SNOMEDCT)',\n",
       " 'Clinical Substance',\n",
       " 'D(Rh) Sensitized',\n",
       " 'D(Rh) Type',\n",
       " 'DIRQuantityMeasurementTypeCodes',\n",
       " 'Diet Item Grouping',\n",
       " 'Encounter Planned',\n",
       " 'Enteral Nutrition Composition Grouping',\n",
       " 'Extended Pregnancy Status',\n",
       " 'Feeding Device Grouping',\n",
       " 'Feeding Device SNOMED CT',\n",
       " 'Food and Nutrition Related History Grouping',\n",
       " 'Goal Achievement',\n",
       " 'HealthStatus',\n",
       " 'Healthcare Agent Qualifier',\n",
       " 'Infectious Disease',\n",
       " 'Medication Route',\n",
       " 'Mental Status Observation',\n",
       " 'Mental and Functional Status Response',\n",
       " 'Nutrition Anthropometric Measurements Grouping',\n",
       " 'Nutrition Diagnosis Grouping',\n",
       " 'Nutrition Focused Physical Findings Grouping',\n",
       " 'Nutrition Order Item Grouping',\n",
       " 'Nutrition Recommendation Grouping',\n",
       " 'Nutrition Recommendations',\n",
       " 'Nutritional Status',\n",
       " 'Obligation or Prohibition Instruction Type',\n",
       " 'Organism',\n",
       " 'Patient Education',\n",
       " 'Postpartum Status',\n",
       " 'Pregnancy Intention',\n",
       " 'Pregnancy Outcome',\n",
       " 'Pregnancy Related Findings',\n",
       " 'Pregnancy Status Determination Method',\n",
       " 'Pressure Point',\n",
       " 'Pressure Ulcer Stage',\n",
       " 'Priority Level',\n",
       " 'Problem',\n",
       " 'Problem Status',\n",
       " 'Problem Type (SNOMEDCT)',\n",
       " 'Procedure',\n",
       " 'Referral Types',\n",
       " 'Residence and Accommodation Type',\n",
       " 'Sensory Status Problem Type',\n",
       " 'Severity',\n",
       " 'Smoking Status',\n",
       " 'Social History Type',\n",
       " 'Substance Reactant for Intolerance',\n",
       " 'TargetSite Qualifiers',\n",
       " 'Tobacco Use',\n",
       " 'Transmission Based Precaution Types',\n",
       " 'Wound Characteristic',\n",
       " 'Wound Type'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df[\"Value Set Name\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df[df[\"Description\"].str.contains(\"smoker\")]\n",
    "df_random = df.sample(n=50)\n",
    "df_sample = pd.concat([df_sample[:10], df_sample])\n",
    "loader = CSVLoader(file_path=f_sample, content_columns=[\"Value Set Name\", \"Purpose: Clinical Focus\", \"Description\"], metadata_columns=[\"Code\"])\n",
    "data = loader.load()\n",
    "print(data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Code System\n",
       "SNOMEDCT    321864\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snomed_dataset[\"Code System\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "\n",
    "def load_json(file_path, jq_schema):\n",
    "    \"\"\"Load JSON documents.\"\"\"\n",
    "    loader = JSONLoader(\n",
    "        file_path=file_path,\n",
    "        jq_schema=jq_schema,\n",
    "        text_content=False\n",
    "    )\n",
    "    return loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value Set Name</th>\n",
       "      <th>Code</th>\n",
       "      <th>Description</th>\n",
       "      <th>Purpose: Clinical Focus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ability</td>\n",
       "      <td>1091000175109</td>\n",
       "      <td>Requires practice (qualifier value)</td>\n",
       "      <td>Representation of a person's general functiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ability</td>\n",
       "      <td>717896003</td>\n",
       "      <td>Does not (qualifier value)</td>\n",
       "      <td>Representation of a person's general functiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ability</td>\n",
       "      <td>371151008</td>\n",
       "      <td>Unable (qualifier value)</td>\n",
       "      <td>Representation of a person's general functiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ability</td>\n",
       "      <td>371152001</td>\n",
       "      <td>Assisted (qualifier value)</td>\n",
       "      <td>Representation of a person's general functiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ability</td>\n",
       "      <td>371153006</td>\n",
       "      <td>Independent (qualifier value)</td>\n",
       "      <td>Representation of a person's general functiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321859</th>\n",
       "      <td>Wound Type</td>\n",
       "      <td>723071003</td>\n",
       "      <td>Pressure injury of deep tissue (disorder)</td>\n",
       "      <td>General concepts representing injuries to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321860</th>\n",
       "      <td>Wound Type</td>\n",
       "      <td>7231009</td>\n",
       "      <td>Bullous dermatosis (disorder)</td>\n",
       "      <td>General concepts representing injuries to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321861</th>\n",
       "      <td>Wound Type</td>\n",
       "      <td>95321009</td>\n",
       "      <td>Fissure in skin (disorder)</td>\n",
       "      <td>General concepts representing injuries to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321862</th>\n",
       "      <td>Wound Type</td>\n",
       "      <td>1163215007</td>\n",
       "      <td>Pressure injury (disorder)</td>\n",
       "      <td>General concepts representing injuries to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321863</th>\n",
       "      <td>Wound Type</td>\n",
       "      <td>1163217004</td>\n",
       "      <td>Pressure injury stage I (disorder)</td>\n",
       "      <td>General concepts representing injuries to the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>321864 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Value Set Name           Code  \\\n",
       "0             Ability  1091000175109   \n",
       "1             Ability      717896003   \n",
       "2             Ability      371151008   \n",
       "3             Ability      371152001   \n",
       "4             Ability      371153006   \n",
       "...               ...            ...   \n",
       "321859     Wound Type      723071003   \n",
       "321860     Wound Type        7231009   \n",
       "321861     Wound Type       95321009   \n",
       "321862     Wound Type     1163215007   \n",
       "321863     Wound Type     1163217004   \n",
       "\n",
       "                                      Description  \\\n",
       "0             Requires practice (qualifier value)   \n",
       "1                      Does not (qualifier value)   \n",
       "2                        Unable (qualifier value)   \n",
       "3                      Assisted (qualifier value)   \n",
       "4                   Independent (qualifier value)   \n",
       "...                                           ...   \n",
       "321859  Pressure injury of deep tissue (disorder)   \n",
       "321860              Bullous dermatosis (disorder)   \n",
       "321861                 Fissure in skin (disorder)   \n",
       "321862                 Pressure injury (disorder)   \n",
       "321863         Pressure injury stage I (disorder)   \n",
       "\n",
       "                                  Purpose: Clinical Focus  \n",
       "0       Representation of a person's general functiona...  \n",
       "1       Representation of a person's general functiona...  \n",
       "2       Representation of a person's general functiona...  \n",
       "3       Representation of a person's general functiona...  \n",
       "4       Representation of a person's general functiona...  \n",
       "...                                                   ...  \n",
       "321859  General concepts representing injuries to the ...  \n",
       "321860  General concepts representing injuries to the ...  \n",
       "321861  General concepts representing injuries to the ...  \n",
       "321862  General concepts representing injuries to the ...  \n",
       "321863  General concepts representing injuries to the ...  \n",
       "\n",
       "[321864 rows x 4 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# import json\n",
    "# # from embeddings.embeddings import VectorStore\n",
    "# # from embeddings.utils import load_json\n",
    "# from datasets import load_dataset\n",
    "# from langchain_community.document_loaders import DataFrameLoader\n",
    "\n",
    "\n",
    "def connect_loinc():\n",
    "    \"\"\"Initialise the vector store for LOINC embeddings.\"\"\"\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    pc_store = VectorStore(\n",
    "        collection_name=\"loinc_mappings\",\n",
    "        index_name=\"apollo-mappings\",\n",
    "        vectorstore_type=\"pinecone\",\n",
    "        embedding_type=\"openai\"\n",
    "    )\n",
    "\n",
    "    return pc_store\n",
    "\n",
    "def connect_snomed():\n",
    "    \"\"\"Initialise the vector store for SNOMED embeddings.\"\"\"\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    pc_store = VectorStore(\n",
    "        collection_name=\"snomed_mappings\",\n",
    "        index_name=\"apollo-mappings\",\n",
    "        vectorstore_type=\"pinecone\",\n",
    "        embedding_type=\"openai\"\n",
    "    )\n",
    "\n",
    "    return pc_store\n",
    "\n",
    "def preprocess_loinc(df, keep_cols, embed_cols):\n",
    "    \"\"\"Preprocess a Huggingface LOINC dataframe and populate a Pinecone vector store instance with the data.\"\"\"\n",
    "\n",
    "    # Select dataset columns to include\n",
    "    df = df[keep_cols]\n",
    "\n",
    "    # Replace NULL values with empty string\n",
    "    df = df.fillna('')\n",
    "    \n",
    "    # Combine selected columns in a JSON string. This new combined field will be embedded and used for searching.\n",
    "    df[\"text\"] = df[embed_cols].apply(\n",
    "        lambda row: json.dumps({col: row[col] for col in embed_cols}),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "def preprocess_snomed(df, keep_cols, embed_cols, project_value_sets):\n",
    "    \"\"\"Preprocess a Huggingface SNOMED dataframe and populate a Pinecone vector store instance with the data.\"\"\"\n",
    "\n",
    "    # Select dataset columns to include\n",
    "    df = df[keep_cols]\n",
    "    \n",
    "    # Select the SNOMED Value Sets to include\n",
    "    df = df[df[\"Value Set Name\"].isin(project_value_sets)]\n",
    "\n",
    "    # Combine selected columns in a JSON string. This new combined field will be embedded and used for searching.\n",
    "    df[\"text\"] = df[embed_cols].apply(\n",
    "        lambda row: json.dumps({col: row[col] for col in embed_cols}),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "def upload_loinc_data(store, \n",
    "                       keep_cols=[\"LONG_COMMON_NAME\", \"METHOD_TYP\", \"CLASS\", \"SYSTEM\"],\n",
    "                       embed_cols=[\"LONG_COMMON_NAME\", \"METHOD_TYP\", \"CLASS\", \"SYSTEM\"],):\n",
    "    \"\"\"Preprocess a Huggingface LOINC dataset and populate a Pinecone vector store instance with the data.\"\"\"\n",
    "    \n",
    "    # Get the data as a dataframe\n",
    "    df = load_dataset(\"awacke1/LOINC-Clinical-Terminology\")\n",
    "    df = pd.DataFrame(df['train'])\n",
    "\n",
    "    # # TODO remove this sampling step when we know how to embed the data\n",
    "    # df = df[:25]\n",
    "    # df\n",
    "\n",
    "    # Preprocess and filter the dataframe\n",
    "    df = preprocess_loinc(df, keep_cols, embed_cols)\n",
    "\n",
    "    # Create a new collection in the vector store and add the data\n",
    "    loader = DataFrameLoader(df, page_content_column=\"text\")\n",
    "    docs = loader.load()\n",
    "    store.add_docs(docs)\n",
    "\n",
    "    return pc_store\n",
    "\n",
    "def upload_snomed_data(store, \n",
    "                       keep_cols=[\"Value Set Name\", \"Code\", \"Description\", \"Purpose: Clinical Focus\"],\n",
    "                       embed_cols=[\"Value Set Name\", \"Description\", \"Purpose: Clinical Focus\"],\n",
    "                       project_value_sets=[\"Body Site Value Set\", \"Procedure\"]):\n",
    "    \"\"\"Preprocess a Huggingface SNOMED dataset and populate a Pinecone vector store instance with the data.\"\"\"\n",
    "    \n",
    "    # Get the data as a dataframe\n",
    "    df = load_dataset(\"awacke1/SNOMED-CT-Code-Value-Semantic-Set.csv\")\n",
    "    df = pd.DataFrame(df['train'])\n",
    "\n",
    "    # # TODO remove this sampling step when we know how to embed the data\n",
    "    # df = df[df[\"Value Set Name\"]==\"Body Site Value Set\"]\n",
    "    # df = df[:25]\n",
    "\n",
    "    # Preprocess and filter the dataframe\n",
    "    df = preprocess_snomed(df, keep_cols, embed_cols, project_value_sets)\n",
    "\n",
    "    # Create a new collection in the vector store and add the data\n",
    "    loader = DataFrameLoader(df, page_content_column=\"text\")\n",
    "    docs = loader.load()\n",
    "    store.add_docs(docs)\n",
    "\n",
    "    return pc_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m pc_store \u001b[38;5;241m=\u001b[39m VectorStore(\n\u001b[1;32m      2\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnomed-mappings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     index_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapollo-mappings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     vectorstore_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpinecone\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     embedding_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m \u001b[43mupload_snomed_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpc_store\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[30], line 116\u001b[0m, in \u001b[0;36mupload_snomed_data\u001b[0;34m(store, keep_cols, embed_cols, project_value_sets)\u001b[0m\n\u001b[1;32m    114\u001b[0m loader \u001b[38;5;241m=\u001b[39m DataFrameLoader(df, page_content_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    115\u001b[0m docs \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m--> 116\u001b[0m \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pc_store\n",
      "Cell \u001b[0;32mIn[1], line 104\u001b[0m, in \u001b[0;36mVectorStore.add_docs\u001b[0;34m(self, docs, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_docs\u001b[39m(\u001b[38;5;28mself\u001b[39m, docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    Create a new collection from documents and initialise it with the specified settings.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m        Initialised vectorstore containing the input documents\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVectorStoreClass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_core/vectorstores/base.py:852\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[1;32m    850\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ids\n\u001b[0;32m--> 852\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_pinecone/vectorstores.py:583\u001b[0m, in \u001b[0;36mPineconeVectorStore.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, batch_size, text_key, namespace, index_name, upsert_kwargs, pool_threads, embeddings_chunk_size, async_req, id_prefix, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m pinecone_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_pinecone_index(index_name, pool_threads)\n\u001b[1;32m    581\u001b[0m pinecone \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(pinecone_index, embedding, text_key, namespace, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 583\u001b[0m \u001b[43mpinecone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_chunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings_chunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_req\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_req\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mupsert_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pinecone\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_pinecone/vectorstores.py:283\u001b[0m, in \u001b[0;36mPineconeVectorStore.add_texts\u001b[0;34m(self, texts, metadatas, ids, namespace, batch_size, embedding_chunk_size, async_req, id_prefix, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m vector_tuples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(chunk_ids, embeddings, chunk_metadatas)\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m async_req:\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# Runs the pinecone upsert asynchronously.\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m     async_res \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_vector_tuples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43masync_req\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_req\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_vector_tuples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_iterate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_tuples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    292\u001b[0m     [res\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m async_res]\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/langchain_pinecone/vectorstores.py:284\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    280\u001b[0m vector_tuples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(chunk_ids, embeddings, chunk_metadatas)\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m async_req:\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# Runs the pinecone upsert asynchronously.\u001b[39;00m\n\u001b[1;32m    283\u001b[0m     async_res \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 284\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_vector_tuples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43masync_req\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_req\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m batch_vector_tuples \u001b[38;5;129;01min\u001b[39;00m batch_iterate(batch_size, vector_tuples)\n\u001b[1;32m    291\u001b[0m     ]\n\u001b[1;32m    292\u001b[0m     [res\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m async_res]\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pinecone/utils/error_handling.py:11\u001b[0m, in \u001b[0;36mvalidate_and_convert_errors.<locals>.inner_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_func\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ProtocolError):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pinecone/data/index.py:175\u001b[0m, in \u001b[0;36mIndex.upsert\u001b[0;34m(self, vectors, namespace, batch_size, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masync_req is not supported when batch_size is provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo upsert in parallel, please follow: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.pinecone.io/docs/insert-data#sending-upserts-in-parallel\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m     )\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_upsert_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_check_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_size, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m batch_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size must be a positive integer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pinecone/data/index.py:206\u001b[0m, in \u001b[0;36mIndex._upsert_batch\u001b[0;34m(self, vectors, namespace, _check_type, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m args_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_non_empty_args([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnamespace\u001b[39m\u001b[38;5;124m\"\u001b[39m, namespace)])\n\u001b[1;32m    202\u001b[0m vec_builder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m v: VectorFactory\u001b[38;5;241m.\u001b[39mbuild(v, check_type\u001b[38;5;241m=\u001b[39m_check_type)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_api\u001b[38;5;241m.\u001b[39mupsert(\n\u001b[1;32m    205\u001b[0m     UpsertRequest(\n\u001b[0;32m--> 206\u001b[0m         vectors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(vec_builder, vectors)),\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs_dict,\n\u001b[1;32m    208\u001b[0m         _check_type\u001b[38;5;241m=\u001b[39m_check_type,\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _OPENAPI_ENDPOINT_PARAMS},\n\u001b[1;32m    210\u001b[0m     ),\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _OPENAPI_ENDPOINT_PARAMS},\n\u001b[1;32m    212\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pinecone/data/index.py:202\u001b[0m, in \u001b[0;36mIndex._upsert_batch.<locals>.<lambda>\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_upsert_batch\u001b[39m(\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    196\u001b[0m     vectors: Union[List[Vector], List[\u001b[38;5;28mtuple\u001b[39m], List[\u001b[38;5;28mdict\u001b[39m]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m UpsertResponse:\n\u001b[1;32m    201\u001b[0m     args_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_non_empty_args([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnamespace\u001b[39m\u001b[38;5;124m\"\u001b[39m, namespace)])\n\u001b[0;32m--> 202\u001b[0m     vec_builder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m v: \u001b[43mVectorFactory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_check_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_api\u001b[38;5;241m.\u001b[39mupsert(\n\u001b[1;32m    205\u001b[0m         UpsertRequest(\n\u001b[1;32m    206\u001b[0m             vectors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(vec_builder, vectors)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _OPENAPI_ENDPOINT_PARAMS},\n\u001b[1;32m    212\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pinecone/data/vector_factory.py:26\u001b[0m, in \u001b[0;36mVectorFactory.build\u001b[0;34m(item, check_type)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m item\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVectorFactory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tuple_to_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, Mapping):\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m VectorFactory\u001b[38;5;241m.\u001b[39m_dict_to_vector(item, check_type)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pinecone/data/vector_factory.py:42\u001b[0m, in \u001b[0;36mVectorFactory._tuple_to_vector\u001b[0;34m(item, check_type)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSparse values are not supported in tuples. Please use either dicts or Vector objects as inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m     )\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_to_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_check_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pinecone/core/openapi/shared/model_utils.py:33\u001b[0m, in \u001b[0;36mconvert_js_args_to_python_args.<locals>.wrapped_init\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_property_naming:\n\u001b[1;32m     32\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m change_keys_js_to_python(kwargs, _self \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_self, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m _self\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pinecone/core/openapi/data/model/vector.py:289\u001b[0m, in \u001b[0;36mVector.__init__\u001b[0;34m(self, id, values, *args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_visited_composed_classes \u001b[38;5;241m=\u001b[39m _visited_composed_classes \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m,)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mid\u001b[39m\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m \u001b[38;5;241m=\u001b[39m values\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var_name, var_value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    292\u001b[0m         var_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattribute_map\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configuration \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m     ):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# discard variable.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pinecone/core/openapi/shared/model_utils.py:156\u001b[0m, in \u001b[0;36mOpenApiModel.__setattr__\u001b[0;34m(self, attr, value)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr, value):\n\u001b[1;32m    155\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"set the value of an attribute using dot notation: `instance.attr = val`\"\"\"\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pinecone/core/openapi/shared/model_utils.py:432\u001b[0m, in \u001b[0;36mModelNormal.__setitem__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[name] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 432\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_attribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pinecone/core/openapi/shared/model_utils.py:132\u001b[0m, in \u001b[0;36mOpenApiModel.set_attribute\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PineconeApiTypeError(error_msg, path_to_item\u001b[38;5;241m=\u001b[39mpath_to_item, valid_classes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mstr\u001b[39m,), key_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_type:\n\u001b[0;32m--> 132\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_and_convert_types\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequired_types_mixed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_to_item\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spec_property_naming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (name,) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallowed_values:\n\u001b[1;32m    141\u001b[0m     check_allowed_values(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallowed_values, (name,), value)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pinecone/core/openapi/shared/model_utils.py:1489\u001b[0m, in \u001b[0;36mvalidate_and_convert_types\u001b[0;34m(input_value, required_types_mixed, path_to_item, spec_property_naming, _check_type, configuration)\u001b[0m\n\u001b[1;32m   1487\u001b[0m         inner_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(path_to_item)\n\u001b[1;32m   1488\u001b[0m         inner_path\u001b[38;5;241m.\u001b[39mappend(index)\n\u001b[0;32m-> 1489\u001b[0m         input_value[index] \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_and_convert_types\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m            \u001b[49m\u001b[43minner_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m            \u001b[49m\u001b[43minner_required_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m            \u001b[49m\u001b[43minner_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspec_property_naming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_check_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1495\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(input_value, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m   1498\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_value \u001b[38;5;241m==\u001b[39m {}:\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;66;03m# allow an empty dict\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pinecone/core/openapi/shared/model_utils.py:1433\u001b[0m, in \u001b[0;36mvalidate_and_convert_types\u001b[0;34m(input_value, required_types_mixed, path_to_item, spec_property_naming, _check_type, configuration)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_and_convert_types\u001b[39m(\n\u001b[1;32m   1403\u001b[0m     input_value, required_types_mixed, path_to_item, spec_property_naming, _check_type, configuration\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1404\u001b[0m ):\n\u001b[1;32m   1405\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Raises a TypeError is there is a problem, otherwise returns value\u001b[39;00m\n\u001b[1;32m   1406\u001b[0m \n\u001b[1;32m   1407\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;124;03m        PineconeApiTypeError\u001b[39;00m\n\u001b[1;32m   1432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1433\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mget_required_type_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequired_types_mixed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec_property_naming\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1434\u001b[0m     valid_classes, child_req_types_by_current_type \u001b[38;5;241m=\u001b[39m results\n\u001b[1;32m   1436\u001b[0m     input_class_simple \u001b[38;5;241m=\u001b[39m get_simple_class(input_value)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pinecone/core/openapi/shared/model_utils.py:1074\u001b[0m, in \u001b[0;36mget_required_type_classes\u001b[0;34m(required_types_mixed, spec_property_naming)\u001b[0m\n\u001b[1;32m   1072\u001b[0m         child_req_types_by_current_type[\u001b[38;5;28mdict\u001b[39m] \u001b[38;5;241m=\u001b[39m required_type[\u001b[38;5;28mstr\u001b[39m]\n\u001b[1;32m   1073\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1074\u001b[0m         valid_classes\u001b[38;5;241m.\u001b[39mextend(\u001b[43mget_possible_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequired_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec_property_naming\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(valid_classes), child_req_types_by_current_type\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pinecone/core/openapi/shared/model_utils.py:1032\u001b[0m, in \u001b[0;36mget_possible_classes\u001b[0;34m(cls, from_server_context)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_server_context:\n\u001b[1;32m   1031\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m possible_classes\n\u001b[0;32m-> 1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiscriminator\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdiscriminator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1033\u001b[0m     possible_classes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1034\u001b[0m     possible_classes\u001b[38;5;241m.\u001b[39mextend(get_discriminated_classes(\u001b[38;5;28mcls\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pc_store = VectorStore(\n",
    "    collection_name=\"snomed-mappings\",\n",
    "    index_name=\"apollo-mappings\",\n",
    "    vectorstore_type=\"pinecone\",\n",
    "    embedding_type=\"openai\"\n",
    ")\n",
    "upload_snomed_data(pc_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SearchResult(text='{\"Value Set Name\": \"Body Site Value Set\", \"Description\": \"Structure of posterior process of nasal septal cartilage (body structure)\", \"Purpose: Clinical Focus\": \"All SNOMED CT anatomic structures, locations, abnormal structures that can be considered to describe an anatomical site.\"}', metadata={'Code': 9609000.0, 'Description': 'Structure of posterior process of nasal septal cartilage (body structure)', 'Purpose: Clinical Focus': 'All SNOMED CT anatomic structures, locations, abnormal structures that can be considered to describe an anatomical site.', 'Value Set Name': 'Body Site Value Set'}, score=None),\n",
       " SearchResult(text='{\"Value Set Name\": \"Body Site Value Set\", \"Description\": \"Subcutaneous tissue structure of lower margin of nasal septum (body structure)\", \"Purpose: Clinical Focus\": \"All SNOMED CT anatomic structures, locations, abnormal structures that can be considered to describe an anatomical site.\"}', metadata={'Code': 9662007.0, 'Description': 'Subcutaneous tissue structure of lower margin of nasal septum (body structure)', 'Purpose: Clinical Focus': 'All SNOMED CT anatomic structures, locations, abnormal structures that can be considered to describe an anatomical site.', 'Value Set Name': 'Body Site Value Set'}, score=None)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_store.search(\"nasal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'LONG_COMMON_NAME': 'Specimen care is maintained', 'METHOD_TYP': '', 'CLASS': 'SURVEY.PNDS', 'SYSTEM': '^Patient'}, page_content='{\"LONG_COMMON_NAME\": \"Specimen care is maintained\", \"METHOD_TYP\": \"\", \"CLASS\": \"SURVEY.PNDS\", \"SYSTEM\": \"^Patient\"}'), Document(metadata={'LONG_COMMON_NAME': 'Team communication is maintained throughout care', 'METHOD_TYP': '', 'CLASS': 'SURVEY.PNDS', 'SYSTEM': '^Patient'}, page_content='{\"LONG_COMMON_NAME\": \"Team communication is maintained throughout care\", \"METHOD_TYP\": \"\", \"CLASS\": \"SURVEY.PNDS\", \"SYSTEM\": \"^Patient\"}'), Document(metadata={'LONG_COMMON_NAME': 'Demonstrates knowledge of the expected psychosocial responses to the procedure', 'METHOD_TYP': '', 'CLASS': 'SURVEY.PNDS', 'SYSTEM': '^Patient'}, page_content='{\"LONG_COMMON_NAME\": \"Demonstrates knowledge of the expected psychosocial responses to the procedure\", \"METHOD_TYP\": \"\", \"CLASS\": \"SURVEY.PNDS\", \"SYSTEM\": \"^Patient\"}'), Document(metadata={'LONG_COMMON_NAME': 'Demonstrates knowledge of nutritional management related to the procedure', 'METHOD_TYP': '', 'CLASS': 'SURVEY.PNDS', 'SYSTEM': '^Patient'}, page_content='{\"LONG_COMMON_NAME\": \"Demonstrates knowledge of nutritional management related to the procedure\", \"METHOD_TYP\": \"\", \"CLASS\": \"SURVEY.PNDS\", \"SYSTEM\": \"^Patient\"}'), Document(metadata={'LONG_COMMON_NAME': 'Demonstrates knowledge of medication management', 'METHOD_TYP': '', 'CLASS': 'SURVEY.PNDS', 'SYSTEM': '^Patient'}, page_content='{\"LONG_COMMON_NAME\": \"Demonstrates knowledge of medication management\", \"METHOD_TYP\": \"\", \"CLASS\": \"SURVEY.PNDS\", \"SYSTEM\": \"^Patient\"}'), Document(metadata={'LONG_COMMON_NAME': 'Demonstrates knowledge of pain management', 'METHOD_TYP': '', 'CLASS': 'SURVEY.PNDS', 'SYSTEM': '^Patient'}, page_content='{\"LONG_COMMON_NAME\": \"Demonstrates knowledge of pain management\", \"METHOD_TYP\": \"\", \"CLASS\": \"SURVEY.PNDS\", \"SYSTEM\": \"^Patient\"}'), Document(metadata={'LONG_COMMON_NAME': 'R wave duration in lead AVR', 'METHOD_TYP': 'EKG', 'CLASS': 'EKG.MEAS', 'SYSTEM': 'Heart'}, page_content='{\"LONG_COMMON_NAME\": \"R wave duration in lead AVR\", \"METHOD_TYP\": \"EKG\", \"CLASS\": \"EKG.MEAS\", \"SYSTEM\": \"Heart\"}'), Document(metadata={'LONG_COMMON_NAME': 'Demonstrates knowledge of wound management', 'METHOD_TYP': '', 'CLASS': 'SURVEY.PNDS', 'SYSTEM': '^Patient'}, page_content='{\"LONG_COMMON_NAME\": \"Demonstrates knowledge of wound management\", \"METHOD_TYP\": \"\", \"CLASS\": \"SURVEY.PNDS\", \"SYSTEM\": \"^Patient\"}'), Document(metadata={'LONG_COMMON_NAME': 'Demonstrates knowledge of the procedure and expected results', 'METHOD_TYP': '', 'CLASS': 'SURVEY.PNDS', 'SYSTEM': '^Patient'}, page_content='{\"LONG_COMMON_NAME\": \"Demonstrates knowledge of the procedure and expected results\", \"METHOD_TYP\": \"\", \"CLASS\": \"SURVEY.PNDS\", \"SYSTEM\": \"^Patient\"}'), Document(metadata={'LONG_COMMON_NAME': 'No injury related to procedure equipment, medical supplies, or instrumentation', 'METHOD_TYP': '', 'CLASS': 'SURVEY.PNDS', 'SYSTEM': '^Patient'}, page_content='{\"LONG_COMMON_NAME\": \"No injury related to procedure equipment, medical supplies, or instrumentation\", \"METHOD_TYP\": \"\", \"CLASS\": \"SURVEY.PNDS\", \"SYSTEM\": \"^Patient\"}'), Document(metadata={'LONG_COMMON_NAME': 'No injury related to an electrical source', 'METHOD_TYP': '', 'CLASS': 'SURVEY.PNDS', 'SYSTEM': '^Patient'}, page_content='{\"LONG_COMMON_NAME\": \"No injury related to an electrical source\", \"METHOD_TYP\": \"\", \"CLASS\": \"SURVEY.PNDS\", \"SYSTEM\": \"^Patient\"}'), Document(metadata={'LONG_COMMON_NAME': \"Participates in decisions affecting the patient's plan of care\", 'METHOD_TYP': '', 'CLASS': 'SURVEY.PNDS', 'SYSTEM': '^Patient'}, page_content='{\"LONG_COMMON_NAME\": \"Participates in decisions affecting the patient\\'s plan of care\", \"METHOD_TYP\": \"\", \"CLASS\": \"SURVEY.PNDS\", \"SYSTEM\": \"^Patient\"}'), Document(metadata={'LONG_COMMON_NAME': 'Participates in the discharge process', 'METHOD_TYP': '', 'CLASS': 'SURVEY.PNDS', 'SYSTEM': '^Patient'}, page_content='{\"LONG_COMMON_NAME\": \"Participates in the discharge process\", \"METHOD_TYP\": \"\", \"CLASS\": \"SURVEY.PNDS\", \"SYSTEM\": \"^Patient\"}'), Document(metadata={'LONG_COMMON_NAME': 'Psychosocial health is maintained at or improved from baseline', 'METHOD_TYP': '', 'CLASS': 'SURVEY.PNDS', 'SYSTEM': '^Patient'}, page_content='{\"LONG_COMMON_NAME\": \"Psychosocial health is maintained at or improved from baseline\", \"METHOD_TYP\": \"\", \"CLASS\": \"SURVEY.PNDS\", \"SYSTEM\": \"^Patient\"}'), Document(metadata={'LONG_COMMON_NAME': 'No injury related to positioning due to care or procedure', 'METHOD_TYP': '', 'CLASS': 'SURVEY.PNDS', 'SYSTEM': '^Patient'}, page_content='{\"LONG_COMMON_NAME\": \"No injury related to positioning due to care or procedure\", \"METHOD_TYP\": \"\", \"CLASS\": \"SURVEY.PNDS\", \"SYSTEM\": \"^Patient\"}'), Document(metadata={'LONG_COMMON_NAME': 'R wave duration in lead I', 'METHOD_TYP': 'EKG', 'CLASS': 'EKG.MEAS', 'SYSTEM': 'Heart'}, page_content='{\"LONG_COMMON_NAME\": \"R wave duration in lead I\", \"METHOD_TYP\": \"EKG\", \"CLASS\": \"EKG.MEAS\", \"SYSTEM\": \"Heart\"}'), Document(metadata={'LONG_COMMON_NAME': 'No injury related to a laser source', 'METHOD_TYP': '', 'CLASS': 'SURVEY.PNDS', 'SYSTEM': '^Patient'}, page_content='{\"LONG_COMMON_NAME\": \"No injury related to a laser source\", \"METHOD_TYP\": \"\", \"CLASS\": \"SURVEY.PNDS\", \"SYSTEM\": \"^Patient\"}'), Document(metadata={'LONG_COMMON_NAME': 'Perioperative nursing data set outcomes panel [PNDS]', 'METHOD_TYP': 'PNDS', 'CLASS': 'PANEL.SURVEY.PNDS', 'SYSTEM': '^Patient'}, page_content='{\"LONG_COMMON_NAME\": \"Perioperative nursing data set outcomes panel [PNDS]\", \"METHOD_TYP\": \"PNDS\", \"CLASS\": \"PANEL.SURVEY.PNDS\", \"SYSTEM\": \"^Patient\"}'), Document(metadata={'LONG_COMMON_NAME': 'Hospice care Note', 'METHOD_TYP': 'Hospice care', 'CLASS': 'DOC.ONTOLOGY', 'SYSTEM': '{Setting}'}, page_content='{\"LONG_COMMON_NAME\": \"Hospice care Note\", \"METHOD_TYP\": \"Hospice care\", \"CLASS\": \"DOC.ONTOLOGY\", \"SYSTEM\": \"{Setting}\"}'), Document(metadata={'LONG_COMMON_NAME': 'ALK gene mutations found [Identifier] in Blood or Tissue by Molecular genetics method Nominal', 'METHOD_TYP': 'Molgen', 'CLASS': 'MOLPATH.MUT', 'SYSTEM': 'Bld/Tiss'}, page_content='{\"LONG_COMMON_NAME\": \"ALK gene mutations found [Identifier] in Blood or Tissue by Molecular genetics method Nominal\", \"METHOD_TYP\": \"Molgen\", \"CLASS\": \"MOLPATH.MUT\", \"SYSTEM\": \"Bld/Tiss\"}'), Document(metadata={'LONG_COMMON_NAME': 'GNA11 gene mutations found [Identifier] in Blood or Tissue by Molecular genetics method Nominal', 'METHOD_TYP': 'Molgen', 'CLASS': 'MOLPATH.MUT', 'SYSTEM': 'Bld/Tiss'}, page_content='{\"LONG_COMMON_NAME\": \"GNA11 gene mutations found [Identifier] in Blood or Tissue by Molecular genetics method Nominal\", \"METHOD_TYP\": \"Molgen\", \"CLASS\": \"MOLPATH.MUT\", \"SYSTEM\": \"Bld/Tiss\"}'), Document(metadata={'LONG_COMMON_NAME': 'GNAQ gene mutations found [Identifier] in Blood or Tissue by Molecular genetics method Nominal', 'METHOD_TYP': 'Molgen', 'CLASS': 'MOLPATH.MUT', 'SYSTEM': 'Bld/Tiss'}, page_content='{\"LONG_COMMON_NAME\": \"GNAQ gene mutations found [Identifier] in Blood or Tissue by Molecular genetics method Nominal\", \"METHOD_TYP\": \"Molgen\", \"CLASS\": \"MOLPATH.MUT\", \"SYSTEM\": \"Bld/Tiss\"}'), Document(metadata={'LONG_COMMON_NAME': 'IDH1 gene mutations found [Identifier] in Blood or Tissue by Molecular genetics method Nominal', 'METHOD_TYP': 'Molgen', 'CLASS': 'MOLPATH.MUT', 'SYSTEM': 'Bld/Tiss'}, page_content='{\"LONG_COMMON_NAME\": \"IDH1 gene mutations found [Identifier] in Blood or Tissue by Molecular genetics method Nominal\", \"METHOD_TYP\": \"Molgen\", \"CLASS\": \"MOLPATH.MUT\", \"SYSTEM\": \"Bld/Tiss\"}'), Document(metadata={'LONG_COMMON_NAME': 'IDH2 gene mutations found [Identifier] in Blood or Tissue by Molecular genetics method Nominal', 'METHOD_TYP': 'Molgen', 'CLASS': 'MOLPATH.MUT', 'SYSTEM': 'Bld/Tiss'}, page_content='{\"LONG_COMMON_NAME\": \"IDH2 gene mutations found [Identifier] in Blood or Tissue by Molecular genetics method Nominal\", \"METHOD_TYP\": \"Molgen\", \"CLASS\": \"MOLPATH.MUT\", \"SYSTEM\": \"Bld/Tiss\"}'), Document(metadata={'LONG_COMMON_NAME': 'R wave duration in lead II', 'METHOD_TYP': 'EKG', 'CLASS': 'EKG.MEAS', 'SYSTEM': 'Heart'}, page_content='{\"LONG_COMMON_NAME\": \"R wave duration in lead II\", \"METHOD_TYP\": \"EKG\", \"CLASS\": \"EKG.MEAS\", \"SYSTEM\": \"Heart\"}')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y3/tg4ts42x7bl1ty6zww9fx4bh0000gn/T/ipykernel_87877/3112543583.py:130: UserWarning: \n",
      "No results found. This could mean:\n",
      "1. Collection 'loinc-mappings' doesn't exist (run add_docs first)\n",
      "2. No similar documents found (check the input or the search criteria)\n",
      "3. Connection issues\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pc_store = VectorStore(\n",
    "    collection_name=\"loinc-mappings\",\n",
    "    index_name=\"apollo-mappings\",\n",
    "    vectorstore_type=\"pinecone\",\n",
    "    embedding_type=\"openai\"\n",
    ")\n",
    "upload_loinc_data(pc_store)\n",
    "pc_store.search(\"psyche\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SearchResult(text='{\"LONG_COMMON_NAME\": \"Psychosocial health is maintained at or improved from baseline\", \"METHOD_TYP\": \"\", \"CLASS\": \"SURVEY.PNDS\", \"SYSTEM\": \"^Patient\"}', metadata={'CLASS': 'SURVEY.PNDS', 'LONG_COMMON_NAME': 'Psychosocial health is maintained at or improved from baseline', 'METHOD_TYP': '', 'SYSTEM': '^Patient'}, score=None),\n",
       " SearchResult(text='{\"LONG_COMMON_NAME\": \"Demonstrates knowledge of the expected psychosocial responses to the procedure\", \"METHOD_TYP\": \"\", \"CLASS\": \"SURVEY.PNDS\", \"SYSTEM\": \"^Patient\"}', metadata={'CLASS': 'SURVEY.PNDS', 'LONG_COMMON_NAME': 'Demonstrates knowledge of the expected psychosocial responses to the procedure', 'METHOD_TYP': '', 'SYSTEM': '^Patient'}, score=None)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_store.search(\"psyche\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hanna/openfn/ai_experiments/apollo/services\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "parent_dir = os.path.abspath(\"../\")\n",
    "print(parent_dir)\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snomed import embed_snomed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loinc import embed_loinc_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embeddings import loinc_store, snomed_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_store_snomed = snomed_store.connect_snomed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanna/openfn/ai_experiments/apollo/services/embeddings/embeddings.py:130: UserWarning: \n",
      "No results found. This could mean:\n",
      "1. Collection 'snomed_mappings' doesn't exist (run add_docs first)\n",
      "2. No similar documents found (check the input or the search criteria)\n",
      "3. Connection issues\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(pc_store_snomed.search(\"nasal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_store_loinc = loinc_store.connect_loinc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanna/openfn/ai_experiments/apollo/services/embeddings/embeddings.py:130: UserWarning: \n",
      "No results found. This could mean:\n",
      "1. Collection 'loinc_mappings' doesn't exist (run add_docs first)\n",
      "2. No similar documents found (check the input or the search criteria)\n",
      "3. Connection issues\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pc_store_loinc.search(\"nasal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embeddings.embeddings import VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = VectorStore(\n",
    "    collection_name=\"snomed_sample_smoker\", # sample\n",
    "    index_name=\"apollo-mappings\",\n",
    "    vectorstore_type=\"pinecone\",\n",
    "    embedding_type=\"openai\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SearchResult(text='Bye!', metadata={'seq_num': 1.0, 'source': '/Users/hanna/openfn/ai_experiments/data/example.json'}, score=None),\n",
       " SearchResult(text='Bye!', metadata={'seq_num': 1.0, 'source': '/Users/hanna/openfn/ai_experiments/data/example.json'}, score=None)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.search(\"nasal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.search(\"nasal\", search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.88})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = VectorStore(\n",
    "    collection_name=\"loinc-mappings\",\n",
    "    index_name=\"apollo-mappings\",\n",
    "    vectorstore_type=\"pinecone\",\n",
    "    embedding_type=\"openai\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SearchResult(text='{\"LONG_COMMON_NAME\": \"Physical findings of Nasal septum\", \"METHOD_TYP\": \"Observed\", \"CLASS\": \"H&P.PX\", \"SYSTEM\": \"Nasal septum\"}', metadata={'CLASS': 'H&P.PX', 'LONG_COMMON_NAME': 'Physical findings of Nasal septum', 'METHOD_TYP': 'Observed', 'SYSTEM': 'Nasal septum'}, score=None),\n",
       " SearchResult(text='{\"LONG_COMMON_NAME\": \"Color of Nasal fluid\", \"METHOD_TYP\": \"\", \"CLASS\": \"SPEC\", \"SYSTEM\": \"Nasal fluid\"}', metadata={'CLASS': 'SPEC', 'LONG_COMMON_NAME': 'Color of Nasal fluid', 'METHOD_TYP': '', 'SYSTEM': 'Nasal fluid'}, score=None)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.search(\"nasal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SearchResult(text='{\"LONG_COMMON_NAME\": \"Physical findings of Nasal septum\", \"METHOD_TYP\": \"Observed\", \"CLASS\": \"H&P.PX\", \"SYSTEM\": \"Nasal septum\"}', metadata={'CLASS': 'H&P.PX', 'LONG_COMMON_NAME': 'Physical findings of Nasal septum', 'METHOD_TYP': 'Observed', 'SYSTEM': 'Nasal septum'}, score=None),\n",
       " SearchResult(text='{\"LONG_COMMON_NAME\": \"Color of Nasal fluid\", \"METHOD_TYP\": \"\", \"CLASS\": \"SPEC\", \"SYSTEM\": \"Nasal fluid\"}', metadata={'CLASS': 'SPEC', 'LONG_COMMON_NAME': 'Color of Nasal fluid', 'METHOD_TYP': '', 'SYSTEM': 'Nasal fluid'}, score=None),\n",
       " SearchResult(text='{\"LONG_COMMON_NAME\": \"Rhinovirus+Enterovirus RNA [Presence] in Nasopharynx by NAA with non-probe detection\", \"METHOD_TYP\": \"Non-probe.amp.tar\", \"CLASS\": \"MICRO\", \"SYSTEM\": \"Nph\"}', metadata={'CLASS': 'MICRO', 'LONG_COMMON_NAME': 'Rhinovirus+Enterovirus RNA [Presence] in Nasopharynx by NAA with non-probe detection', 'METHOD_TYP': 'Non-probe.amp.tar', 'SYSTEM': 'Nph'}, score=None),\n",
       " SearchResult(text='{\"LONG_COMMON_NAME\": \"Basophils [Presence] in Nose by Light microscopy\", \"METHOD_TYP\": \"Microscopy.light\", \"CLASS\": \"HEM/BC\", \"SYSTEM\": \"Nose\"}', metadata={'CLASS': 'HEM/BC', 'LONG_COMMON_NAME': 'Basophils [Presence] in Nose by Light microscopy', 'METHOD_TYP': 'Microscopy.light', 'SYSTEM': 'Nose'}, score=None)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.search(\"nasal\", search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.88})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = VectorStore(\n",
    "    collection_name=\"snomed-mappings\",\n",
    "    index_name=\"apollo-mappings\",\n",
    "    vectorstore_type=\"pinecone\",\n",
    "    embedding_type=\"openai\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SearchResult(text='{\"Value Set Name\": \"Body Site Value Set\", \"Description\": \"Entire mucous membrane of nasal cavity and nasal sinus (body structure)\", \"Purpose: Clinical Focus\": \"All SNOMED CT anatomic structures, locations, abnormal structures that can be considered to describe an anatomical site.\"}', metadata={'Code': 736508000.0, 'Description': 'Entire mucous membrane of nasal cavity and nasal sinus (body structure)', 'Purpose: Clinical Focus': 'All SNOMED CT anatomic structures, locations, abnormal structures that can be considered to describe an anatomical site.', 'Value Set Name': 'Body Site Value Set'}, score=None),\n",
       " SearchResult(text='{\"Value Set Name\": \"Body Site Value Set\", \"Description\": \"Entire mucous membrane of nasal cavity and nasal sinus (body structure)\", \"Purpose: Clinical Focus\": \"All SNOMED CT anatomic structures, locations, abnormal structures that can be considered to describe an anatomical site.\"}', metadata={'Code': 736508000.0, 'Description': 'Entire mucous membrane of nasal cavity and nasal sinus (body structure)', 'Purpose: Clinical Focus': 'All SNOMED CT anatomic structures, locations, abnormal structures that can be considered to describe an anatomical site.', 'Value Set Name': 'Body Site Value Set'}, score=None)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.search(\"nasal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SearchResult(text='{\"Value Set Name\": \"Body Site Value Set\", \"Description\": \"Entire mucous membrane of nasal cavity and nasal sinus (body structure)\", \"Purpose: Clinical Focus\": \"All SNOMED CT anatomic structures, locations, abnormal structures that can be considered to describe an anatomical site.\"}', metadata={'Code': 736508000.0, 'Description': 'Entire mucous membrane of nasal cavity and nasal sinus (body structure)', 'Purpose: Clinical Focus': 'All SNOMED CT anatomic structures, locations, abnormal structures that can be considered to describe an anatomical site.', 'Value Set Name': 'Body Site Value Set'}, score=None),\n",
       " SearchResult(text='{\"Value Set Name\": \"Body Site Value Set\", \"Description\": \"Entire mucous membrane of nasal cavity and nasal sinus (body structure)\", \"Purpose: Clinical Focus\": \"All SNOMED CT anatomic structures, locations, abnormal structures that can be considered to describe an anatomical site.\"}', metadata={'Code': 736508000.0, 'Description': 'Entire mucous membrane of nasal cavity and nasal sinus (body structure)', 'Purpose: Clinical Focus': 'All SNOMED CT anatomic structures, locations, abnormal structures that can be considered to describe an anatomical site.', 'Value Set Name': 'Body Site Value Set'}, score=None),\n",
       " SearchResult(text='{\"Value Set Name\": \"Procedure\", \"Description\": \"Aspiration of nasal sinus through natural ostium (procedure)\", \"Purpose: Clinical Focus\": \"A clinical action representing a treatment, an operation, or a process that results in a finding\"}', metadata={'Code': 15936009.0, 'Description': 'Aspiration of nasal sinus through natural ostium (procedure)', 'Purpose: Clinical Focus': 'A clinical action representing a treatment, an operation, or a process that results in a finding', 'Value Set Name': 'Procedure'}, score=None),\n",
       " SearchResult(text='{\"Value Set Name\": \"Procedure\", \"Description\": \"Aspiration of nasal sinus through natural ostium (procedure)\", \"Purpose: Clinical Focus\": \"A clinical action representing a treatment, an operation, or a process that results in a finding\"}', metadata={'Code': 15936009.0, 'Description': 'Aspiration of nasal sinus through natural ostium (procedure)', 'Purpose: Clinical Focus': 'A clinical action representing a treatment, an operation, or a process that results in a finding', 'Value Set Name': 'Procedure'}, score=None)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.search(\"nasal\", search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.88})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo see why import doesn't work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openfn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
