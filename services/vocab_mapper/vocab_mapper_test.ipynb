{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hanna/openfn/ai_experiments/apollo/services\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y3/tg4ts42x7bl1ty6zww9fx4bh0000gn/T/ipykernel_15924/1999610401.py:27: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"/Users/hanna/openfn/ai_experiments/data/LOINC-Clinical-Terminology/LoincTableCore.csv\")\n"
     ]
    }
   ],
   "source": [
    "# set path for testing\n",
    "import sys\n",
    "import os\n",
    "parent_dir = os.path.abspath(\"../\")\n",
    "print(parent_dir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import pandas as pd\n",
    "import anthropic\n",
    "from embeddings import snomed_store, loinc_store\n",
    "from embeddings.embeddings import SearchResult\n",
    "\n",
    "load_dotenv(override=True)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "\n",
    "snomed_store = snomed_store.connect_snomed()\n",
    "loinc_store = loinc_store.connect_loinc()\n",
    "\n",
    "# import data to temporarily plug in missing metadata that will be in the vector store\n",
    "df = pd.read_csv(\"/Users/hanna/openfn/ai_experiments/data/LOINC-Clinical-Terminology/LoincTableCore.csv\")\n",
    "loinc_num_dict = dict(zip(df.LONG_COMMON_NAME.to_list(), df.LOINC_NUM.to_list()))\n",
    "\n",
    "# use LLM to get input text CT synonym then search vector store. Also add hybrid search.\n",
    "\n",
    "synonym_expand_system_prompt = \"\"\"\n",
    "You are an assisstant for matching terminology between health record systems. \n",
    "You will be given a source text from one health system, which might be in another language.\n",
    "You should output its equivalent name (the long name, not the code) in LOINC clinical terminology with no further explanation.\n",
    "\"\"\"\n",
    "\n",
    "synonym_expand_user_prompt = \"\"\"\n",
    "Source text to output a LOINC term for: \"{input_text}\"\n",
    "\"\"\"\n",
    "\n",
    "synonym_expand_select_system_prompt = \"\"\"\n",
    "You are an assisstant for matching terminology between health record systems. \n",
    "You will be given a LOINC entry to look for in a list of similar records. You will also be given the original soruce term for context.\n",
    "You should select the correct LOINC entry from the options and output just the LONG_COMMON_NAME and the LOINC_NUMBER separated by a semicolon.\n",
    "\"\"\"\n",
    "\n",
    "synonym_expand_select_user_prompt = \"\"\"\n",
    "Original source term for context: {input_text}\n",
    "LOINC entry to look for: {LLM_guess}\n",
    "LOINC entries to select from: \"{retreived_texts}\"\n",
    "\"\"\"\n",
    "\n",
    "def synonym_method_2(input_query):\n",
    "    # input_query = \"malaria_RDT_result\"\n",
    "\n",
    "    synonym_expand_user_prompt_formatted = synonym_expand_user_prompt.format(input_text=input_query)\n",
    "    message = client.messages.create(\n",
    "        model= \"claude-3-5-sonnet-20241022\", #\"claude-3-5-sonnet-20241022\", #claude-3-5-haiku-20241022\n",
    "        max_tokens=500,\n",
    "        temperature=0,\n",
    "        system=synonym_expand_system_prompt,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": synonym_expand_user_prompt_formatted\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    synonym_expand_answer = message.content[0].text\n",
    "    print(f\"LLM guess for the CT: {synonym_expand_answer}\")\n",
    "    synonym_expand_retreived_data = loinc_store.search(input_query, search_kwargs={\"k\": 100})\n",
    "\n",
    "    # add keyword search to conduct hybrid search\n",
    "    keyword_search_results = df[df[\"LONG_COMMON_NAME\"].str.contains(synonym_expand_answer)].LONG_COMMON_NAME.to_list()\n",
    "    keyword_search_results = [SearchResult(text=json.dumps({\"LONG_COMMON_NAME\": s}), metadata={}, score=None) for s in keyword_search_results]\n",
    "    search_results_combined = keyword_search_results+synonym_expand_retreived_data\n",
    "\n",
    "    # temp fix for missing loinc numbers\n",
    "    search_results_combined = [SearchResult(text=r.text, metadata={**r.metadata, 'LOINC_NUMBER': loinc_num_dict.get(json.loads(r.text)['LONG_COMMON_NAME'])}, score=r.score) for r in search_results_combined]\n",
    "    synonym_expand_select_user_prompt_formatted = synonym_expand_select_user_prompt.format(input_text=input_query, LLM_guess=synonym_expand_answer, retreived_texts=search_results_combined)\n",
    "    message = client.messages.create(\n",
    "        model= \"claude-3-5-sonnet-20241022\", #\"claude-3-5-sonnet-20241022\", #claude-3-5-haiku-20241022\n",
    "        max_tokens=500,\n",
    "        temperature=0,\n",
    "        system=synonym_expand_select_system_prompt,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": synonym_expand_select_user_prompt_formatted\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    synonym_expand_select_answer = message.content[0].text\n",
    "    \n",
    "    return synonym_expand_select_answer\n",
    "\n",
    "body_site_step_1_system_prompt = \"\"\"\n",
    "You are an assistant for tagging diagnoses and processes in health records with\n",
    "the correct body sites as defined in SNOMED Clinical Terminology.\n",
    "You will be given an input text from a health record. \n",
    "Simply state the SNOMED body site term for the input.\n",
    "\"\"\"\n",
    "# \n",
    "body_site_step_1_user_prompt = \"\"\"\n",
    "Input to return a body site for: \"{input_text}\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_snomed_bodysite(input_query):\n",
    "\n",
    "    body_site_step_1_user_prompt_formatted = body_site_step_1_user_prompt.format(input_text=input_query.replace(\"_\", \" \"))\n",
    "\n",
    "    message = client.messages.create(\n",
    "        model= \"claude-3-5-sonnet-20241022\", #\"claude-3-5-sonnet-20241022\", #\"claude-3-5-haiku-20241022\"\n",
    "        max_tokens=500,\n",
    "        temperature=0,\n",
    "        system=body_site_step_1_system_prompt,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": body_site_step_1_user_prompt_formatted\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    body_site_answer = message.content[0].text\n",
    "    body_site_snomed_entry = snomed_store.search(body_site_answer, search_kwargs={\"k\": 1})\n",
    "    found_name = body_site_snomed_entry[0].metadata[\"Description\"]\n",
    "    found_code = body_site_snomed_entry[0].metadata[\"Code\"]\n",
    "\n",
    "    return f\"llm guess: {body_site_answer}; matched entry: {found_name};{found_code}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You can test the mapping functions below this cell by changing the text in input_query and running the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM guess for the CT: Tobacco smoking status\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Tobacco smoking status;72166-2'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Synonyms – mapping an input to LOINC terms\n",
    "# Method 2 – LLM outputs what it thinks the term is, then we use it to retreive results using hybrid search (similarity search + keyword search).\n",
    "# We then use the LLM again to pick the correct exact term and the LOINC code.\n",
    "\n",
    "input_query = \"smoking_history\"\n",
    "synonym_method_2(input_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'llm guess: For \"epilepsy\", the relevant SNOMED body site is:\\n\\nBrain structure (entire brain); matched entry: Entire ependyma of brain ventricle (body structure);731442007.0'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Snomed body site mapping\n",
    "# Method 1 – LLM outputs what it thinks the term is, then we use it to retreive results.\n",
    "# Note: Currently the SNOMED code retreival part fails - the retreival step needs fixing.\n",
    "\n",
    "input_query = \"epilepsy\"\n",
    "get_snomed_bodysite(input_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openfn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
