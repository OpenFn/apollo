{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hanna/openfn/ai_experiments/apollo/services\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "parent_dir = os.path.abspath(\"../\")\n",
    "print(parent_dir)\n",
    "sys.path.append(parent_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search_docsite import DocsiteSearch\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import anthropic\n",
    "from embed_docsite import github_utils\n",
    "\n",
    "load_dotenv()\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:pinecone_plugin_interface.logging:Discovering subpackages in _NamespacePath(['/Users/hanna/opt/anaconda3/envs/openfn/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "INFO:pinecone_plugin_interface.logging:Looking for plugins in pinecone_plugins.inference\n",
      "INFO:pinecone_plugin_interface.logging:Installing plugin inference into Pinecone\n",
      "INFO:DocsiteSearch:Metadata filters built\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:DocsiteSearch:Similar documents retreived: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SearchResult(text='---\\ntitle: Asana Adaptor\\n---## About Asana\\n\\n[Asana](https://app.asana.com/) is a web-based project management tool that helps teams organize, plan, collaborate, and execute tasks.## Integration Options\\n\\nAsana supports 2 primary integration options:\\n\\n1. Rest API: Asana has an available REST API that enable external services like OpenFn to pull data from Asana, or push data from external apps to Asana. This option is suited for scheduled, bulk syncs or workflows that must update data in Asana with external information. See [functions](/adaptors/packages/asana-docs) for more on how to use this adaptor to work with the API.\\n\\n2. Webhook: Asana also has a [Webhook or Data Forwarding](https://developers.asana.com/docs/webhooks-guide) to push data from Asana to external systems. This option is suited for real-time, event-based data integration. Check out the Asana [devloper documentation](/adaptors/packages/asana-docs) to learn how to set up a webhook to push data to OpenFn.', metadata={'doc_title': 'asana', 'docs_type': 'adaptor_docs'}, score=None),\n",
       " SearchResult(text='sana-configuration-schema) for more on the required authentication parameters.\\n\\nSee platform docs on [managing credentials](/documentation/manage-projects/manage-credentials) for how to configure a credential in OpenFn. If working locally or if using a Raw JSON credential type, then your configuration will look something like this:```\\n{\\n  \"apiVersion\": \"1.0\",\\n  \"token\": \"sample-tokenyWSJdXBACMLLWMNGgADFA\"\\n}\\n```### Helpful Links\\n\\n1. [API documentation](https://developers.asana.com/docs/overview)### Implementation Examples\\n\\n1. The Wildlife Conservation Society (WCS) - KoboToolBox -> GoogleSheets -> Asana sync: [https://openfn.github.io/ConSoSci/asana/](https://openfn.github.io/ConSoSci/asana/)', metadata={'doc_title': 'asana', 'docs_type': 'adaptor_docs'}, score=None),\n",
       " SearchResult(text=\"Check out the Asana [devloper documentation](/adaptors/packages/asana-docs) to learn how to set up a webhook to push data to OpenFn.## Authentication\\n\\nSee [Asana docs](https://developers.asana.com/docs/authentication) for the latest on supported authentication methods. \\n\\nWhen integrating with Asana via OpenFn, there is one primary authentication method supported: **Personal Access Token (PAT)**. You can generate a personal access token from the Asana [developer console](https://developers.asana.com/docs/personal-access-token).\\n\\nSee this adaptor's [Configuration docs](/adaptors/packages/asana-configuration-schema) for more on the required authentication parameters.\\n\\nSee platform docs on [managing credentials](/documentation/manage-projects/manage-credentials) for how to configure a credential in OpenFn. If working locally or if using a Raw JSON credential type, then your configuration will look something like this:\", metadata={'doc_title': 'asana', 'docs_type': 'adaptor_docs'}, score=None),\n",
       " SearchResult(text='Then, we load\\n(send it to the destination).## Integration platform\\n\\nAn integration platform (e.g., OpenFn) is an application (or set of\\napplications) that help organizations set up, run, and maintain/manage the\\nintegrations between all of their various systems.### iPaaS\\n\\nYou may also see the acronym \"iPaaS\". This stands for integration platform as a\\nservice and is a type of \"software as a service\" (or \"SaaS\"). SaaS is a software\\npurchasing model in which software is paid for only as it is used (often\\nmonth-to-month), rather than purchased up front or given away for free.## Metadata\\n\\nThis is data that tells us about our data. In a table, for example, that\\'s the\\nname of the columns, the number of rows, etc. Metadata is often brought up in\\nconversations about privacy—e.g., regulators might want to ensure that _only\\nmetadata_ is moved from Ministry A to Ministry B, as opposed to personally\\nidentifiable information (PII) about individuals themselves.', metadata={'doc_title': 'glossary', 'docs_type': 'general_docs'}, score=None),\n",
       " SearchResult(text='Otherwise, read on!## Project\\n\\nA Project is an administrative grouping in OpenFn like a \"workspace\".\\n\\nOn the platform (OpenFn/lightning), Projects define who can access your OpenFn\\nworkflow configuration & history. Projects have an owner and one or more\\nCollaborators.\\n\\nIn local deployment and development, Project also corresponds to a\\n[`project.yaml`](/documentation/deploy/portability-versions#v2) file, which\\ndefines a project\\' configuration.\\n\\nIn either case, a Project contains Workflows, Triggers, Credentials, and\\neverything you need to automate and integrate with OpenFn.## Workflow\\n\\n:::tip\\n\\nWorkflows are the **\"what to do\"** part of automation!\\n\\n:::\\n\\nA Workflow is a collection of a Trigger, Steps, Paths, and custom logic\\nconnected together to automate a specific business process or task. A Workflow\\nis configured via the Canvas in the web app, or locally (via code).\\n\\nOpenFn automation centers around [Workflows](/documentation/build/workflows),\\nwhich may have one or multiple Steps. Workflows can be run in real-time (based\\non an event -e.g., new patient registration), on a scheduled basis (e.g., every\\nday at 8am), or manually on-demand.\\n\\nThink of workflow as a set of instructions you might give a staff member (e.g.,\\nplease create a new Patient record in OpenMRS when a form containing a newly\\nregistered client is received from CommCare, export data to DHIS2 every week on\\nFriday 11pm, send SMS with payment confirmation number when payment confirmation\\nmessage is received etc.).\\n\\nCommon Workflows automate:\\n', metadata={'doc_title': 'terminology', 'docs_type': 'general_docs'}, score=None),\n",
       " SearchResult(text='We are committed to constantly evaluating\\nwhat our user base needs most and spending the few resources we have to deliver\\nvalue to them—we simply can\\'t guarantee that what sounds like the \"7th most\\nimportant feature to build\" now will still be on our list in 6 months.At the same time, we strive to be as transparent and inclusive as we can in our\\nplanning processes. We have a big backlog of feature requests and GitHub issues\\n(bug reports, stubs, even partially shaped epics or projects) that are getting\\nvoted up, commented on, and used as inspiration when we\\'re deciding what to\\nprioritize next.\\n\\nRead on to learn more about how we work, how you can see what\\'s coming, and how\\nyou can get involved!\\n\\n:::## What are we currently working on?\\n\\nAll of our team\\'s work is tracked publicly using a GitHub Project. Three key\\nviews give you up-to-the-minute insights on what we\\'re doing and what\\'s on our\\nimmediate roadmap.', metadata={'doc_title': 'openfn-roadmap', 'docs_type': 'general_docs'}, score=None),\n",
       " SearchResult(text='If you capture these 3 elements, user stories can b ean effective way of\\ndetailing integration requirements and starting discussions at your organization\\nabout which requirements are priority.### Example user stories:\\n\\n- **Case Referrals:** As a caseworker, I want to automatically send referral\\n  requests to my partner agency using another case management system, so that I\\n  can securely share case information and quickly notify them when their\\n  services are needed in a crisis situation.\\n- **EMR - HIS:** As a clinic manager, I would like to integrate patient data\\n  from the district clinic electronic medical record system with the national\\n  DHIS2 health information system, so that I can securely and automatically\\n  report on health outcomes for key indicators in my district.\\n- **Kobo Toolbox - MSSQL Database:** As a M&E manager, I want to monitor Kobo\\n  Toolbox survey responses in a central database in real-time, so that I can\\n  better understand data collection activities and program performance across my\\n  research partner sites.', metadata={'doc_title': 'overview', 'docs_type': 'general_docs'}, score=None),\n",
       " SearchResult(text=\"Learn more about how data is structured in Salesforce at the links below:\\n\\n- How data is organized in Salesforce:\\n  https://help.salesforce.com/s/articleView?id=sf.basics_organize_data.htm&type=5\\n- Salesforce objects: https://www.salesforcetutorial.com/salesforce-objects/## Integration Use Cases\\n\\nSalesforce may be used to manage an organization's programs, operations,\\nfundraising, and more. Therefore integrations with 3rd-party apps is a common\\nrequirement.\\n\\nExample user stories:\\n\\n- As a program or M&E manager working in areas with limited internet\\n  connectivity, I would like to collect data on a mobile applicaiton that\\n  supports offline data capture, but then sync the data collected to Salesforce\\n  so that I can centrally monitor field activities and analyze data collected to\\n  evaluate program impact.\\n- As a fundraiser at an NGO, I would like to see all donor information tracked\\n  in Salesforce so that I can better monitor fundraising activities, nurture\\n  relationships with all funders, and manage campaigns.\", metadata={'doc_title': 'salesforce', 'docs_type': 'adaptor_docs'}, score=None),\n",
       " SearchResult(text='This versatile platform caters\\nto a diverse array of needs, serving researchers, NGOs, government agencies, and\\nother entities seeking reliable data collection solutions.## Integration Use Cases:\\n\\nAs SurveyCTO is primarily a mobile data collection tool, often that data needs\\nto be extracted, managed, summarized, and analysed in another system (e.g.,\\ndatabase/data warehouse, analytics tools, and \"MIS\"/data management software\\nlike like DHIS2, Salesforce, etc.).\\n\\nExample user story:\\n\\n- As a program or M&E manager, I would like my field officers to collect data in\\n  places with limited connection availability using SurveyCTO. I want the data\\n  collected to automatically sync to my Tabluea dashboard for visualization and\\n  further analysis.', metadata={'doc_title': 'surveycto', 'docs_type': 'adaptor_docs'}, score=None),\n",
       " SearchResult(text=':::## About the Assistant\\n\\nThe AI Assistant is built on the Claude 3.5 Sonnet model from\\n[Anthropic](https://www.anthropic.com/) and is trained with OpenFn documentation\\nand example job code.\\n\\nAt the moment, the Assistant is only configured to help with job writing. Later\\nversions of the assistant may be rolled out to other pages.\\n\\nAll chat sessions are shared between all users of the project. You can start a\\nnew chat session at any time, or open an old one.\\n\\nInput data and run-time job logs not sent to the model. But we do include\\nyour step code so that the Assistant can provide a contextually relevant answer.## A Note on Responsible AI Usage\\n\\nThe AI assistant is built on emerging Large Language Model (terminology). Like\\nother LLMS and chatbots, its capabilities are impressive, but imperfect.\\n\\nRemember that ultimately, all responses are generated by an algorithm and YOU,\\nthe human in charge, are responsible for how its output is used. You should\\nconsider all responses critically and verify the output where possible.\\n\\nYou can read more about our approach to AI in our\\n[Responsible AI Policy](https://www.openfn.org/ai).', metadata={'doc_title': 'ai-assistant', 'docs_type': 'general_docs'}, score=None)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsite_search = DocsiteSearch(collection_name=\"docsite-20250225\")\n",
    "results = docsite_search.search(\"what's asana\", top_k=10)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc_title': 'asana', 'docs_type': 'adaptor_docs'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:DocsiteSearch:Metadata filters built\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:DocsiteSearch:Similar documents retreived: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SearchResult(text='---\\ntitle: Asana Adaptor\\n---## About Asana\\n\\n[Asana](https://app.asana.com/) is a web-based project management tool that helps teams organize, plan, collaborate, and execute tasks.## Integration Options\\n\\nAsana supports 2 primary integration options:\\n\\n1. Rest API: Asana has an available REST API that enable external services like OpenFn to pull data from Asana, or push data from external apps to Asana. This option is suited for scheduled, bulk syncs or workflows that must update data in Asana with external information. See [functions](/adaptors/packages/asana-docs) for more on how to use this adaptor to work with the API.\\n\\n2. Webhook: Asana also has a [Webhook or Data Forwarding](https://developers.asana.com/docs/webhooks-guide) to push data from Asana to external systems. This option is suited for real-time, event-based data integration. Check out the Asana [devloper documentation](/adaptors/packages/asana-docs) to learn how to set up a webhook to push data to OpenFn.', metadata={'doc_title': 'asana', 'docs_type': 'adaptor_docs'}, score=None),\n",
       " SearchResult(text='sana-configuration-schema) for more on the required authentication parameters.\\n\\nSee platform docs on [managing credentials](/documentation/manage-projects/manage-credentials) for how to configure a credential in OpenFn. If working locally or if using a Raw JSON credential type, then your configuration will look something like this:```\\n{\\n  \"apiVersion\": \"1.0\",\\n  \"token\": \"sample-tokenyWSJdXBACMLLWMNGgADFA\"\\n}\\n```### Helpful Links\\n\\n1. [API documentation](https://developers.asana.com/docs/overview)### Implementation Examples\\n\\n1. The Wildlife Conservation Society (WCS) - KoboToolBox -> GoogleSheets -> Asana sync: [https://openfn.github.io/ConSoSci/asana/](https://openfn.github.io/ConSoSci/asana/)', metadata={'doc_title': 'asana', 'docs_type': 'adaptor_docs'}, score=None),\n",
       " SearchResult(text=\"Check out the Asana [devloper documentation](/adaptors/packages/asana-docs) to learn how to set up a webhook to push data to OpenFn.## Authentication\\n\\nSee [Asana docs](https://developers.asana.com/docs/authentication) for the latest on supported authentication methods. \\n\\nWhen integrating with Asana via OpenFn, there is one primary authentication method supported: **Personal Access Token (PAT)**. You can generate a personal access token from the Asana [developer console](https://developers.asana.com/docs/personal-access-token).\\n\\nSee this adaptor's [Configuration docs](/adaptors/packages/asana-configuration-schema) for more on the required authentication parameters.\\n\\nSee platform docs on [managing credentials](/documentation/manage-projects/manage-credentials) for how to configure a credential in OpenFn. If working locally or if using a Raw JSON credential type, then your configuration will look something like this:\", metadata={'doc_title': 'asana', 'docs_type': 'adaptor_docs'}, score=None)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = docsite_search.search(\"what's asana\", top_k=10, docs_type='adaptor_docs', doc_title='asana')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:DocsiteSearch:Metadata filters built\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:DocsiteSearch:Similar documents retreived: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SearchResult(text='---\\ntitle: Asana Adaptor\\n---## About Asana\\n\\n[Asana](https://app.asana.com/) is a web-based project management tool that helps teams organize, plan, collaborate, and execute tasks.## Integration Options\\n\\nAsana supports 2 primary integration options:\\n\\n1. Rest API: Asana has an available REST API that enable external services like OpenFn to pull data from Asana, or push data from external apps to Asana. This option is suited for scheduled, bulk syncs or workflows that must update data in Asana with external information. See [functions](/adaptors/packages/asana-docs) for more on how to use this adaptor to work with the API.\\n\\n2. Webhook: Asana also has a [Webhook or Data Forwarding](https://developers.asana.com/docs/webhooks-guide) to push data from Asana to external systems. This option is suited for real-time, event-based data integration. Check out the Asana [devloper documentation](/adaptors/packages/asana-docs) to learn how to set up a webhook to push data to OpenFn.', metadata={'doc_title': 'asana', 'docs_type': 'adaptor_docs'}, score=None),\n",
       " SearchResult(text='sana-configuration-schema) for more on the required authentication parameters.\\n\\nSee platform docs on [managing credentials](/documentation/manage-projects/manage-credentials) for how to configure a credential in OpenFn. If working locally or if using a Raw JSON credential type, then your configuration will look something like this:```\\n{\\n  \"apiVersion\": \"1.0\",\\n  \"token\": \"sample-tokenyWSJdXBACMLLWMNGgADFA\"\\n}\\n```### Helpful Links\\n\\n1. [API documentation](https://developers.asana.com/docs/overview)### Implementation Examples\\n\\n1. The Wildlife Conservation Society (WCS) - KoboToolBox -> GoogleSheets -> Asana sync: [https://openfn.github.io/ConSoSci/asana/](https://openfn.github.io/ConSoSci/asana/)', metadata={'doc_title': 'asana', 'docs_type': 'adaptor_docs'}, score=None),\n",
       " SearchResult(text=\"Check out the Asana [devloper documentation](/adaptors/packages/asana-docs) to learn how to set up a webhook to push data to OpenFn.## Authentication\\n\\nSee [Asana docs](https://developers.asana.com/docs/authentication) for the latest on supported authentication methods. \\n\\nWhen integrating with Asana via OpenFn, there is one primary authentication method supported: **Personal Access Token (PAT)**. You can generate a personal access token from the Asana [developer console](https://developers.asana.com/docs/personal-access-token).\\n\\nSee this adaptor's [Configuration docs](/adaptors/packages/asana-configuration-schema) for more on the required authentication parameters.\\n\\nSee platform docs on [managing credentials](/documentation/manage-projects/manage-credentials) for how to configure a credential in OpenFn. If working locally or if using a Raw JSON credential type, then your configuration will look something like this:\", metadata={'doc_title': 'asana', 'docs_type': 'adaptor_docs'}, score=None),\n",
       " SearchResult(text=\"Learn more about how data is structured in Salesforce at the links below:\\n\\n- How data is organized in Salesforce:\\n  https://help.salesforce.com/s/articleView?id=sf.basics_organize_data.htm&type=5\\n- Salesforce objects: https://www.salesforcetutorial.com/salesforce-objects/## Integration Use Cases\\n\\nSalesforce may be used to manage an organization's programs, operations,\\nfundraising, and more. Therefore integrations with 3rd-party apps is a common\\nrequirement.\\n\\nExample user stories:\\n\\n- As a program or M&E manager working in areas with limited internet\\n  connectivity, I would like to collect data on a mobile applicaiton that\\n  supports offline data capture, but then sync the data collected to Salesforce\\n  so that I can centrally monitor field activities and analyze data collected to\\n  evaluate program impact.\\n- As a fundraiser at an NGO, I would like to see all donor information tracked\\n  in Salesforce so that I can better monitor fundraising activities, nurture\\n  relationships with all funders, and manage campaigns.\", metadata={'doc_title': 'salesforce', 'docs_type': 'adaptor_docs'}, score=None),\n",
       " SearchResult(text='This versatile platform caters\\nto a diverse array of needs, serving researchers, NGOs, government agencies, and\\nother entities seeking reliable data collection solutions.## Integration Use Cases:\\n\\nAs SurveyCTO is primarily a mobile data collection tool, often that data needs\\nto be extracted, managed, summarized, and analysed in another system (e.g.,\\ndatabase/data warehouse, analytics tools, and \"MIS\"/data management software\\nlike like DHIS2, Salesforce, etc.).\\n\\nExample user story:\\n\\n- As a program or M&E manager, I would like my field officers to collect data in\\n  places with limited connection availability using SurveyCTO. I want the data\\n  collected to automatically sync to my Tabluea dashboard for visualization and\\n  further analysis.', metadata={'doc_title': 'surveycto', 'docs_type': 'adaptor_docs'}, score=None),\n",
       " SearchResult(text=\"---\\ntitle: Kobo Toolbox\\n---## App Overview\\n\\n[Kobo Toolbox](https://www.kobotoolbox.org/) is a suite of open source tools for\\nfield data collection for use in challenging environments. If you've worked on\\nODK or ONA, the underlying tech is very similar. They offer free accounts and\\nhosting for humanitarian projects, and the app provides a nice interface for\\nmanaging (and cleaning!) form submissions.\\n\\n:::note\\n\\nTool docs are (1) to ensure all OpenFn can more quickly and easily integrate\\nwith common tools, and (2) to educate any OpenFn user/the wider sector.\\n\\n:::## Data Model\\n\\nKobo data is collected using `projects` or `forms` which are the actual surveys/\\nquestions being adminsitered. Form responses are collected as individual\\n`form submissions` (1 row for every form submitted is logged in the Kobo web\\napp, viewable via the `Data` menu option).\", metadata={'doc_title': 'kobotoolbox', 'docs_type': 'adaptor_docs'}, score=None),\n",
       " SearchResult(text=\"- As a fundraiser at an NGO, I would like to see all donor information tracked\\n  in Salesforce so that I can better monitor fundraising activities, nurture\\n  relationships with all funders, and manage campaigns.## APIs & Integration Options\\n\\nSalesforce has a rich ecosystem of developers and ready-made applications. See\\nthe [Salesforce App Exchange](https://appexchange.salesforce.com/) for existing\\napps and integrations custom-made for Salesforce. If existing applications do\\nnot meet your functional or budget requirements, leverage Salesforce's robust\\nAPIs to configure a custom integration.\\n\\n1. **APIs:** Salesforce has a robust set of RESTful APIs that support a wide\\n   range of operations. For connecting with these APIs, including the\\n   `Bulk API`, OpenFn has developed a robust API adaptor for quicker integration\\n   setup - see\\n   [`language-salesforce`](https://github.com/OpenFn/language-salesforce).\\n2. **Webhook:** By configuring\\n   [`Outbound Messages`](https://developer.salesforce.com/docs/atlas.en-us.api.meta/api/sforce_api_om_outboundmessaging_understanding.htm)\\n   that can be sent via criteria-based `Workflow Rules`, Salesforce Admins can\", metadata={'doc_title': 'salesforce', 'docs_type': 'adaptor_docs'}, score=None),\n",
       " SearchResult(text=\"---\\ntitle: CKAN\\n---## App Overview\\n\\nCKAN (Comprehensive Knowledge Archive Network) is the world’s leading\\nopen-source data portal platform. CKAN makes it easy to publish, share and work\\nwith data. It's a data management system that provides a powerful platform for\\ncataloging, storing and accessing datasets with a rich front-end, full API (for\\nboth data and catalog), visualization tools and more.\\n\\nCKAN is a tool for making open data websites. It helps you manage and publish\\ncollections of data. It is used by national and local governments, research\\ninstitutions, and other organizations who collect a lot of data. See the public\\ndocumentation for more:\\n\\n- https://ckan.org/\\n- https://docs.ckan.org/en/2.9/user-guide.html#what-is-ckan\", metadata={'doc_title': 'ckan', 'docs_type': 'adaptor_docs'}, score=None),\n",
       " SearchResult(text='---\\ntitle: Salesforce\\n---## App Overview\\n\\n[Salesforce](https://www.salesforce.com/) is a cloud-based **customer\\nrelationship management (CRM)** platform that hosts applications that customers\\ncan access online. Beyond its core CRM product, Salesforce offers a customizable\\nplatform for configuring relational databases, business automation, web portals,\\nreporting tools, and robust applications for supporting a wide range of use\\ncases.### Data Model\\n\\nAt its core, Salesforce is a relational database. It has some out-of-box or\\n\"standard\" data tables and features, but can be easily extended to include\\n\"custom\" metadata configuration and other app features.\\n\\nSalesforce data is stored in **individual records (rows)** and organized within\\n**objects (tables)**. Record attributes are captured in **fields (columns)**.\\nThe data model is configurable, but there are some standard objects that are\\nprovided. Note that naming conventions for custom and standard metadata may\\ndiffer (e.g., all \"custom\" field names include the suffix `__c` like\\n`CustomField__c`).\\n\\nLearn more about how data is structured in Salesforce at the links below:\\n\\n- How data is organized in Salesforce:\\n  https://help.salesforce.com/s/articleView?id=sf.basics_organize_data.htm&type=5\\n- Salesforce objects: https://www.salesforcetutorial.com/salesforce-objects/', metadata={'doc_title': 'salesforce', 'docs_type': 'adaptor_docs'}, score=None),\n",
       " SearchResult(text='In the following sections, special systems will be described.#### Example user stories\\n\\n1 Logistics Management(LMIS)\\n\\n- LMIS is an area where a multitude of parallel, overlapping or competing\\n  software solutions can be found in a single country\\n- Although a basic LMIS configuration based on aggregate data can take you very\\n  far, in some cases a transactional LMIS is necessary if you need to track such\\n  detailed operations as returns, transfer between facilities, barcode reading,\\n  batch and expiry managemen\\n- In such a situation...\\n\\n2 Data Sharing for Health and Nutrition, Water Sanitation and Hygiene Projects\\n\\n- Case management sytsems such as CommCare are widely preffered in collecting\\n  case data(or patient level data) due to its dominance in the sector and easy\\n  of adoption. In such scenarios, ...\\n\\n3 DHIS2 Instance Synchronization\\n\\n- Different DHIS2 instances in a given organisation or government ministry may\\n  be deployed on separate servers which places the need for synchronization in', metadata={'doc_title': 'dhis2', 'docs_type': 'adaptor_docs'}, score=None)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = docsite_search.search(\"what's asana\", top_k=10, docs_type='adaptor_docs')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['adaptor_functions_chunks', 'adaptor_docs_chunks', 'general_docs_chunks'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "folder = \"/Users/hanna/openfn/ai_experiments/apollo/services/tmp/split_sections\"\n",
    "files = [\"adaptor_functions_chunks.json\", \"adaptor_docs_chunks.json\", \"general_docs_chunks.json\"]\n",
    "doc_dict = {}\n",
    "for file in files:\n",
    "    with open(f\"{folder}/{file}\") as f:\n",
    "        data = json.load(f)\n",
    "        doc_dict[file[:-5]] = data\n",
    "doc_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adaptor_functions_chunks\n",
      "315\n",
      "adaptor_docs_chunks\n",
      "171\n",
      "general_docs_chunks\n",
      "596\n"
     ]
    }
   ],
   "source": [
    "for d in doc_dict.keys():\n",
    "    print(f\"{d}\")\n",
    "    print(len(doc_dict[d]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:GitHubUtils:Fetched 38 URLs from GitHub for https://api.github.com/repos/OpenFn/docs/contents/adaptors\n",
      "INFO:GitHubUtils:Downloaded and processed 38 files from GitHub\n",
      "INFO:GitHubUtils:{'name': 'asana.md', 'docs': '---\\ntitle: Asana Adaptor\\n---\\n\\n## About Asana\\n\\n[Asana](https://app.asana.com/) is a web-based project management tool that helps teams organize, plan, collaborate, and execute tasks. \\n\\n## Integration Options\\n\\nAsana supports 2 primary integration options:\\n\\n1. Rest API: Asana has an available REST API that enable external services like OpenFn to pull data from Asana, or push data from external apps to Asana. This option is suited for scheduled, bulk syncs or workflows that must update data in Asana with external information. See [functions](/adaptors/packages/asana-docs) for more on how to use this adaptor to work with the API.\\n\\n2. Webhook: Asana also has a [Webhook or Data Forwarding](https://developers.asana.com/docs/webhooks-guide) to push data from Asana to external systems. This option is suited for real-time, event-based data integration. Check out the Asana [devloper documentation](/adaptors/packages/asana-docs) to learn how to set up a webhook to push data to OpenFn.\\n\\n## Authentication\\n\\nSee [Asana docs](https://developers.asana.com/docs/authentication) for the latest on supported authentication methods. \\n\\nWhen integrating with Asana via OpenFn, there is one primary authentication method supported: **Personal Access Token (PAT)**. You can generate a personal access token from the Asana [developer console](https://developers.asana.com/docs/personal-access-token).\\n\\nSee this adaptor\\'s [Configuration docs](/adaptors/packages/asana-configuration-schema) for more on the required authentication parameters.\\n\\nSee platform docs on [managing credentials](/documentation/manage-projects/manage-credentials) for how to configure a credential in OpenFn. If working locally or if using a Raw JSON credential type, then your configuration will look something like this:\\n\\n```\\n{\\n  \"apiVersion\": \"1.0\",\\n  \"token\": \"sample-tokenyWSJdXBACMLLWMNGgADFA\"\\n}\\n```\\n\\n### Helpful Links\\n\\n1. [API documentation](https://developers.asana.com/docs/overview)\\n\\n### Implementation Examples\\n\\n1. The Wildlife Conservation Society (WCS) - KoboToolBox -> GoogleSheets -> Asana sync: [https://openfn.github.io/ConSoSci/asana/](https://openfn.github.io/ConSoSci/asana/)\\n\\n\\n\\n\\n'}\n",
      "INFO:GitHubUtils:Fetched 82 URLs from GitHub for https://api.github.com/repos/OpenFn/docs/contents/docs\n",
      "INFO:GitHubUtils:Downloaded and processed 82 files from GitHub\n",
      "INFO:GitHubUtils:{'name': 'build-compliant-apps.md', 'docs': '---\\ntitle: Developing connected applications\\nsidebar_label: Building compliant APIs\\n---\\n\\nThis section is for you if you are hoping to build or extend an existing\\napplication that can connect to OpenFn. We follow modern web-standard JSON API\\nguidelines.\\n\\nFor your application to a be data provider (or \"source\") for OpenFn\\nintegrations, we highly recommend that you create a \"notifications service\"\\n(sometimes called a \"webhooks service\" or \"event-based push API\"). This is\\npreferable to using a REST api for two reasons: (1) A notifications service will\\ngive your clients the ability to set up real-time integrations, and (2) a\\nnotifications service is more efficient for both your servers and OpenFn—instead\\nof having requests be made and handled every X seconds, your servers and\\nOpenFn\\'s servers will only work when new data is available.\\n\\nFor your application to be a consumer (or \"destination\") for OpenFn, you must\\neither have a standard, JSON-based REST API or create a language-package that\\nmeets your API specifications.\\n\\n## Sending data to OpenFn\\n\\nTo send data to OpenFn, your application must be able to make an HTTPS post to\\nan external URL with a valid JSON object as the post body. See the following\\nexample using cURL:\\n\\n```sh\\ncurl -X POST \\\\\\n  -H \"Content-Type: application/json\" \\\\\\n  -H \"Cache-Control: no-cache\" \\\\\\n  -d \\'{\"foo\":\"bar\", \"baz\":\"qux\"}\\' \\\\\\n  \"https://app.openfn.org/i/some-secret-inbox-uuid\"\\n```\\n\\nOpenFn will respond with a 200 and an empty JSON object in the event of a\\nsuccessful post. 400s mean that the user\\'s external URL is wrong, and 500s means\\nthat there is an application error on OpenFn. While 500s are rare, they could be\\ndue to invalid JSON in your POST body.\\n\\nIf you cannot notify an external URL when some event takes place, you can still\\nintegrate with OpenFn if you have a JSON-based REST API. OpenFn users can make\\nHTTP GET requests to your application and perform additional actions based on\\nyour response. You should allow either basic or token authentication and\\nresponse to a valid GET with JSON. There is no specific format for your\\nresponse, as users can parse it any way they\\'d like, extracting relevant data\\nand then performing other actions—like loading it into a destination system—with\\nthat data. See [language-http](https://www.github.com/openfn/language-http) for\\ndetails on how users make these generic HTTP requests.\\n\\n### Payload sizing\\n\\nIf you\\'re using the platform, and you\\'re not planning on using an enterprise\\nplan you\\'ll have to consider the size of the data you\\'re sending in each\\npayload. Run `state` is typically limited to `10MB` and you should therefore\\nkeep your payloads well below that limit.\\n\\n## Receiving data from OpenFn\\n\\nTo make it easy for users to connect to your application, it\\'s highly\\nrecommended that you create a language-package with your required authentication\\nand a set of simple, allowable actions nicely abstracted into \"helper\\nfunctions\". See [language-dhis2](https://www.github.com/openfn/language-dhis2)\\nfor an example of a language-package which creates a simpler interface for a\\ntraditional JSON-based REST api. Adaptors are written in Javascript and execute\\nin Node. You can convert OpenFn\\'s JSON into XML, or any other format before\\nsending it to your application and you may make use of any node modules you\\'d\\nlike. See\\n[language-postgresql](https://www.github.com/openfn/language-postgresql) for an\\nexample of an adaptor that connects directly to PostgreSQL databases using a\\npopular NPM module called \"pg\".\\n\\nTo receive data from OpenFn\\'s generic `language-http` adaptor, your application\\nmust allow either basic, token, or digest authenticated POST, PUT, or GET\\nrequests. (Though it is not advisable to create an API that requires GET\\nrequests to create or update data.)\\n'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'build-compliant-apps.md',\n",
       "  'docs': '---\\ntitle: Developing connected applications\\nsidebar_label: Building compliant APIs\\n---\\n\\nThis section is for you if you are hoping to build or extend an existing\\napplication that can connect to OpenFn. We follow modern web-standard JSON API\\nguidelines.\\n\\nFor your application to a be data provider (or \"source\") for OpenFn\\nintegrations, we highly recommend that you create a \"notifications service\"\\n(sometimes called a \"webhooks service\" or \"event-based push API\"). This is\\npreferable to using a REST api for two reasons: (1) A notifications service will\\ngive your clients the ability to set up real-time integrations, and (2) a\\nnotifications service is more efficient for both your servers and OpenFn—instead\\nof having requests be made and handled every X seconds, your servers and\\nOpenFn\\'s servers will only work when new data is available.\\n\\nFor your application to be a consumer (or \"destination\") for OpenFn, you must\\neither have a standard, JSON-based REST API or create a language-package that\\nmeets your API specifications.\\n\\n## Sending data to OpenFn\\n\\nTo send data to OpenFn, your application must be able to make an HTTPS post to\\nan external URL with a valid JSON object as the post body. See the following\\nexample using cURL:\\n\\n```sh\\ncurl -X POST \\\\\\n  -H \"Content-Type: application/json\" \\\\\\n  -H \"Cache-Control: no-cache\" \\\\\\n  -d \\'{\"foo\":\"bar\", \"baz\":\"qux\"}\\' \\\\\\n  \"https://app.openfn.org/i/some-secret-inbox-uuid\"\\n```\\n\\nOpenFn will respond with a 200 and an empty JSON object in the event of a\\nsuccessful post. 400s mean that the user\\'s external URL is wrong, and 500s means\\nthat there is an application error on OpenFn. While 500s are rare, they could be\\ndue to invalid JSON in your POST body.\\n\\nIf you cannot notify an external URL when some event takes place, you can still\\nintegrate with OpenFn if you have a JSON-based REST API. OpenFn users can make\\nHTTP GET requests to your application and perform additional actions based on\\nyour response. You should allow either basic or token authentication and\\nresponse to a valid GET with JSON. There is no specific format for your\\nresponse, as users can parse it any way they\\'d like, extracting relevant data\\nand then performing other actions—like loading it into a destination system—with\\nthat data. See [language-http](https://www.github.com/openfn/language-http) for\\ndetails on how users make these generic HTTP requests.\\n\\n### Payload sizing\\n\\nIf you\\'re using the platform, and you\\'re not planning on using an enterprise\\nplan you\\'ll have to consider the size of the data you\\'re sending in each\\npayload. Run `state` is typically limited to `10MB` and you should therefore\\nkeep your payloads well below that limit.\\n\\n## Receiving data from OpenFn\\n\\nTo make it easy for users to connect to your application, it\\'s highly\\nrecommended that you create a language-package with your required authentication\\nand a set of simple, allowable actions nicely abstracted into \"helper\\nfunctions\". See [language-dhis2](https://www.github.com/openfn/language-dhis2)\\nfor an example of a language-package which creates a simpler interface for a\\ntraditional JSON-based REST api. Adaptors are written in Javascript and execute\\nin Node. You can convert OpenFn\\'s JSON into XML, or any other format before\\nsending it to your application and you may make use of any node modules you\\'d\\nlike. See\\n[language-postgresql](https://www.github.com/openfn/language-postgresql) for an\\nexample of an adaptor that connects directly to PostgreSQL databases using a\\npopular NPM module called \"pg\".\\n\\nTo receive data from OpenFn\\'s generic `language-http` adaptor, your application\\nmust allow either basic, token, or digest authenticated POST, PUT, or GET\\nrequests. (Though it is not advisable to create an API that requires GET\\nrequests to create or update data.)\\n'},\n",
       " {'name': 'build-with-api.md',\n",
       "  'docs': '---\\nid: build-with-api\\ntitle: Build Projects via the OpenFn API\\nsidebar_label: Build with the API\\nslug: /build-with-api\\n---\\n\\nOpenFn offers the ability to configure projects via HTTP requests sent to the REST API. See the [OpenFn/Lightning GitHub repo](https://openfn.github.io/lightning/provisioning.html) for detailed developer documentation. \\n'}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "doc_types = [\"adaptor_functions\", \"adaptor_docs\", \"general_docs\"]\n",
    "# doc_types = [\"adaptor_functions\"]\n",
    "doc_dict = {}\n",
    "for d in doc_types:\n",
    "    doc_list = github_utils.get_docs(docs_type=d)\n",
    "    doc_dict[d] = doc_list\n",
    "\n",
    "doc_dict[d][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['build-compliant-apps',\n",
       " 'build-with-api',\n",
       " 'cli-challenges',\n",
       " 'cli-collections',\n",
       " 'cli-intro']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genral_docs_topics = [d[\"name\"][:-3] for d in doc_dict[\"general_docs\"]]\n",
    "genral_docs_topics[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['asana', 'cht', 'ckan', 'collections', 'commcare']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaptor_docs_topics = [d[\"name\"][:-3] for d in doc_dict[\"adaptor_docs\"]]\n",
    "print(len(adaptor_docs_topics))\n",
    "adaptor_docs_topics[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Test SQLite for searching by column value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an assistant for a solutions engineer helping a user write a job for our platform.\n",
    "Our platform is OpenFn (Open Function Group), the world's leading digital public good for workflow automation.\n",
    "Your job is to decide whether the user question requires consulting our documentation. If the question is\n",
    "about general coding advice or other external information, we do not need to consult the documentation. \n",
    "\n",
    "Answer nothing but YES or NO.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"The user question is as follows: \"{user_question}\" \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_question = \"How to inverse columns in javascript\"\n",
    "# user_question = \"Given a JSON data, and given a list of columns in an sql table, give me an insert query\"\n",
    "# user_question = \"\"\"write a job for me that creates new datavaluesets under the \"Approved School CHP\" organization unit\"\"\"\n",
    "# user_question = \"\"\"How to get data from asana in my job\"\"\"\n",
    "# user_question = \"What's the difference between a Trigger and a Step in a workflow?\"\n",
    "user_question = \"“Can I write a step that allows for creation of an JSON file of the transformed records that can be sent to an email or Google Drive”\"\n",
    "# user_question = \"Why does this part of the code only POST the first submission in the submissions[] array? I want to POST _each_ submission. each( '$.submissions[*]', post(URL, { body: () => {} ))”\"\n",
    "# user_question = \"write a job to fetch for an attribute in the input and map it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "YES\n"
     ]
    }
   ],
   "source": [
    "# Needs docs YES/NO ?\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20241022\", # TODO change to cheaper model\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    system=system_prompt,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": user_prompt.format(user_question=user_question)\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which search AND how?\n",
    "\n",
    "# system_prompt = \"\"\"\n",
    "# You are an assistant for a solutions engineer helping a user write a job for our platform.\n",
    "# Our platform is OpenFn (Open Function Group), the world's leading digital public good for workflow automation.\n",
    "# Your job is to query the documenation based on the user's question.  \n",
    "\n",
    "# Your answer should detail one or more searches that should be done on the documentation.\n",
    "# The options for search types are: \n",
    "# a) semantic search \n",
    "# b) direct retrieval by section (options: \"adaptor_documentation\", \"general_documentation\")\n",
    "\n",
    "# Answer in nothing but code, using one or both of these functions, one or more times, filling in an appropriate input: \n",
    "\n",
    "# semantic_search(query)\n",
    "# database_search(documentation_section)\n",
    "# \"\"\"\n",
    "#  ------------------------------\n",
    "# system_prompt = \"\"\"\n",
    "# You are an assistant for a solutions engineer helping a user write a job for our platform.\n",
    "# Our platform is OpenFn (Open Function Group), the world's leading digital public good for workflow automation.\n",
    "# Your job is to query the documenation based on the user's question.  \n",
    "\n",
    "# Your answer should detail one or more searches that should be done on the documentation.\n",
    "# The options for search types are: \n",
    "# a) semantic search \n",
    "# b) direct retrieval by section (options: \"adaptor_documentation\", \"general_documentation\")\n",
    "\n",
    "# You can use one or both of these functions, one or more times: \n",
    "\n",
    "# semantic_search(query)\n",
    "# database_search(documentation_section_query)\n",
    "\n",
    "# list which ones you would like to use in dictionaries on new lines:\n",
    "# {\"function\": \"semantic_search\", \"query\": \"your_query\"}\n",
    "# {\"function\":\"database_search\", \"query\": \"adaptor_documentation\"}\n",
    "\n",
    "# Return nothing but this list of dictionaries with \"function\" and \"query\" keys.\n",
    "# \"\"\"\n",
    "#  ------------------------------\n",
    "system_prompt = \"\"\"\n",
    "You are an assistant for a solutions engineer helping a user write a job for our platform.\n",
    "Our platform is Open Function, a platform for workflow automation.\n",
    "Your job is to run search queries on the documentation based on the user's question.  \n",
    "\n",
    "Your answer should detail the searches that should be done on the documentation.\n",
    "Stick to one search query only per topic. If the user question requires information across\n",
    "distinct topics (e.g. two different adaptors; CLI and API instructions), then list additional queries.\n",
    "\n",
    "A search consists of a query string, and an optional filter for doc_type. \n",
    "This can be either adaptor_documentation or general_documentation.\n",
    "If the filter is adaptor_documentation, then the query should be just the name of the adaptor.\n",
    "\n",
    "List your searches in dictionaries on new lines:\n",
    "{\"query\": \"your_query\", \"doc_type\": None}\n",
    "{\"query\": \"optional_second_query\", \"doc_type\":\"adaptor_documentation\"}\n",
    "\n",
    "\n",
    "Return nothing but this list of dictionaries.\n",
    "\"\"\"\n",
    "#  ------------------------------\n",
    "\n",
    "user_prompt = \"\"\"The user question is as follows: \"{user_question}\" \"\"\"\n",
    "\n",
    "# # fucnution plus query\n",
    "# response_schemas = [\n",
    "#     ResponseSchema(name=\"function\", description=\"The function to be called\"),\n",
    "#     ResponseSchema(name=\"query\", description=\"The query for the function\")\n",
    "# ]\n",
    "\n",
    "# parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "# query plus filter\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"query\", description=\"The function to be called\"),\n",
    "    ResponseSchema(name=\"doc_type\", description=\"The doc_type filter for the function\")\n",
    "]\n",
    "\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "def search_docs(user_question):\n",
    "    message = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241022\", # TODO change to cheaper model\n",
    "        max_tokens=1000,\n",
    "        temperature=0,\n",
    "        system=system_prompt,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": user_prompt.format(user_question=user_question)\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    text = message.content[0].text\n",
    "    # print(text)\n",
    "    answer_parsed = [parser.parse(a) for a in text.split(\"\\n\")]\n",
    "\n",
    "    return answer_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "{\"function\": \"semantic_search\", \"query\": \"difference between trigger and step in workflow\"}\n",
      "{\"function\": \"database_search\", \"query\": \"general_documentation\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'function': 'semantic_search',\n",
       "  'query': 'difference between trigger and step in workflow'},\n",
       " {'function': 'database_search', 'query': 'general_documentation'}]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer = search_docs(user_question)\n",
    "# print(answer)\n",
    "# answer_parsed = [parser.parse(a) for a in answer.split(\"\\n\")]\n",
    "# answer_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "[{'query': 'asana', 'doc_type': 'adaptor_documentation'}]\n"
     ]
    }
   ],
   "source": [
    "answer = search_docs(user_question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:DocsiteSearch:Metadata filters built\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:DocsiteSearch:Similar documents retreived: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SearchResult(text='---\\ntitle: Asana Adaptor\\n---## About Asana\\n\\n[Asana](https://app.asana.com/) is a web-based project management tool that helps teams organize, plan, collaborate, and execute tasks.## Integration Options\\n\\nAsana supports 2 primary integration options:\\n\\n1. Rest API: Asana has an available REST API that enable external services like OpenFn to pull data from Asana, or push data from external apps to Asana. This option is suited for scheduled, bulk syncs or workflows that must update data in Asana with external information. See [functions](/adaptors/packages/asana-docs) for more on how to use this adaptor to work with the API.\\n\\n2. Webhook: Asana also has a [Webhook or Data Forwarding](https://developers.asana.com/docs/webhooks-guide) to push data from Asana to external systems. This option is suited for real-time, event-based data integration. Check out the Asana [devloper documentation](/adaptors/packages/asana-docs) to learn how to set up a webhook to push data to OpenFn.', metadata={'doc_title': 'asana', 'docs_type': 'adaptor_docs'}, score=None),\n",
       " SearchResult(text='If you capture these 3 elements, user stories can b ean effective way of\\ndetailing integration requirements and starting discussions at your organization\\nabout which requirements are priority.### Example user stories:\\n\\n- **Case Referrals:** As a caseworker, I want to automatically send referral\\n  requests to my partner agency using another case management system, so that I\\n  can securely share case information and quickly notify them when their\\n  services are needed in a crisis situation.\\n- **EMR - HIS:** As a clinic manager, I would like to integrate patient data\\n  from the district clinic electronic medical record system with the national\\n  DHIS2 health information system, so that I can securely and automatically\\n  report on health outcomes for key indicators in my district.\\n- **Kobo Toolbox - MSSQL Database:** As a M&E manager, I want to monitor Kobo\\n  Toolbox survey responses in a central database in real-time, so that I can\\n  better understand data collection activities and program performance across my\\n  research partner sites.', metadata={'doc_title': 'overview', 'docs_type': 'general_docs'}, score=None),\n",
       " SearchResult(text='sana-configuration-schema) for more on the required authentication parameters.\\n\\nSee platform docs on [managing credentials](/documentation/manage-projects/manage-credentials) for how to configure a credential in OpenFn. If working locally or if using a Raw JSON credential type, then your configuration will look something like this:```\\n{\\n  \"apiVersion\": \"1.0\",\\n  \"token\": \"sample-tokenyWSJdXBACMLLWMNGgADFA\"\\n}\\n```### Helpful Links\\n\\n1. [API documentation](https://developers.asana.com/docs/overview)### Implementation Examples\\n\\n1. The Wildlife Conservation Society (WCS) - KoboToolBox -> GoogleSheets -> Asana sync: [https://openfn.github.io/ConSoSci/asana/](https://openfn.github.io/ConSoSci/asana/)', metadata={'doc_title': 'asana', 'docs_type': 'adaptor_docs'}, score=None),\n",
       " SearchResult(text=\"Check out the Asana [devloper documentation](/adaptors/packages/asana-docs) to learn how to set up a webhook to push data to OpenFn.## Authentication\\n\\nSee [Asana docs](https://developers.asana.com/docs/authentication) for the latest on supported authentication methods. \\n\\nWhen integrating with Asana via OpenFn, there is one primary authentication method supported: **Personal Access Token (PAT)**. You can generate a personal access token from the Asana [developer console](https://developers.asana.com/docs/personal-access-token).\\n\\nSee this adaptor's [Configuration docs](/adaptors/packages/asana-configuration-schema) for more on the required authentication parameters.\\n\\nSee platform docs on [managing credentials](/documentation/manage-projects/manage-credentials) for how to configure a credential in OpenFn. If working locally or if using a Raw JSON credential type, then your configuration will look something like this:\", metadata={'doc_title': 'asana', 'docs_type': 'adaptor_docs'}, score=None),\n",
       " SearchResult(text='Then, we load\\n(send it to the destination).## Integration platform\\n\\nAn integration platform (e.g., OpenFn) is an application (or set of\\napplications) that help organizations set up, run, and maintain/manage the\\nintegrations between all of their various systems.### iPaaS\\n\\nYou may also see the acronym \"iPaaS\". This stands for integration platform as a\\nservice and is a type of \"software as a service\" (or \"SaaS\"). SaaS is a software\\npurchasing model in which software is paid for only as it is used (often\\nmonth-to-month), rather than purchased up front or given away for free.## Metadata\\n\\nThis is data that tells us about our data. In a table, for example, that\\'s the\\nname of the columns, the number of rows, etc. Metadata is often brought up in\\nconversations about privacy—e.g., regulators might want to ensure that _only\\nmetadata_ is moved from Ministry A to Ministry B, as opposed to personally\\nidentifiable information (PII) about individuals themselves.', metadata={'doc_title': 'glossary', 'docs_type': 'general_docs'}, score=None)]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get adaptor doc by title or rever to semantic search?\n",
    "def get_adaptor_documentation(query):\n",
    "   if query.lower() in adaptor_docs_topics:\n",
    "        target_section = query.lower()\n",
    "   else:\n",
    "    #  search docsite-topics\n",
    "    #  target_section = search_result\n",
    "    # result = fetch_local(doc=target_section)\n",
    "    \n",
    "    return result\n",
    "\n",
    "search_results = []\n",
    "for q in answer:\n",
    "    query_text = q.get(\"query\", \"\")\n",
    "    if query_text:\n",
    "        doc_type = q.get(\"doc_type\", None)\n",
    "        if doc_type == \"adaptor_documentation\":\n",
    "          results = get_adaptor_documentation(query_text)  \n",
    "        # results = docsite_search.search(query_text, top_k=5, docs_type=doc_type)\n",
    "        search_results.extend(results)\n",
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs docs?\n",
    "# parallel a: should we fetch one of more of the following docs sections?\n",
    "# parallel b: llm: run semantic search\n",
    "# dedup & combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick from topics\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are an assistant for a solutions engineer helping a user write a job for our platform.\n",
    "Our platform is OpenFn (Open Function Group), the world's leading digital public good for workflow automation.\n",
    "Your job is to query the documentation based on the user's question.  \n",
    "\n",
    "Your answer should pick titles to retreive from the list below. Where possible, stick to only one title.\n",
    "\n",
    "Titles to pick from:\n",
    "{document_titles}\n",
    "\n",
    "Answer in nothing but the list of titles on new lines.\n",
    "\"\"\"\n",
    "\n",
    "#  ------------------------------\n",
    "\n",
    "user_prompt = \"\"\"The user question is as follows: \"{user_question}\" \"\"\"\n",
    "\n",
    "def select_title(user_question, document_titles):\n",
    "    message = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241022\", # TODO change to cheaper model\n",
    "        max_tokens=1000,\n",
    "        temperature=0,\n",
    "        system=system_prompt.format(document_titles=document_titles),\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": user_prompt.format(user_question=user_question)\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    text = message.content[0].text\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http\\nsftp'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_title(user_question, adaptor_docs_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile test set\n",
    "test_questions = []\n",
    "test_types = [\"platform_questions\", \"specific_coding_questions\", \"workflow_overview_questions\"]\n",
    "for test_type, test in zip(test_types, [platform_questions, specific_coding_questions, workflow_overview_questions]):\n",
    "    questions = [t for t in test.split(\"\\n\")[:10] if t] #TODO limiting size now\n",
    "    for q in questions:\n",
    "        test_questions.append({\"question_type\":test_type, \"question\":q})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Optional, Dict, Any\n",
    "from dataclasses import dataclass\n",
    "from anthropic import (\n",
    "    Anthropic,\n",
    "    APIConnectionError,\n",
    "    BadRequestError,\n",
    "    AuthenticationError,\n",
    "    PermissionDeniedError,\n",
    "    NotFoundError,\n",
    "    UnprocessableEntityError,\n",
    "    RateLimitError,\n",
    "    InternalServerError,\n",
    ")\n",
    "from util import ApolloError, create_logger\n",
    "# from .prompt import build_prompt\n",
    "from job_chat.prompt import build_prompt\n",
    "\n",
    "logger = create_logger(\"job_chat\")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Payload:\n",
    "    \"\"\"\n",
    "    Data class for validating and storing input parameters.\n",
    "    Required fields will raise TypeError if not provided.\n",
    "    \"\"\"\n",
    "\n",
    "    content: str\n",
    "    context: Optional[str] = None\n",
    "    api_key: Optional[str] = None\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, data: Dict[str, Any]) -> \"Payload\":\n",
    "        \"\"\"\n",
    "        Create a Payload instance from a dictionary, validating required fields.\n",
    "        \"\"\"\n",
    "        if \"content\" not in data:\n",
    "            raise ValueError(\"'content' is required\")\n",
    "\n",
    "        return cls(content=data[\"content\"], context=data.get(\"context\"), api_key=data.get(\"api_key\"))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ChatConfig:\n",
    "    model: str = \"claude-3-5-sonnet-20240620\"\n",
    "    max_tokens: int = 1024\n",
    "    api_key: Optional[str] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ChatResponse:\n",
    "    content: str\n",
    "    history: List[Dict[str, str]]\n",
    "    usage: Dict[str, Any]\n",
    "\n",
    "\n",
    "class AnthropicClient:\n",
    "    def __init__(self, config: Optional[ChatConfig] = None):\n",
    "        self.config = config or ChatConfig()\n",
    "        self.api_key = self.config.api_key or os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"API key must be provided\")\n",
    "        self.client = Anthropic(api_key=self.api_key)\n",
    "\n",
    "    def generate(\n",
    "        self, content: str, history: Optional[List[Dict[str, str]]] = None, context: Optional[str] = None\n",
    "    ) -> ChatResponse:\n",
    "        \"\"\"\n",
    "        Generate a response using the Claude API with improved error handling and response processing.\n",
    "        \"\"\"\n",
    "        history = history.copy() if history else []\n",
    "\n",
    "        system_message, prompt = build_prompt(content, history, context)\n",
    "\n",
    "        message = self.client.beta.prompt_caching.messages.create(\n",
    "            max_tokens=self.config.max_tokens, messages=prompt, model=self.config.model, system=system_message\n",
    "        )\n",
    "\n",
    "        if hasattr(message, \"usage\"):\n",
    "            if message.usage.cache_creation_input_tokens:\n",
    "                logger.info(f\"Cache write: {message.usage.cache_creation_input_tokens} tokens\")\n",
    "            if message.usage.cache_read_input_tokens:\n",
    "                logger.info(f\"Cache read: {message.usage.cache_read_input_tokens} tokens\")\n",
    "\n",
    "        response_parts = []\n",
    "        for content_block in message.content:\n",
    "            if content_block.type == \"text\":\n",
    "                response_parts.append(content_block.text)\n",
    "            else:\n",
    "                logger.warning(f\"Unhandled content type: {content_block.type}\")\n",
    "\n",
    "        response = \"\\n\\n\".join(response_parts)\n",
    "\n",
    "        updated_history = history + [\n",
    "            {\"role\": \"user\", \"content\": content},\n",
    "            {\"role\": \"assistant\", \"content\": response},\n",
    "        ]\n",
    "\n",
    "        return ChatResponse(\n",
    "            content=response,\n",
    "            history=updated_history,\n",
    "            usage=message.usage.model_dump() if hasattr(message, \"usage\") else {},\n",
    "        )\n",
    "\n",
    "\n",
    "def main(data_dict: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Main entry point with improved error handling and input validation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = Payload.from_dict(data_dict)\n",
    "\n",
    "        config = ChatConfig(api_key=data.api_key) if data.api_key else None\n",
    "        client = AnthropicClient(config)\n",
    "\n",
    "        result = client.generate(content=data.content, history=data_dict.get(\"history\", []), context=data.context)\n",
    "\n",
    "        return {\"response\": result.content, \"history\": result.history, \"usage\": result.usage}\n",
    "\n",
    "    except ValueError as e:\n",
    "        raise ApolloError(400, str(e), type=\"BAD_REQUEST\")\n",
    "\n",
    "    except APIConnectionError as e:\n",
    "        raise ApolloError(\n",
    "            503,\n",
    "            \"Unable to reach the Anthropic AI Service\",\n",
    "            type=\"CONNECTION_ERROR\",\n",
    "            details={\"cause\": str(e.__cause__)},\n",
    "        )\n",
    "    except AuthenticationError as e:\n",
    "        raise ApolloError(401, \"Authentication failed\", type=\"AUTH_ERROR\")\n",
    "    except RateLimitError as e:\n",
    "        raise ApolloError(\n",
    "            429, \"Rate limit exceeded, please try again later\", type=\"RATE_LIMIT\", details={\"retry_after\": 60}\n",
    "        )\n",
    "    except BadRequestError as e:\n",
    "        raise ApolloError(400, str(e), type=\"BAD_REQUEST\")\n",
    "    except PermissionDeniedError as e:\n",
    "        raise ApolloError(403, \"Not authorized to perform this action\", type=\"FORBIDDEN\")\n",
    "    except NotFoundError as e:\n",
    "        raise ApolloError(404, \"Resource not found\", type=\"NOT_FOUND\")\n",
    "    except UnprocessableEntityError as e:\n",
    "        raise ApolloError(422, str(e), type=\"INVALID_REQUEST\")\n",
    "    except InternalServerError as e:\n",
    "        raise ApolloError(500, \"The Anthropic AI Service encountered an error\", type=\"PROVIDER_ERROR\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error during chat generation: {str(e)}\")\n",
    "        raise ApolloError(500, str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjob_chat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_prompt, Context\n\u001b[0;32m----> 3\u001b[0m apollo_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms asana\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43madaptor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m@openfn/language-http@2.0.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m apollo_prompt\n",
      "File \u001b[0;32m~/openfn/ai_experiments/apollo/services/job_chat/prompt.py:188\u001b[0m, in \u001b[0;36mbuild_prompt\u001b[0;34m(content, history, context)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_prompt\u001b[39m(content, history, context):\n\u001b[0;32m--> 188\u001b[0m     system_message \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_system_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    191\u001b[0m     prompt\u001b[38;5;241m.\u001b[39mextend(history)\n",
      "File \u001b[0;32m~/openfn/ai_experiments/apollo/services/job_chat/prompt.py:163\u001b[0m, in \u001b[0;36mgenerate_system_message\u001b[0;34m(context_dict)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m adaptor_docs:\n\u001b[1;32m    162\u001b[0m     adaptor_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTypescript definitions for doc \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 163\u001b[0m     adaptor_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43madaptor_docs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdescription\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    164\u001b[0m adaptor_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</adaptor>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m message\u001b[38;5;241m.\u001b[39mappend(adaptor_string)\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "from job_chat.prompt import build_prompt, Context\n",
    "\n",
    "apollo_prompt = build_prompt(content=\"What's asana\", history=None, context=Context(adaptor=\"@openfn/language-http@2.0.0\"))\n",
    "apollo_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import create_logger, apollo\n",
    "\n",
    "# logger = create_logger(\"job_chat.prompt\")\n",
    "\n",
    "system_role = \"\"\"\n",
    "You are a software engineer helping a non-expert user write a job for our platform.\n",
    "We are OpenFn (Open Function Group) the world's leading digital public good for workflow automation.\n",
    "\n",
    "Where reasonable, assume questions are related to workflow automation, \n",
    "professional platforms or programming. You may provide general information around these topics, \n",
    "e.g. general programming assistance unrelated to job writing.\n",
    "If a question is entirely irrelevant, do not answer it.\n",
    "\n",
    "You MUST keep your responses concise. Do not explain your answers unless\n",
    "the user explicitly asks you to. When generating code, always use the simplest\n",
    "possible code to achieve the task.\n",
    "\n",
    "Do not thank the user or be obsequious. Address the user directly.\n",
    "\n",
    "You are embedded in our app for building workflows. Our app will provide the\n",
    "history of each chat session to you. Our app will send you the user's code and\n",
    "tell you which adaptor (library) is being used. We will not send you the user's \n",
    "input data, output data, or logs, because they might contain sensitive information. \n",
    "Chat sessions are saved to each job, so any user who can see the workflow can see the chat.\n",
    "\n",
    "Your chat panel is embedded in a web based IDE, which lets users build a Workflow with a number\n",
    "of steps (or jobs). There is a code editor next to you, which users can copy and paste code into.\n",
    "Users must set or select an input in the Input tab, and can then run the current job.\n",
    "\n",
    "Users can Flag any answers that are not helpful, which will help us build a better prompt for you.\n",
    "\"\"\"\n",
    "\n",
    "job_writing_summary = \"\"\"\n",
    "<credential management>\n",
    "When writing jobs, users will use their own credentials to access different\n",
    "backend systems. The OpenFn app handles all credential management for them\n",
    "in a secure way.\n",
    "\n",
    "For more help direct them to https://docs.openfn.org/documentation/build/credentials\n",
    "\n",
    "Users must never add credentials into job code directly. If a user gives you an\n",
    "API key, password, access token, or other credential, you must reject it.\n",
    "</credential management>\n",
    "<job writing guide>\n",
    "An OpenFn Job is written in a DSL which is very similar to Javascript.\n",
    "\n",
    "Job code does not use import statements or async/await.\n",
    "\n",
    "Job code must only contain function calls at the top level.\n",
    "\n",
    "If the user is talking about collections, suggest this: \"For working with collections, refer to the official documentation here: https://docs.openfn.org/adaptors/packages/collections-docs.\".\n",
    "Avoid suggesting code to a user enquiring about collections or a single collection.\n",
    "\n",
    "Each job is associated with an adaptor, which provides functions for the job.\n",
    "All jobs have the fn() and each() function, which are very important.\n",
    "\n",
    "DO NOT use the `alterState()` function. Use `fn()` instead.\n",
    "\n",
    "The adaptor API may be attached.\n",
    "\n",
    "The functions provided by an adaptor are called Operations.\n",
    "Know that technically an Operation is a factory function which returns a function that takes state and returns state, like this:\n",
    "```js\n",
    "const myOperation = (arg) => (state) => { /* do something with arg and state */ return state; }\n",
    "```\n",
    "But the DSL presents these operations like simple functions. Users don't know it's a factory, they think it's a regular function.\n",
    "<examples>\n",
    "<example>\n",
    "Here's how we issue a GET request with the http adaptor:\n",
    "```\n",
    "get('/patients');\n",
    "```\n",
    "The first argument to get is the path to request from (the configuration will tell\n",
    "the adaptor what base url to use). In this case we're passing a static string,\n",
    "but we can also pass a value from state:\n",
    "```\n",
    "get(state => state.endpoint);\n",
    "```\n",
    "</example>\n",
    "<example>\n",
    "Example job code with the HTTP adaptor:\n",
    "```\n",
    "get('/patients');\n",
    "fn(state => {\n",
    "  const patients = state.data.map(p => {\n",
    "    return { ...p, enrolled: true }\n",
    "  });\n",
    "\n",
    "  return { ...state, data: { patients } };\n",
    "})\n",
    "post('/patients', dataValue('patients'));\n",
    "</example>\n",
    "<example>\n",
    "```\n",
    "Example job code with the Salesforce adaptor:\n",
    "```\n",
    "each(\n",
    "  '$.form.participants[*]',\n",
    "  upsert('Person__c', 'Participant_PID__c', state => ({\n",
    "    Participant_PID__c: state.pid,\n",
    "    First_Name__c: state.participant_first_name,\n",
    "    Surname__c: state.participant_surname,\n",
    "  }))\n",
    ");\n",
    "```\n",
    "</example>\n",
    "<example>\n",
    "Example job code with the ODK adaptor:\n",
    "```\n",
    "create(\n",
    "  'ODK_Submission__c',\n",
    "  fields(\n",
    "    field('Site_School_ID_Number__c', dataValue('school')),\n",
    "    field('Date_Completed__c', dataValue('date')),\n",
    "    field('comments__c', dataValue('comments')),\n",
    "    field('ODK_Key__c', dataValue('*meta-instance-id*'))\n",
    "  )\n",
    ");\n",
    "```\n",
    "</example>\n",
    "<examples>\n",
    "</job writing guide>\n",
    "<workflow guide>\n",
    "A job is just one step in a workflow (or pipeline). Workflows are used\n",
    "to automate processes and migrate data from system to system.\n",
    "\n",
    "In OpenFn, each step works with a single backend system, or adaptor. Data is shared\n",
    "between steps through the state object.\n",
    "\n",
    "To build a successful workflow, we have to take the user's problem and break it down\n",
    "step by step. Focus on one bit at a time. For example, when uploading from commcare to salesforce, we have to:\n",
    "1. Download our data from commcare in one step\n",
    "2. Transform/map data into salesforce format in another step (with the common adaptor)\n",
    "3. Upload the transformed data into salesforce in the final step\n",
    "</workflow guide>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Context:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "    def has(self, key):\n",
    "        return hasattr(self, key) and getattr(self, key) is not None\n",
    "\n",
    "\n",
    "def generate_system_message(context_dict):\n",
    "    context = context_dict if isinstance(context_dict, Context) else Context(**context_dict)\n",
    "\n",
    "    message = [system_role]\n",
    "    message.append(f\"<job_writing_guide>{job_writing_summary}</job_writing_guide>\")\n",
    "    message.append({\"type\": \"text\", \"text\": \".\", \"cache_control\": {\"type\": \"ephemeral\"}})\n",
    "\n",
    "    if context.has(\"adaptor\"):\n",
    "        adaptor_string = (\n",
    "            f\"<adaptor>The user is using the OpenFn {context.adaptor} adaptor. Use functions provided by its API.\"\n",
    "        )\n",
    "\n",
    "        adaptor_docs = apollo(\"describe_adaptor\", {\"adaptor\": context.adaptor})\n",
    "\n",
    "        for doc in adaptor_docs:\n",
    "            adaptor_string += f\"Typescript definitions for doc {doc}\"\n",
    "            adaptor_string += adaptor_docs[doc][\"description\"]\n",
    "        adaptor_string += \"</adaptor>\"\n",
    "\n",
    "        message.append(adaptor_string)\n",
    "    else:\n",
    "        message.append(\"The user is using an OpenFn Adaptor to write the job.\")\n",
    "\n",
    "    message.append({\"type\": \"text\", \"text\": \".\", \"cache_control\": {\"type\": \"ephemeral\"}})\n",
    "\n",
    "    if context.has(\"expression\"):\n",
    "        message.append(f\"<user_code>{context.expression}</user_code>\")\n",
    "\n",
    "    if context.has(\"input\"):\n",
    "        message.append(f\"<input>The user's input data is :\\n\\n```{context.input}```</input>\")\n",
    "\n",
    "    if context.has(\"output\"):\n",
    "        message.append(f\"<output>The user's last output data was :\\n\\n```{context.output}```</output>\")\n",
    "\n",
    "    if context.has(\"log\"):\n",
    "        message.append(f\"<log>The user's last log output was :\\n\\n```{context.log}```</log>\")\n",
    "\n",
    "    return list(map(lambda text: text if isinstance(text, dict) else {\"type\": \"text\", \"text\": text}, message))\n",
    "\n",
    "\n",
    "def build_prompt(content, history, context):\n",
    "    system_message = generate_system_message(context)\n",
    "\n",
    "    prompt = []\n",
    "    prompt.extend(history)\n",
    "    prompt.append({\"role\": \"user\", \"content\": content})\n",
    "\n",
    "    return (system_message, prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<adaptor>The user is using the OpenFn @openfn/language-googlesheets@3.0.5 adaptor. Use functions provided by its API.Typescript definitions for doc @openfn/language-common/**\\n * Execute a sequence of operations.\\n * Main outer API for executing expressions.\\n * @public\\n * @example\\n *  execute(\\n *    create(\\'foo\\'),\\n *    delete(\\'bar\\')\\n *  )\\n * @private\\n * @param {Operations} operations - Operations to be performed.\\n * @returns {Promise}\\n */\\nexport function execute(...operations: Operations): Promise<any>;\\n/**\\n * alias for \"fn()\"\\n * @function\\n * @param {Function} func is the function\\n * @returns {Operation}\\n */\\nexport function alterState(func: Function): Operation;\\n/**\\n * Creates a custom step (or operation) for more flexible job writing.\\n * @public\\n * @function\\n * @example\\n * fn(state => {\\n *   // do some things to state\\n *   return state;\\n * });\\n * @param {Function} func is the function\\n * @returns {Operation}\\n */\\nexport function fn(func: Function): Operation;\\n/**\\n * A custom operation that will only execute the function if the condition returns true\\n * @public\\n * @function\\n * @example\\n * fnIf((state) => state?.data?.name, get(\"https://example.com\"));\\n * @param {Boolean} condition - The condition that returns true\\n * @param {Operation} operation - The operation needed to be executed.\\n * @returns {Operation}\\n */\\nexport function fnIf(condition: boolean, operation: Operation): Operation;\\n/**\\n * Picks out a single value from a JSON object.\\n * If a JSONPath returns more than one value for the reference, the first\\n * item will be returned.\\n * @public\\n * @function\\n * @example\\n * jsonValue({ a:1 }, \\'a\\')\\n * @param {object} obj - A valid JSON object.\\n * @param {String} path - JSONPath referencing a point in given JSON object.\\n * @returns {Operation}\\n */\\nexport function jsonValue(obj: object, path: string): Operation;\\n/**\\n * Picks out a single value from source data.\\n * If a JSONPath returns more than one value for the reference, the first\\n * item will be returned.\\n * @public\\n * @function\\n * @example\\n * sourceValue(\\'$.key\\')\\n * @param {String} path - JSONPath referencing a point in `state`.\\n * @returns {Operation}\\n */\\nexport function sourceValue(path: string): Operation;\\n/**\\n * Picks out a value from source data.\\n * Will return whatever JSONPath returns, which will always be an array.\\n * If you need a single value use `sourceValue` instead.\\n * @public\\n * @function\\n * @example\\n * source(\\'$.key\\')\\n * @param {String} path - JSONPath referencing a point in `state`.\\n * @returns {Array.<String|Object>}\\n */\\nexport function source(path: string): Array<string | any>;\\n/**\\n * Ensures a path points at the data.\\n * @public\\n * @function\\n * @example\\n * dataPath(\\'key\\')\\n * @param {string} path - JSONPath referencing a point in `data`.\\n * @returns {string}\\n */\\nexport function dataPath(path: string): string;\\n/**\\n * Picks out a single value from the source data object—usually `state.data`.\\n * If a JSONPath returns more than one value for the reference, the first\\n * item will be returned.\\n * @public\\n * @function\\n * @example\\n * dataValue(\\'key\\')\\n * @param {String} path - JSONPath referencing a point in `data`.\\n * @returns {Operation}\\n */\\nexport function dataValue(path: string): Operation;\\n/**\\n * Ensures a path points at references.\\n * @public\\n * @function\\n * @example\\n * referencePath(\\'key\\')\\n * @param {string} path - JSONPath referencing a point in `references`.\\n * @returns {string}\\n */\\nexport function referencePath(path: string): string;\\n/**\\n * Picks out the last reference value from source data.\\n * @public\\n * @function\\n * @example\\n * lastReferenceValue(\\'key\\')\\n * @param {String} path - JSONPath referencing a point in `references`.\\n * @returns {Operation}\\n */\\nexport function lastReferenceValue(path: string): Operation;\\n/**\\n * Simple switcher allowing other expressions to use either a JSONPath or\\n * object literals as a data source.\\n * - JSONPath referencing a point in `state`\\n * - Object Literal of the data itself.\\n * - Function to be called with state.\\n * @public\\n * @function\\n * @example\\n * asData(\\'$.key\\'| key | callback)\\n * @param {String|object|function} data\\n * @param {object} state - The current state.\\n * @returns {array}\\n */\\nexport function asData(data: string | object | Function, state: object): any[];\\n/**\\n * Iterates over an array of items and invokes an operation upon each one, where the state\\n * object is _scoped_ so that state.data is the item under iteration.\\n * The rest of the state object is untouched and can be referenced as usual.\\n * You can pass an array directly, or use lazy state or a JSONPath string to\\n * reference a slice of state.\\n * @public\\n * @function\\n * @example <caption>Using lazy state ($) to iterate over items in state.data and pass each into an \"insert\" operation</caption>\\n * each(\\n *   $.data,\\n *   // Inside the callback operation, `$.data` is scoped to the item under iteration\\n *   insert(\"patient\", {\\n *     patient_name: $.data.properties.case_name,\\n *     patient_id: $.data.case_id,\\n *   })\\n * );\\n * @example <caption>Iterate over items in state.data and pass each one into an \"insert\" operation</caption>\\n * each(\\n *   $.data,\\n *   insert(\"patient\", (state) => ({\\n *     patient_id: state.data.case_id,\\n *     ...state.data\\n *   }))\\n * );\\n * @example <caption>Using JSON path to iterate over items in state.data and pass each one into an \"insert\" operation</caption>\\n * each(\\n *   \"$.data[*]\",\\n *   insert(\"patient\", (state) => ({\\n *     patient_name: state.data.properties.case_name,\\n *     patient_id: state.data.case_id,\\n *   }))\\n * );\\n * @param {DataSource} dataSource - JSONPath referencing a point in `state`.\\n * @param {Operation} operation - The operation needed to be repeated.\\n * @returns {Operation}\\n */\\nexport function each(dataSource: DataSource, operation: Operation): Operation;\\n/**\\n * Combines two operations into one\\n * @public\\n * @function\\n * @example\\n * combine(\\n *   create(\\'foo\\'),\\n *   delete(\\'bar\\')\\n * )\\n * @param {Operations} operations - Operations to be performed.\\n * @returns {Operation}\\n */\\nexport function combine(...operations: Operations): Operation;\\n/**\\n * Adds data from a target object\\n * @public\\n * @function\\n * @example\\n * join(\\'$.key\\',\\'$.data\\',\\'newKey\\')\\n * @param {String} targetPath - Target path\\n * @param {String} sourcePath - Source path\\n * @param {String} targetKey - Target Key\\n * @returns {Operation}\\n */\\nexport function join(targetPath: string, sourcePath: string, targetKey: string): Operation;\\n/**\\n * Recursively resolves objects that have resolvable values (functions).\\n * @public\\n * @function\\n * @param {object} value - data\\n * @param {Function} [skipFilter] - a function which returns true if a value should be skipped\\n * @returns {Operation}\\n */\\nexport function expandReferences(value: object, skipFilter?: Function): Operation;\\n/**\\n * Returns a key, value pair in an array.\\n * @public\\n * @function\\n * @example\\n * field(\\'destination_field_name__c\\', \\'value\\')\\n * @param {string} key - Name of the field\\n * @param {Value} value - The value itself or a sourceable operation.\\n * @returns {Field}\\n */\\nexport function field(key: string, value: Value): Field;\\n/**\\n * Zips key value pairs into an object.\\n * @public\\n * @function\\n * @example\\n *  fields(list_of_fields)\\n * @param {Fields} fields - a list of fields\\n * @returns {Object}\\n */\\nexport function fields(...fields: Fields): any;\\n/**\\n * Merges fields into each item in an array.\\n * @public\\n * @example\\n * merge(\\n *   \"$.books[*]\",\\n *   fields(\\n *     field( \"publisher\", sourceValue(\"$.publisher\") )\\n *   )\\n * )\\n * @function\\n * @public\\n * @param {DataSource} dataSource\\n * @param {Object} fields - Group of fields to merge in.\\n * @returns {DataSource}\\n */\\nexport function merge(dataSource: DataSource, fields: any): DataSource;\\n/**\\n * Groups an array of objects by a specified key path.\\n * @public\\n * @example\\n * const users = [\\n *   { name: \\'Alice\\', age: 25, city: \\'New York\\' },\\n *   { name: \\'Bob\\', age: 30, city: \\'San Francisco\\' },\\n *   { name: \\'Charlie\\', age: 25, city: \\'New York\\' },\\n *   { name: \\'David\\', age: 30, city: \\'San Francisco\\' }\\n * ];\\n * group(users, \\'city\\');\\n * // state is { data: { \\'New York\\': [/Alice, Charlie/], \\'San Francisco\\': [ /Bob, David / ] }\\n * @function\\n * @public\\n * @param {Object[]} arrayOfObjects - The array of objects to be grouped.\\n * @param {string} keyPath - The key path to group by.\\n * @param {function} callback - (Optional) Callback function\\n * @returns {Operation}\\n */\\nexport function group(arrayOfObjects: any[], keyPath: string, callback?: Function): Operation;\\n/**\\n * Returns the index of the current array being iterated.\\n * To be used with `each` as a data source.\\n * @public\\n * @function\\n * @example\\n * index()\\n * @returns {DataSource}\\n */\\nexport function index(): DataSource;\\n/**\\n * Turns an array into a string, separated by X.\\n * @public\\n * @function\\n * @example\\n * field(\"destination_string__c\", function(state) {\\n *   return arrayToString(dataValue(\"path_of_array\")(state), \\', \\')\\n * })\\n * @param {array} arr - Array of toString\\'able primatives.\\n * @param {string} separator - Separator string.\\n * @returns {string}\\n */\\nexport function arrayToString(arr: any[], separator: string): string;\\n/**\\n * Ensures primitive data types are wrapped in an array.\\n * Does not affect array objects.\\n * @public\\n * @function\\n * @example\\n * each(function(state) {\\n *   return toArray( dataValue(\"path_of_array\")(state) )\\n * }, ...)\\n * @param {any} arg - Data required to be in an array\\n * @returns {array}\\n */\\nexport function toArray(arg: any): any[];\\n/**\\n * Prepares next state\\n * @public\\n * @function\\n * @example\\n * composeNextState(state, response)\\n * @param {State} state - state\\n * @param {Object} response - Response to be added\\n * @returns {State}\\n */\\nexport function composeNextState(state: State, response: any): State;\\n/**\\n * Substitutes underscores for spaces and proper-cases a string\\n * @public\\n * @function\\n * @example\\n * field(\"destination_string__c\", humanProper(state.data.path_to_string))\\n * @param {string} str - String that needs converting\\n * @returns {string}\\n */\\nexport function humanProper(str: string): string;\\n/**\\n * Splits an object into two objects based on a list of keys.\\n * The first object contains the keys that are not in the list,\\n * and the second contains the keys that are.\\n * @public\\n * @function\\n * @param {Object} obj - The object to split.\\n * @param {string[]} keys - List of keys to split on.\\n * @returns {Object[]} - Tuple of objects, first object contains keys not in list, second contains keys that are.\\n */\\nexport function splitKeys(obj: any, keys: string[]): any[];\\n/**\\n * Replaces emojis in a string.\\n * @public\\n * @function\\n * @example\\n * scrubEmojis(\\'Dove🕊️⭐ 29\\')\\n * @param {string} text - String that needs to be cleaned\\n * @param {string} replacementChars - Characters that replace the emojis\\n * @returns {string}\\n */\\nexport function scrubEmojis(text: string, replacementChars: string): string;\\n/**\\n * Chunks an array into an array of arrays, each with no more than a certain size.\\n * @public\\n * @function\\n * @example\\n * chunk([1,2,3,4,5], 2)\\n * @param {Object} array - Array to be chunked\\n * @param {Integer} chunkSize - The maxiumum size of each chunks\\n * @returns {Object}\\n */\\nexport function chunk(array: any, chunkSize: Integer): any;\\n/**\\n * Takes a CSV file string or stream and parsing options as input, and returns a promise that\\n * resolves to the parsed CSV data as an array of objects.\\n * Options for `parsingOptions` include:\\n * - `delimiter` {string/Buffer/[string/Buffer]} - Defines the character(s) used to delineate the fields inside a record. Default: `\\',\\'`\\n * - `quote` {string/Buffer/[string/Buffer]} - Defines the characters used to surround a field. Default: `\\'\"\\'`\\n * - `escape` {Buffer/string/null/boolean} - Set the escape character as one character/byte only. Default: `\"`\\n * - `columns` {boolean / array / function} - Generates record in the form of object literals. Default: `true`\\n * - `bom` {boolean} - Strips the {@link https://en.wikipedia.org/wiki/Byte_order_mark byte order mark (BOM)} from the input string or buffer. Default: `true`\\n * - `trim` {boolean} - Ignore whitespace characters immediately around the `delimiter`. Default: `true`\\n * - `ltrim` {boolean} - Ignore whitespace characters from the left side of a CSV field. Default: `true`\\n * - `rtrim` {boolean} - Ignore whitespace characters from the right side of a CSV field. Default: `true`\\n * - `chunkSize` {number} - The size of each chunk of CSV data. Default: `Infinity`\\n * - `skip_empty_lines` {boolean} - Ignore empty lines in the CSV file. Default: `true`\\n * @public\\n * @function\\n * @param {String | Stream} csvData - A CSV string or a readable stream\\n * @param {Object} [parsingOptions] - Optional. Parsing options for converting CSV to JSON.\\n * @param {function} [callback] - (Optional) callback function. If used it will be called state and an array of rows.\\n * @returns {Operation} The function returns a Promise that resolves to the result of parsing a CSV `stringOrStream`.\\n */\\nexport function parseCsv(csvData: string | Stream, parsingOptions?: any, callback?: Function): Operation;\\n/**\\n * Validate against a JSON schema. Any erors are written to an array at `state.validationErrors`.\\n * Schema can be passed directly, loaded as a JSON path from state, or loaded from a URL\\n * Data can be passed directly or loaded as a JSON path from state.\\n * By default, schema is loaded from `state.schema` and data from `state.data`.\\n * @pubic\\n * @function\\n * @param {string|object} schema - The schema, path or URL to validate against\\n * @param {string|object} data - The data or path to validate\\n * @example <caption>Validate `state.data` with `state.schema`</caption>\\n * validate()\\n * @example <caption>Validate form data at `state.form` with a schema from a URL</caption>\\n * validate(\"https://www.example.com/schema/record\", \"form\")\\n * @example <caption>Validate the each item in `state.records` with a schema from a URL</caption>\\n * each(\"records[*]\", validate(\"https://www.example.com/schema/record\"))\\n * @returns {Operation}\\n */\\nexport function validate(schema?: string | object, data?: string | object): Operation;\\n/**\\n * Sets a cursor property on state.\\n * Supports natural language dates like `now`, `today`, `yesterday`, `n hours ago`, `n days ago`, and `start`,\\n * which will be converted relative to the environment (ie, the Lightning or CLI locale). Custom timezones\\n * are not yet supported.\\n * You can provide a formatter to customise the final cursor value, which is useful for normalising\\n * different inputs. The custom formatter runs after natural language date conversion.\\n * See the usage guide at {@link https://docs.openfn.org/documentation/jobs/job-writing-guide#using-cursors}\\n * @public\\n * @function\\n * @example <caption>Use a cursor from state if present, or else use the default value</caption>\\n * cursor($.cursor, { defaultValue: \\'today\\' })\\n * @example <caption>Use a pagination cursor</caption>\\n * cursor(22)\\n * @param {any} value - the cursor value. Usually an ISO date, natural language date, or page number\\n * @param {object} options - options to control the cursor.\\n * @param {string} options.key - set the cursor key. Will persist through the whole run.\\n * @param {any} options.defaultValue - the value to use if value is falsy\\n * @param {Function} options.format - custom formatter for the final cursor value\\n * @returns {Operation}\\n */\\nexport function cursor(value: any, options?: {\\n    key: string;\\n    defaultValue: any;\\n    format: Function;\\n}): Operation;\\n/**\\n * Scopes an array of data based on a JSONPath.\\n * Useful when the source data has `n` items you would like to map to\\n * an operation.\\n * The operation will receive a slice of the data based of each item\\n * of the JSONPath provided.\\n * @public\\n * @function\\n * @example\\n * map(\"$.[*]\",\\n *   create(\"SObject\",\\n *     field(\"FirstName\", sourceValue(\"$.firstName\"))\\n *   )\\n * )\\n * @param {string} path - JSONPath referencing a point in `state.data`.\\n * @param {function} operation - The operation needed to be repeated.\\n * @param {State} state - Runtime state.\\n * @returns {State}\\n */\\nexport const map: any;\\n\\n\\n/**\\n * Scopes an array of data based on a JSONPath.\\n * Useful when the source data has `n` items you would like to map to\\n * an operation.\\n * The operation will receive a slice of the data based of each item\\n * of the JSONPath provided.\\n *\\n * It also ensures the results of an operation make their way back into\\n * the state\\'s references.\\n * @public\\n * @example\\n *  each(\"$.[*]\",\\n *    create(\"SObject\",\\n *    field(\"FirstName\", sourceValue(\"$.firstName\")))\\n *  )\\n * @function\\n * @param {DataSource} dataSource - JSONPath referencing a point in `state`.\\n * @param {Operation} operation - The operation needed to be repeated.\\n * @returns {Operation}\\n */\\nexport function each(dataSource: DataSource, operation: Operation): Operation;\\n\\n\\nexport { parse, format } from \"date-fns\";\\n\\n\\n/**\\n * Builder function to create request options. Returns an object with helpers to\\n * easily add commonly used options. The return object is chainable so you can set\\n * as many options as you want.\\n * Pass an object to set your own options.\\n * @param {CommonRequestOptions} options - options to pass to the request\\n * @returns {OptionsHelpers}\\n * @function\\n * @public\\n * @example <caption>Get with a query an oath token</caption>\\n * get($.data.url, http.options({ query: $.query }).oath($.configuration.access_token)\\n */\\nexport function options(opts?: {}): any;\\n/**\\n * Make a GET request.\\n * @public\\n * @function\\n * @example <caption>Request a resource</caption>\\n * http.get(\\'https://jsonplaceholder.typicode.com/todos\\')\\n * @example <caption>Request a resource with basic auth</caption>\\n * http.get(\\n *  \\'https://jsonplaceholder.typicode.com/todos\\',\\n *  http.options().basic(\\'user\\', \\'pass\\')\\n * )\\n * @example <caption>Request a resource with oauth</caption>\\n * http.get(\\n *  \\'https://jsonplaceholder.typicode.com/todos\\',\\n *  http.options().oauth($.configuration.access_token)\\n * )\\n * @param {string} url - URL to access\\n * @param {CommonRequestOptions} options - Request options\\n * @state {CommonHttpState}\\n * @returns {Operation}\\n */\\nexport function get(url: string, options: CommonRequestOptions): Operation;\\n/**\\n * Make a POST request.\\n * @public\\n * @function\\n * @example <caption>Post a JSON object (setting the content-type header)</caption>\\n *  http.post(\\n *    \\'https://jsonplaceholder.typicode.com/todos\\',\\n *    $.data,\\n *    options().json(),\\n *  })\\n * @param {string} url - URL to access\\n * @param {CommonRequestOptions} options - Request options\\n * @state {CommonHttpState}\\n * @returns {Operation}\\n */\\nexport function post(path: any, data: any, options: CommonRequestOptions): Operation;\\nexport { req as request };\\n/**\\n * Helper functions provided by `http.options`.\\n */\\nexport type OptionsHelpers = any;\\n/**\\n * Options provided to the HTTP request\\n */\\nexport type CommonRequestOptions = {\\n    /**\\n     * - Map of errorCodes -> error messages, ie, `{ 404: \\'Resource not found;\\' }`. Pass `false` to suppress errors.\\n     */\\n    errors: object;\\n    /**\\n     * - Pass a JSON object to be serialised into a multipart HTML form (as FormData) in the body.\\n     */\\n    form: object;\\n    /**\\n     * - An object of query parameters to be encoded into the URL.\\n     */\\n    query: object;\\n    /**\\n     * - An object of headers to append to the request.\\n     */\\n    headers: object;\\n    /**\\n     * - Parse the response body as json, text or stream. By default will use the response headers.\\n     */\\n    parseAs: string;\\n    /**\\n     * - Request timeout in ms. Default: 300 seconds.\\n     */\\n    timeout: number;\\n    /**\\n     * - TLS/SSL authentication options. See https://nodejs.org/api/tls.html#tlscreatesecurecontextoptions\\n     */\\n    tls: object;\\n};\\n/**\\n * State object\\n */\\nexport type CommonHttpState = any;\\n/**\\n * Options provided to the HTTP request\\n * @typedef {Object} CommonRequestOptions\\n * @property {object} errors - Map of errorCodes -> error messages, ie, `{ 404: \\'Resource not found;\\' }`. Pass `false` to suppress errors.\\n * @property {object} form - Pass a JSON object to be serialised into a multipart HTML form (as FormData) in the body.\\n * @property {object} query - An object of query parameters to be encoded into the URL.\\n * @property {object} headers - An object of headers to append to the request.\\n * @property {string} parseAs - Parse the response body as json, text or stream. By default will use the response headers.\\n * @property {number} timeout - Request timeout in ms. Default: 300 seconds.\\n * @property {object} tls - TLS/SSL authentication options. See https://nodejs.org/api/tls.html#tlscreatesecurecontextoptions\\n */\\n/**\\n * State object\\n * @typedef {Object} CommonHttpState\\n * @private\\n * @property data - the parsed response body\\n * @property response - the response from the HTTP server, including headers, statusCode, body, etc\\n * @property references - an array of all previous data objects used in the Job\\n **/\\n/**\\n * Make a HTTP request.\\n * @public\\n * @function\\n * @example\\n * http.request(\\n *   \\'GET\\',\\n *   \\'https://jsonplaceholder.typicode.com/todos\\'\\n * )\\n * @name request\\n * @param {string} method - The HTTP method to use.\\n * @param {string} url - URL to resource.\\n * @param {CommonRequestOptions} options - Request options\\n * @state {CommonHttpState}\\n * @returns {Operation}\\n */\\ndeclare function req(method: string, url: string, options: CommonRequestOptions): Operation;\\n\\n\\nimport * as Adaptor from \\'./Adaptor\\';\\nexport default Adaptor;\\nexport * from \\'./Adaptor\\';\\nexport * as beta from \\'./beta\\';\\nexport * as http from \\'./http\\';\\nexport * as dateFns from \\'./dateFns\\';\\nimport * as metadata from \\'./metadata\\';\\nexport { metadata };\\n\\n\\ndeclare type Entity = {\\n    name: string;\\n    type: string;\\n    label?: string;\\n    datatype?: string;\\n    desc?: string;\\n    children?: Entity[] | Record<string, Entity>;\\n    meta?: Record<string, any>;\\n    addChild: (e: Entity, name?: string) => void;\\n};\\ndeclare type DataType = \\'string\\' | \\'boolean\\' | \\'date\\';\\n\\n\\nexport function encode(data: string): string;\\nexport function decode(base64Data: string): string;\\nexport function uuid(): string;\\n\\n\\n/**\\n * `request` is a helper function that sends HTTP requests and returns the response\\n * body, headers, and status code.\\n * Use the error map to provide custom error messages or get hold of the response in case of errors.\\n * @param method - The HTTP method to use for the request (e.g., \"GET\", \"POST\", \"PUT\", \"DELETE\", etc.).\\n * @param fullUrlOrPath - The full or partial URL for the request.\\n * @param [options] - The `options` parameter is an object that contains additional configuration\\n * options for the request.\\n * @returns an object with the following properties:\\n * - method: the request method\\n * - url: the request url\\n * - code: the status code of the response\\n * - headers: the headers of the response\\n * - body: the body of the response\\n * - message: the status text of the response\\n * - duration: the response time\\n */\\nexport function request(method: any, fullUrlOrPath: any, options?: {}): Promise<{\\n    url: string;\\n    method: any;\\n    statusCode: any;\\n    statusMessage: string;\\n    headers: any;\\n    body: any;\\n    duration: number;\\n}>;\\nexport function makeBasicAuthHeader(username: any, password: any): {\\n    Authorization: string;\\n};\\nexport function logResponse(response: any): any;\\nexport function enableMockClient(baseUrl: any): import(\"undici/types/mock-interceptor\").Interceptable;\\nexport const ERROR_ABSOLUTE_URL: \"Absolute URLs not suppored\";\\nexport function assertRelativeUrl(path: any): void;\\nexport const ERROR_URL_MISMATCH: \"Target origin does not match baseUrl origin\";\\nexport function parseUrl(pathOrUrl: string, baseUrl: any): {\\n    url: string;\\n    baseUrl: string;\\n    path: string;\\n    query: any;\\n};\\nexport function get(url: any, options: any): Promise<{\\n    url: string;\\n    method: any;\\n    statusCode: any;\\n    statusMessage: string;\\n    headers: any;\\n    body: any;\\n    duration: number;\\n}>;\\nexport function post(url: any, body: any, options: any): Promise<{\\n    url: string;\\n    method: any;\\n    statusCode: any;\\n    statusMessage: string;\\n    headers: any;\\n    body: any;\\n    duration: number;\\n}>;\\nexport function put(url: any, body: any, options: any): Promise<{\\n    url: string;\\n    method: any;\\n    statusCode: any;\\n    statusMessage: string;\\n    headers: any;\\n    body: any;\\n    duration: number;\\n}>;\\nexport function del(url: any, body: any, options: any): Promise<{\\n    url: string;\\n    method: any;\\n    statusCode: any;\\n    statusMessage: string;\\n    headers: any;\\n    body: any;\\n    duration: number;\\n}>;\\n\\n\\nexport * from \"./http\";\\nexport * from \"./helpers\";\\nexport * from \"./references\";\\nimport parseDate from \"./parse-date\";\\nimport throwError from \"./throw-error\";\\nexport { parseDate, throwError };\\n\\n\\ndeclare function _default(d: any, startDate: any): any;\\nexport default _default;\\n\\n\\nexport function expandReferences(state: any, ...args: any[]): any[];\\nexport function normalizeOauthConfig(configuration: any): any;\\n\\n\\ndeclare function _default(code: any, { description, fix, ...extras }?: {\\n    description: any;\\n    fix: any;\\n}): never;\\nexport default _default;\\nTypescript definitions for doc @openfn/language-googlesheets/**\\n * Execute a sequence of oper.\\n * Wraps `language-common/execute`, and prepends initial state for http.\\n * @example\\n * execute(\\n *   create(\\'foo\\'),\\n *   delete(\\'bar\\')\\n * )(state)\\n * @private\\n * @param {Operations} operations - Operations to be performed.\\n * @returns {Operation}\\n */\\nexport function execute(...operations: Operations): Operation;\\n/**\\n * Add an array of rows to the spreadsheet.\\n * https://developers.google.com/sheets/api/samples/writing#append_values\\n * @public\\n * @example\\n * appendValues({\\n *   spreadsheetId: \\'1O-a4_RgPF_p8W3I6b5M9wobA3-CBW8hLClZfUik5sos\\',\\n *   range: \\'Sheet1!A1:E1\\',\\n *   values: [\\n *     [\\'From expression\\', \\'$15\\', \\'2\\', \\'3/15/2016\\'],\\n *     [\\'Really now!\\', \\'$100\\', \\'1\\', \\'3/20/2016\\'],\\n *   ],\\n * })\\n * @function\\n * @param {Object} params - Data object to add to the spreadsheet.\\n * @param {string} [params.spreadsheetId] The spreadsheet ID.\\n * @param {string} [params.range] The range of values to update.\\n * @param {array} [params.values] A 2d array of values to update.\\n * @param {function} callback - (Optional) Callback function\\n * @returns {Operation}\\n */\\nexport function appendValues(params: {\\n    spreadsheetId?: string;\\n    range?: string;\\n    values?: any[];\\n}, callback?: Function): Operation;\\n/**\\n * Batch update values in a Spreadsheet.\\n * @example\\n * batchUpdateValues({\\n *   spreadsheetId: \\'1O-a4_RgPF_p8W3I6b5M9wobA3-CBW8hLClZfUik5sos\\',\\n *   range: \\'Sheet1!A1:E1\\',\\n *   values: [\\n *     [\\'From expression\\', \\'$15\\', \\'2\\', \\'3/15/2016\\'],\\n *     [\\'Really now!\\', \\'$100\\', \\'1\\', \\'3/20/2016\\'],\\n *   ],\\n * })\\n * @function\\n * @public\\n * @param {Object} params - Data object to add to the spreadsheet.\\n * @param {string} [params.spreadsheetId] The spreadsheet ID.\\n * @param {string} [params.range] The range of values to update.\\n * @param {string} [params.valueInputOption] (Optional) Value update options. Defaults to \\'USER_ENTERED\\'\\n * @param {array} [params.values] A 2d array of values to update.\\n * @param {function} callback - (Optional) callback function\\n * @returns {Operation} spreadsheet information\\n */\\nexport function batchUpdateValues(params: {\\n    spreadsheetId?: string;\\n    range?: string;\\n    valueInputOption?: string;\\n    values?: any[];\\n}, callback?: Function): Operation;\\n/**\\n * Gets cell values from a Spreadsheet.\\n * @public\\n * @example\\n * getValues(\\'1O-a4_RgPF_p8W3I6b5M9wobA3-CBW8hLClZfUik5sos\\',\\'Sheet1!A1:E1\\')\\n * @function\\n * @param {string} spreadsheetId The spreadsheet ID.\\n * @param {string} range The sheet range.\\n * @param {function} callback - (Optional) callback function\\n * @returns {Operation} spreadsheet information\\n */\\nexport function getValues(spreadsheetId: string, range: string, callback?: Function): Operation;\\nexport { alterState, combine, cursor, dataPath, dataValue, each, field, fields, fn, fnIf, http, lastReferenceValue, merge, sourceValue } from \"@openfn/language-common\";\\n\\n\\nexport default Adaptor;\\nexport * from \"./Adaptor\";\\nimport * as Adaptor from \"./Adaptor\";\\n</adaptor>'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = Context(adaptor=\"@openfn/language-googlesheets@3.0.5\")\n",
    "adaptor_string = (\n",
    "    f\"<adaptor>The user is using the OpenFn {context.adaptor} adaptor. Use functions provided by its API.\"\n",
    ")\n",
    "\n",
    "adaptor_docs = apollo(\"describe_adaptor\", {\"adaptor\": context.adaptor})\n",
    "\n",
    "for doc in adaptor_docs:\n",
    "    adaptor_string += f\"Typescript definitions for doc {doc}\"\n",
    "    adaptor_string += adaptor_docs[doc][\"description\"]\n",
    "adaptor_string += \"</adaptor>\"\n",
    "adaptor_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_questions = \"\"\"\n",
    "How do I create a new workflow in OpenFn?1\n",
    "\n",
    "What's the difference between a Trigger and a Step in a workflow?1\n",
    "\n",
    "Can I merge branches or skip steps in my workflow?1\n",
    "\n",
    "How do I troubleshoot errors in my workflow?2\n",
    "\n",
    "What do the different status codes mean for a workflow run?3\n",
    "\n",
    "How can I optimize my workflow if it's timing out?3\n",
    "\n",
    "What should I include in my run logs to make troubleshooting easier?3\n",
    "\n",
    "How do I handle mapping errors between source and destination systems?3\n",
    "\n",
    "What does the \"DUPLICATE_VALUE\" error mean and how do I resolve it?3\n",
    "\n",
    "Can I use OpenFn to edit source data before retrying a failed attempt?3\n",
    "\n",
    "How do I set up a request and approval process in my workflow?4\n",
    "\n",
    "What's the best way to handle data transformation in OpenFn jobs?5\n",
    "\n",
    "Can OpenFn auto-generate jobs based on Kobo forms?5\n",
    "\n",
    "How do I access the OpenFn platform to start creating workflows?5\n",
    "\n",
    "What programming knowledge do I need to write complex jobs in OpenFn?5\n",
    "\n",
    "How can I design error messages to be more user-friendly and actionable?6\n",
    "\n",
    "Is it possible to auto-correct minor issues in my workflow?6\n",
    "\n",
    "How do I manually run a workflow for testing and troubleshooting?7\n",
    "\n",
    "Does OpenFn support two-way syncing between applications?9\n",
    "\n",
    "Can I set up time-based triggers for my workflows, like running a job every Friday at 11 PM?9\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_questions = \"\"\"  \n",
    "How do I configure the HTTP adapter to handle OAuth 2.0 authentication for connecting to a REST API? Can you provide an example of setting up the headers and body for a POST request using the HTTP adapter?  \n",
    "\n",
    "What's the best way to handle upserts in Salesforce using the Salesforce adapter, and how do I manage external IDs effectively?  \n",
    "\n",
    "How can I use the KoboToolbox adapter to trigger a workflow every time a new submission is received on a specific form?  \n",
    "\n",
    "How do I configure the CommCare adapter to pull data based on a specific date range or case property?  \n",
    "\n",
    "Can you walk me through an example of using the DHIS2 adapter to push aggregated data to a specific data element and period?  \n",
    "\n",
    "How do I use the each() function within a job to process an array of data and create multiple records in the destination system?  \n",
    "\n",
    "How can I implement custom error handling logic to retry failed operations with exponential backoff?  \n",
    "\n",
    "What are some best practices for using the transform function to reshape data before sending it to the destination system?  \n",
    "\n",
    "Can I set up a workflow to trigger based on changes in a database using a webhook? How?  \n",
    "\n",
    "How can I securely manage API keys and other sensitive information using environment variables in OpenFn?  \n",
    "\n",
    "Does OpenFn offer any built-in support for encrypting sensitive data in transit or at rest?  \n",
    "\n",
    "How can I customize the logging level and output format for my workflows?  \n",
    "\n",
    "What's the recommended workflow for using Git to manage and deploy changes to my OpenFn workflows?  \n",
    "\n",
    "How can I write unit tests for my OpenFn jobs to ensure they are working correctly?  \n",
    "\n",
    "How can I set up alerts to notify me when a workflow fails or exceeds a certain execution time?  \n",
    "\n",
    "What's the most efficient way to process large datasets (e.g., millions of records) using OpenFn? Are there specific adapter considerations?  \n",
    "\n",
    "Can I import and use custom JavaScript libraries in my OpenFn jobs? How?  \n",
    "\n",
    "How do I handle nested JSON structures when mapping data between systems?  \n",
    "\n",
    "How can I implement rate limiting in my workflow to avoid exceeding the API limits of the destination system?  \n",
    "\n",
    "How can I use the OpenFn CLI to deploy changes to my workflows and manage my OpenFn instance?  \n",
    "\"\"\"  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_coding_questions = \"\"\"\n",
    "How do I use the each() function to iterate over an array of patients and create individual records in the destination system?\n",
    "\n",
    "What's the correct syntax for using the $ operator to access nested data within the state object?\n",
    "\n",
    "How can I implement error handling using try/catch blocks within a job?\n",
    "\n",
    "What's the proper way to use the dataValue() function to extract specific fields from the incoming data?\n",
    "\n",
    "How do I use the get() function with the HTTP adapter to fetch data from an external API?\n",
    "\n",
    "Can you show me how to use string interpolation to dynamically construct API endpoints in a get() or post() operation?\n",
    "\n",
    "What's the syntax for using the map() function to transform an array of objects before sending them to the destination system?\n",
    "\n",
    "How do I use the upsert() function with the Salesforce adapter to update or insert records based on an external ID?\n",
    "\n",
    "What's the correct way to use the fn() function to execute custom JavaScript code within a job?\n",
    "\n",
    "How can I use the post() function with the HTTP adapter to send transformed data to another system?\n",
    "\n",
    "What's the syntax for using the create() function with the DHIS2 adapter to create new data elements?\n",
    "\n",
    "How do I use the alterState() function to modify the state object between operations?\n",
    "\n",
    "Can you show me how to use the field() function to map data from one schema to another?\n",
    "\n",
    "What's the proper way to use the combine() function to merge data from multiple sources?\n",
    "\n",
    "How do I use the sourceValue() function to reference values from the trigger source in my job?\n",
    "\n",
    "What's the syntax for using the relationship() function to establish relationships between objects in Salesforce?\n",
    "\n",
    "How can I use the then() method to chain operations and handle asynchronous tasks?\n",
    "\n",
    "What's the correct way to use the execute() function to run a custom SQL query in a database adapter?\n",
    "\n",
    "How do I use the scrub() function to clean and standardize data before sending it to the destination system?\n",
    "\n",
    "Can you show me how to use the chunk() function to process large datasets in smaller batches to avoid memory issues?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_overview_questions = \"\"\"\n",
    "How do I configure OpenFn to listen for incoming SMS messages and trigger a workflow based on the message content?\n",
    "\n",
    "Can you help me set up a job that automatically exports data from CommCare and imports it into a DHIS2 instance?\n",
    "\n",
    "I need to create a workflow that synchronizes patient data between OpenMRS and a national health registry. What's the best approach?\n",
    "\n",
    "How can I use OpenFn to transform data from a CSV file into FHIR resources and load them into a FHIR server?\n",
    "\n",
    "I want to set up automated alerts based on data thresholds in my system. How can I achieve this with OpenFn?\n",
    "\n",
    "We're using Salesforce and need to integrate it with our accounting system. Can you help us build a workflow to synchronize invoice data?\n",
    "\n",
    "How can I use the OpenFn CLI to deploy and manage my workflows across multiple environments (dev, staging, production)?\n",
    "\n",
    "I need to implement a data quality check within my workflow. How can I use JavaScript within OpenFn to validate data and handle errors?\n",
    "\n",
    "How can I set up OpenFn to automatically retry failed tasks with exponential backoff?\n",
    "\n",
    "I'm working with a complex data model in ActivityInfo. Can you help me write a job to efficiently extract and transform this data?\n",
    "\n",
    "How do I configure OpenFn to use OAuth 2.0 for authentication with a REST API?\n",
    "\n",
    "What are the best practices for handling Personally Identifiable Information (PII) within OpenFn workflows?\n",
    "\n",
    "How can I use OpenFn to create a scheduled task that runs daily and generates reports based on data from multiple systems?\n",
    "\n",
    "I need to integrate data from a legacy system that only supports XML. How can I transform XML data into JSON for use in my workflows?\n",
    "\n",
    "Can you help me set up monitoring and logging for my OpenFn workflows?\n",
    "\n",
    "How do I write a job to take data from a google sheet and use that data to create a new user in Keycloak?\n",
    "\n",
    "How can I implement a workflow that handles data conflicts between two systems, using a defined conflict resolution strategy?\n",
    "\n",
    "I need to trigger a workflow based on changes in a cloud storage bucket (e.g., AWS S3, Google Cloud Storage). How can I set this up?\n",
    "\n",
    "Can you provide guidance on optimizing the performance of my OpenFn workflows, especially when dealing with large datasets?\n",
    "\n",
    "How do I use OpenFn to implement a bulk data import process, breaking the data into smaller batches to avoid API rate limits?\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openfn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
